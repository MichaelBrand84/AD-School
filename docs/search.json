[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "AutoDiff",
    "section": "",
    "text": "Vorwort"
  },
  {
    "objectID": "index.html#danksagung",
    "href": "index.html#danksagung",
    "title": "AutoDiff",
    "section": "Danksagung",
    "text": "Danksagung"
  },
  {
    "objectID": "intro.html#ableitungen-von-funktionen",
    "href": "intro.html#ableitungen-von-funktionen",
    "title": "1  Ableitungen und ihre Anwendungen",
    "section": "1.1 Ableitungen von Funktionen",
    "text": "1.1 Ableitungen von Funktionen\nWir kennen Ableitungen von Funktionen \\(f: \\mathbb{R}\\rightarrow\\mathbb{R}\\) aus dem Mathematikunterricht. Sie geben uns darüber Auskunft, wie gross die Steigung der Tangente in einem bestimmten Punkt des Funktionsgraphen ist. Die Tangente stellt dabei die beste lineare Annäherung an den Funktionsgraph dar. Ableitungen beschreiben auch die lokale Änderungsrate der Funktion. Ableitungen erlauben es uns ausserdem, die Extrema und Wendepunkte einer Funktion zu bestimmen.\nDie folgende Tabelle fasst die bekannten Ableitungen der Grundfunktionen zusammen.\n\n\nTabelle 1.1: Ableitungen der Grundfunktionen\n\n\n\n\n\n\n\n\n\n\\(f(x)\\)\n\\(f'(x)\\)\n\n\\(f(x)\\)\n\\(f'(x)\\)\n\n\n\n\n\\(x^n\\)\n\\(n \\cdot x^{n-1} \\quad (n\\in\\mathbb{R})\\)\n\n\\(\\sqrt{x}\\)\n\\(\\frac{1}{2\\cdot\\sqrt{x}}\\)\n\n\n\\(e^x\\)\n\\(e^x\\)\n\n\\(a^x\\)\n\\(a^x \\cdot \\ln(a) \\quad (a>0, a\\ne 1)\\)\n\n\n\\(\\ln(x)\\)\n\\(\\frac{1}{x}\\)\n\n\\(\\log_a(x)\\)\n\\(\\frac{1}{x\\cdot\\ln(a)} \\quad (a>0, a\\ne 1)\\)\n\n\n\\(\\sin(x)\\)\n\\(\\cos(x)\\)\n\n\\(\\arcsin(x)\\)\n\\(\\frac{1}{\\sqrt{1-x^2}}\\)\n\n\n\\(\\cos(x)\\)\n\\(-\\sin(x)\\)\n\n\\(\\arccos(x)\\)\n\\(-\\frac{1}{\\sqrt{1-x^2}}\\)\n\n\n\\(\\tan(x)\\)\n\\(\\frac{1}{\\cos^2(x)} = 1 + \\tan^2(x)\\)\n\n\\(\\arctan(x)\\)\n\\(\\frac{1}{x^2+1}\\)\n\n\n\\(\\sinh(x)\\)\n\\(\\cosh(x)\\)\n\n\\(\\textrm{arsinh}(x)\\)\n\\(\\frac{1}{\\sqrt{x^2+1}}\\)\n\n\n\\(\\cosh(x)\\)\n\\(\\sinh(x)\\)\n\n\\(\\textrm{arcosh(x)}\\)\n\\(\\frac{1}{\\sqrt{x^2-1}}\\)\n\n\n\\(\\tanh(x)\\)\n\\(\\frac{1}{\\cosh^2(x)} = 1 - \\tanh^2(x)\\)\n\n\\(\\textrm{artanh(x)}\\)\n\\(-\\frac{1}{x^2-1}\\)\n\n\n\n\nNeue Funktionen erhält man, indem man die Grundfunktionen aus Tabelle 1.1 addiert, subtrahiert, multipliziert, dividiert und komponiert, d.h. Verkettungen der Form \\((f\\circ g)(x) = f(g(x))\\) bildet. Um solche Funktionen abzuleiten, brauchen wir die Regeln aus Tabelle 1.2. Mit diesen Regeln sind wir dann schon in der Lage, alle differenzierbaren Funktionen abzuleiten.\n\n\nTabelle 1.2: Ableitungsregeln\n\n\n\n\n\n\nRegel\nFormel\n\n\n\n\nSummenregel\n\\(\\frac{d}{dx}(f(x)\\pm g(x)) = f'(x) \\pm g'(x)\\)\n\n\nProduktregel\n\\(\\frac{d}{dx}(f(x)\\cdot g(x)) = f'(x)\\cdot g(x) + f(x) \\cdot g'(x)\\)\n\n\nSpezialfall: Faktorregel\n\\(\\frac{d}{dx}(a\\cdot f(x)) = a\\cdot f'(x)\\)\n\n\nQuotientenregel\n\\(\\frac{d}{dx}\\frac{f(x)}{g(x)} = \\frac{f'(x)\\cdot g(x) - f(x) \\cdot g'(x)}{g(x)^2}\\)\n\n\nKettenregel\n\\(\\frac{d}{dx} f(g(x)) = f'(g(x))\\cdot g'(x)\\)\n\n\n\n\nAn dieser Stelle sei noch angemerkt, dass sich der Begriff der Ableitung sinngemäss auf Funktionen \\(f: \\mathbb{R}^n \\rightarrow\\mathbb{R}^m\\) verallgemeinern lässt. Eine kurze Beschreibung der Grundidee findet sich in Slater (2022). Weitergehende Informationen findet man z.B. in Arens u. a. (2022) oder in jedem Lehrbuch zur Analysis 2."
  },
  {
    "objectID": "intro.html#sec-ProgFunc",
    "href": "intro.html#sec-ProgFunc",
    "title": "1  Ableitungen und ihre Anwendungen",
    "section": "1.2 Programme als Funktionen",
    "text": "1.2 Programme als Funktionen\nProgramme, die numerische Werte einlesen und numerische Werte ausgeben, können als mathematische Funktionen betrachtet werden. Wir beschränken uns zunächst auf Programme, die nur ein Argument erhalten und nur einen Rückgabewert liefern.\n\nBeispiel 1.1 (Eine Funktion als Programm) \nBetrachte das folgende Programm:\n\ndef f(x):\n    y = (2 + x) * (x - 3)\n    return y\n\nx0 = 2\nprint( f(x0) )\n\nDiese Python-Funktion entspricht der Funktion \\(f:\\mathbb{R}\\rightarrow\\mathbb{R} , x \\mapsto y=(2+x)(x-3)\\) im Sinne der Mathematik. Natürlich kann der Funktionskörper viel komplizierter aufgebaut sein und z.B. Schleifen und Bedingungen enthalten.\nUm zu verstehen, wie der Computer einen Ausdruck wie y = (2 + x) * (x - 3) auswertet, ist es hilfreich, ihn als Baum (im Sinne der Graphentheorie) darzustellen. Ausdrucksbäume sind ein Spezialfall von so genannten computational graphs und werden z.B. in Hromkovic u. a. (2021) erklärt.\n\n\n\n\n\n\n   \n\nnx\n\nx   \n\nnPlus\n\n +   \n\nnx->nPlus\n\n    \n\nnMinus\n\n -   \n\nnx->nMinus\n\n    \n\nn2\n\n2   \n\nn2->nPlus\n\n    \n\nn3\n\n3   \n\nn3->nMinus\n\n    \n\nnMult\n\n *   \n\nnPlus->nMult\n\n    \n\nnMinus->nMult\n\n    \n\nny\n\ny   \n\nnMult->ny\n\n   \n\n\nAbbildung 1.1: Ausdrucksbaum zum Ausdruck y = (2 + x) * (x - 3).\n\n\n\n\nWir wollen nun unsere Python-Funktion so umschreiben, dass diese Struktur auch im Funktionskörper sichtbar wird. Dazu führen wir drei Hilfsvariablen v0, v1, v2 ein.\n\ndef f(x):\n    v0 = x\n    v1 = 2 + v0\n    v2 = v0 - 3\n    y = v1 * v2\n    return y\n\n\n\n\n\n\n\n\n\nKonvention\n\n\n\nEine Funktion berechnet aus einem Argument x einen Rückgabewert y über eine Reihe von Hilfsvariablen v, die mit aufsteigenden Indizes versehen sind. Dabei setzen wir am Anfang immer v0 = x.\n\n\n\nÜbungsaufgabe 1.1 (Programm in Funktion übersetzen) \nSchreibe die mathematische Funktion auf, die durch das folgende Programm berechnet wird.\n\nimport math\n\ndef f(x):\n    v0 = x\n    v1 = v0 ** 2\n    v2 = v1 + 2\n    v3 = -v1 / 2\n    v4 = math.cos(v2)\n    v5 = math.exp(v3)\n    v6 = v4 * v5\n    y = v6 + 1 / v0\n    return y \n\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\\[\\begin{align*}\nv_1 & = x^2 \\\\\nv_2 & = x^2 + 2 \\\\\nv_3 & = - \\frac{x^2}{2} \\\\\nv_4 & = \\cos(x^2 + 2) \\\\\nv_5 & = e^{- \\frac{x^2}{2}} \\\\\nv_6 & = \\cos(x^2 + 2) \\cdot e^{- \\frac{x^2}{2}} \\\\\ny & = f(x) = \\cos(x^2 + 2) \\cdot e^{- \\frac{x^2}{2}} + \\frac{1}{x}\n\\end{align*}\\]\n\n\n\n\nÜbungsaufgabe 1.2 (Funktion in Graph und Programm übersetzen) \nSchreibe zur mathematischen Funktion \\(y = f(x) = \\frac{\\ln(x^2 + 1)}{\\sqrt{x^2 + 1 + x}}\\) den Ausdrucksbaum auf. Übersetze den Ausdruck anschliessend in eine Python-Funktion gemäss der Konvention.\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\n\n\n\n\n\n   \n\nnx\n\nx   \n\nnPlus2\n\n +   \n\nnx->nPlus2\n\n    \n\nnPow\n\n ^   \n\nnx->nPow\n\n    \n\nn2\n\n2   \n\nn2->nPow\n\n    \n\nn1\n\n1   \n\nnPlus1\n\n +   \n\nn1->nPlus1\n\n    \n\nnPlus1->nPlus2\n\n    \n\nnLog\n\n ln( )   \n\nnPlus1->nLog\n\n    \n\nnSqrt\n\n sqrt( )   \n\nnPlus2->nSqrt\n\n    \n\nnPow->nPlus1\n\n    \n\nnFrac\n\n /   \n\nny\n\ny   \n\nnFrac->ny\n\n    \n\nnLog->nFrac\n\n    \n\nnSqrt->nFrac\n\n   \n\n\nAbbildung 1.2: Computational Graph zum Ausdruck y = ln(x^2 + 1) / sqrt(x^2 + 1 + x).\n\n\n\n\n\n\nCode\nimport math\n\ndef f(x):\n    v0 = x\n    v1 = v0 ** 2\n    v2 = v1 + 1\n    v3 = v2 + v0\n    v4 = math.log(v2)\n    v5 = math.sqrt(v3)\n    y = v4 / v5\n    return y\n\n\nNatürlich hätte man z.B. v3 und v4 auch vertauschen können.\n\n\n\n\nÜbungsaufgabe 1.3 (Ein Programm mit einer Schleife) \nBetrachte das folgende Programm:\n\ndef f(x):\n    v0 = x\n    for i in range(2):\n        v0 = v0 ** 2 + 1\n    y = v0\n    return y\n\nErsetze im Funktionskörper die Schleife durch mehrere Befehle, so dass immer noch der gleiche mathematische Ausdruck berechnet wird und unsere Konvention eingehalten wird. Welche mathematische Funktion wird durch die Python-Funktion berechnet? Was ändert sich, wenn stattdessen for i in range(3) oder for i in range(4) stehen würde?\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\nFür jeden Schleifendurchgang benötigen wir eine neue Hilfsvariable. Die Funktion, die dabei entsteht, kann geschrieben werden als \\(f(x) = (\\ell \\circ \\ell \\circ \\ldots \\circ \\ell)(x)\\), wobei \\(\\ell(x) = x^2 + 1\\) ist.\n\nrange(2)range(3)range(4)\n\n\n\ndef f(x):\n    v0 = x\n    v1 = v0 ** 2 + 1\n    v2 = v1 ** 2 + 1\n    y = v2\n    return y\n\n\\[\\begin{align*}\n    f(x) &= \\ell(\\ell(x)) \\\\\n         &= (x^2 + 1)^2 + 1 = x^4 + 2x^2 + 2\n\\end{align*}\\]\n\n\n\ndef f(x):\n    v0 = x\n    v1 = v0 ** 2 + 1\n    v2 = v1 ** 2 + 1\n    v3 = v2 ** 2 + 1\n    y = v3\n    return y\n\n\\[\\begin{align*}\n    f(x) &= \\ell(\\ell(\\ell(x))) \\\\\n         &= ((x^2 + 1)^2 + 1)^2 + 1 = x^8 + 4x^6 + 8x^4 + 8x^2 + 5\n\\end{align*}\\]\n\n\n\ndef f(x):\n    v0 = x\n    v1 = v0 ** 2 + 1\n    v2 = v1 ** 2 + 1\n    v3 = v2 ** 2 + 1\n    v4 = v3 ** 2 + 1\n    y = v4\n    return y\n\n\\[\\begin{align*}\n    f(x) &= \\ell(\\ell(\\ell(\\ell(x)))) \\\\\n         &= (((x^2 + 1)^2 + 1)^2 + 1)^2 + 1 \\\\\n         &= x^{16} + 8x^{14} + 32x^{12} + 80x^{10} + 138x^8 + 168x^6 + 144x^4 + 80x^2 + 26\n\\end{align*}\\]"
  },
  {
    "objectID": "intro.html#unser-ziel-programme-ableiten",
    "href": "intro.html#unser-ziel-programme-ableiten",
    "title": "1  Ableitungen und ihre Anwendungen",
    "section": "1.3 Unser Ziel: Programme ableiten",
    "text": "1.3 Unser Ziel: Programme ableiten\nWie eingangs erwähnt wurde, haben Ableitungen viele nützliche Anwendungen.\nWir möchten nun Ableitungen von Funktionen berechnen, die durch Programme beschrieben werden, die wie oben einen numerischen Parameter x als Input erhalten und einen numerischen Wert y zurückliefern. Unser Ziel wird es sein, die Programme so zu modifizieren, dass der Funktionsaufruf f(x0) nicht nur den Funktionswert \\(f(x_0)\\) zurückgibt, sondern auch den Wert der Ableitung \\(f'(x_0)\\). Wir sind dabei nicht an einer symbolischen Ableitung interessiert, wie das z.B. GeoGebra oder Mathematica machen (s. Kapitel 2.2), sondern nur an einer punktweisen Auswertung. Natürlich wollen wir die Ableitungsfunktion auch nicht von Hand bestimmen. Wir wollen uns aber auch nicht bloss mit einer Annhäerung des Wertes der Ableitung zufrieden geben (s. Kapitel 2.1), sondern den Wert von \\(f'(x_0)\\) bis auf Maschinengenauigkeit exakt berechnen. In Kapitel 3 werden wir eine Methode kennen lernen, die all dies leistet und dabei die Laufzeit eines Programms nicht wesentlich erhöht. Der Name dieser Methode: Algorithmische Differentiation (AD), obwohl die Namensgebung hier nicht eindeutig ist:\n\nOne of the obstacles in this area [of computing derivatives], which involves “symbolic” and “numerical” methods, has been a confusion in terminology […]. There is not even general agreement on the best name for the field, which is frequently referred to as automatic or computational differentiation in the literature. For this book the adjective algorithmic seemed preferable, because much of the material emphasizes algorithmic structure, sometimes glossing over the details and pitfalls of actual implementations. (Aus dem Vorwort zu Griewank und Walther (2008))\n\nBevor wir uns aber der Methode der algorithmischen Differentiation zuwenden, wollen wir sie durch einige Beispiele motivieren, bei denen die Berechnung von Ableitung von Funktionen und Programmen eine zentrale Rolle spielt: Das Newtonverfahren und das Gradient Descent Verfahren.\n\n1.3.1 Das Newtonverfahren zur Berechnung von Nullstellen\nIn vielen Anwendungen steht man vor der Aufgabe, die Gleichung \\(f(x) = 0\\) nach \\(x\\) aufzulösen, d.h. eine Nullstelle \\(\\bar{x}\\) der Funktion zu finden. Oft ist es aber nicht möglich, die Lösung einer solchen Gleichung in geschlossener Form darzustellen. Um dennoch eine Lösung zumindest näherungsweise berechnen zu können, kann man folgendermassen vorgehen:\n\nWähle einen Startwert \\(x_0\\), der in der Nähe einer Nullstelle \\(\\bar{x}\\) von \\(f\\) liegt.\nIm Kurvenpunkt \\((x_0 | y_0)\\) wird die Tangente an die Kurve \\(f\\) gelegt. Deren Schnittpunkt \\(x_1\\) mit der \\(x\\)-Achse liegt in der Regel näher bei \\(\\bar{x}\\) als \\(x_0\\).\nNun wiederholt man das Verfahren, indem man bei \\(x_1\\) die Tangente an die Kurve legt, usw. Auf diese Weise erhält man eine Folge von Näherungen \\(x_0, x_1, x_2, \\ldots\\), deren Grenzwert die Nullstelle \\(\\bar{x}\\) ist.\n\nDieser Algorithmus ist als Newtonverfahren bekannt.\n\n\n\n\n\n\nDie Gleichung der Tangente im Punkt \\((x_n | y_n) = (x_n | f(x_n))\\) ist bekanntlich \\(t(x) = f(x_n) + f'(x_n) \\cdot (x - x_n)\\). Die Nullstelle der Tangente ist der Näherungswert \\(x_{n+1}\\). Aus \\(t(x_{n+1}) = 0\\) ergibt sich nun die Iterationsvorschrift des Newtonverfahrens: \\[\nx_{n+1} = x_n - \\frac{f(x_n)}{f'(x_n)}\n\\tag{1.1}\\]\n\nÜbungsaufgabe 1.4 (Das Newtonverfahren programmieren) \nSchreibe ein Programm, das mit Hilfe des Newtonverfahrens (Gleichung 1.1) eine Nullstelle der Funktion \\(f(x) = \\frac{1}{31} x^3 -\\frac{1}{20} x^2 -x + 1\\) berechnet. Verwende den Startwert \\(x_0 = -2\\). Du kannst abbrechen, wenn die Differenz \\(|x_{n+1} - x_n|\\) kleiner als eine bestimmte Toleranz wird, z.B. kleiner als tol = 1e-6. Wie flexibel ist dein Programm einsetzbar? Überlege dir z.B., wie viele Änderungen du vornehmen müsstest, wenn du die Nullstelle einer anderen Funktion berechnen müsstest.\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\nWelche der folgenden Lösungsvorschläge kommt deinem Programm am nächsten?\n\nVersion 1Version 2Version 3Version 4\n\n\n\nfrom math import fabs\n\nx0 = -2\ntol = 1e-6\n# Erster Schritt berechnen\nx1 = x0 - (1/31 * x0**3 - 1/20 * x0**2 - x0 + 1) / (3/31 * x0**2 - 1/10 * x0 - 1)\nwhile fabs(x1 - x0) > tol:\n    x0 = x1\n    x1 = x0 - (1/31 * x0**3 - 1/20 * x0**2 - x0 + 1) / (3/31 * x0**2 - 1/10 * x0 - 1)\nprint(x1)\n\n5.908619865450271\n\n\nDas Newtonverfahren wird als main-Funktion (d.h. im Hauptprogramm) ausgeführt. Braucht man jedoch die Nullstelle einer anderen Funktion, dann muss ein neues Programm geschrieben werden. Die Ableitung wurde von Hand berechnet.\n\n\n\nfrom math import fabs\n\ndef f(x):\n    y = 1/31 * x**3 - 1/20 * x**2 - x + 1\n    return y\n\ndef fdot(x):\n    ydot = 3/31 * x**2 - 1/10 * x - 1\n    return ydot\n\nx0 = -2\ntol = 1e-6\n# Erster Schritt berechnen\nx1 = x0 - f(x0) / fdot(x0)\nwhile fabs(x1 - x0) > tol:\n    x0 = x1\n    x1 = x0 - f(x0) / fdot(x0)\nprint(x1)\n\n5.908619865450271\n\n\nDas Newtonverfahren wird als main-Funktion (d.h. im Hauptprogramm) ausgeführt, aber die Berechnung von \\(f\\) und ihrer Ableitung \\(f'\\) wurde in zwei Funktionen f und fdot ausgelagert. Das macht das Programm übersichtlicher und flexibler. Die Ableitung wurde wieder von Hand berechnet.\n\n\n\nfrom math import fabs\n\ndef newton(f, fdot, x0):\n    tol = 1e-6\n    # Erster Schritt berechnen\n    x1 = x0 - f(x0) / fdot(x0)\n    while fabs(x1 - x0) > tol:\n        x0 = x1\n        x1 = x0 - f(x0) / fdot(x0)\n    return x1\n\ndef f(x):\n    y = 1/31 * x**3 - 1/20 * x**2 - x + 1\n    return y\n\ndef fdot(x):\n    ydot = 3/31 * x**2 - 1/10 * x - 1\n    return ydot\n\nx0 = -2\nxbar = newton(f, fdot, x0)\nprint(xbar)\n\n5.908619865450271\n\n\nDas Newtonverfahren wird als eigene Funktion newton(f, fdot, x0) implementiert. Dieser werden die Funktion \\(f\\) und ihre Ableitung \\(f'\\), sowie der Startwert \\(x_0\\) als Argumente übergeben. Sie kann dann im Hauptprogramm aufgerufen werden. Die Ableitung wurde aber immer noch von Hand berechnet.\n\n\n\nfrom math import fabs\n\ndef newton(f, x0):\n    tol = 1e-6\n    # Erster Schritt berechnen\n    # Ableitung von f an der Stelle x0 annähern\n    h = 1e-6\n    ydot = ( f(x0 + h) - f(x0) ) / h\n    x1 = x0 - f(x0) / ydot\n    while fabs(x1 - x0) > tol:\n        x0 = x1\n        ydot = ( f(x0 + h) - f(x0) ) / h\n        x1 = x0 - f(x0) / ydot\n    return x1\n\ndef f(x):\n    y = 1/31 * x**3 - 1/20 * x**2 - x + 1\n    return y\n\nx0 = -2\nxbar = newton(f, x0)\nprint(xbar)\n\n5.90861986545027\n\n\nHier wird das Newtonverfahren in einer Funktion implementiert. Die Ableitung wird nicht mehr von Hand berechnet, sondern innerhalb der Funktion mit \\(f'(x_0)\\approx \\frac{f(x_0 + h) - f(x_0)}{h}\\) angenähert. Dabei wird einfach h = 1e-6 gesetzt und gehofft, dass der entstehende Rundungsfehler klein genug ist. Beachte aber, dass sich der berechnete Wert von der Ausgabe in den anderen Versionen leicht unterscheidet.\n\n\n\n\n\n\nAuch die Version 4 der vorgestellten Lösung ist noch nicht befriedigend. Als wir die Ableitung von Hand berechnet hatten, musste nur die Funktion fdot and der Stelle x0 ausgewertet werden, um den (bis auf Maschinengenauigkeit) exakten Wert von \\(f'(x_0)\\) zu erhalten. Bei der letzten Methode muss man sich mit einem Näherungswert der Ableitung zufrieden geben. Auch wenn der Wert in diesem Beispiel gut genug war 1, so haben wir doch keine Garantie, dass wir für alle Funktionen einen vernünftigen Wert erhalten. Auf die Probleme, die mit dieser Annäherung von \\(f'(x_0)\\) auftreten, wird in Kapitel 2.1 näher eingegangen.1 Das Newton-Verfahren hat die angenehme Eigenschaft, dass kleine Rundungsfehler automatisch ausgeglichen werden. Auf andere numerische Verfahren, die die Ableitung verwenden, trifft dies aber nicht zu.\n\nBeispiel 1.2 (Billard auf einem runden Tisch) \nWir betrachten ein Beispiel aus Gander (2015). Platziere die weisse und die blaue Billardkugel auf dem runden Tisch. Das Ziel ist es, die weisse Kugel so anzustossen, dass sie die blaue Kugel trifft, nachdem sie vorher genau einmal an die Bande gespielt wurde.\n\n\n\n\n\n\nAus Symmetriegründen dürfen wir annehmen, dass der Rand des Billardtisches der Einheitskreis ist und dass die weisse Kugel auf der \\(x\\)-Achse liegt. Die blaue Kugel habe die Koordinaten \\((x_P|y_P)\\). Weiter sei \\(X\\) der Punkt auf dem Einheitskreis, an dem die weisse Kugel abprallt. Wir beschreiben diesen Punkt mit seinen Polarkoordinaten \\(X=(\\cos(x)|\\sin(x))\\). Unser Ziel ist es, \\(x\\) so zu berechnen, dass die weisse Kugel die blaue trifft, nachdem sie bei \\(X\\) an die Bande gestossen ist. Dabei verhält sie sich so, als ob sie an der Kreistangente in \\(X\\) reflektiert wird. Der Tangentenvektor im Punkt \\(X\\) lautet \\(\\vec{t} = \\begin{pmatrix} -\\sin(x) \\\\ \\cos(x) \\end{pmatrix}\\).\n\n\n\n\n\n\nBillard auf einem runden Tisch\n\n\n\nWir betrachten nun die Einheitsvektoren \\(\\vec{e}_Q\\) in Richtung \\(\\overrightarrow{XQ}\\) und \\(\\vec{e}_P\\) in Richtung \\(\\overrightarrow{XP}\\). Wenn die weisse Kugel die blaue treffen soll, dann müssen die Winkel zwischen der Tangente und diesen Vektoren gleich sein. Das ist genau dann der Fall, wenn \\(\\vec{t}\\) senkrecht steht auf \\(\\vec{e}_Q + \\vec{e}_P\\). Wir müssen also \\(x\\) so bestimmen, dass \\(\\vec{t} \\cdot (\\vec{e}_Q + \\vec{e}_P) = 0\\) ist.\nDas folgende Programm berechnet das Skalarprodukt der linken Seite dieser Gleichung.\n\n\nCode\nimport math\nimport matplotlib.pyplot as plt\n\ndef f(x):\n    # Parameter\n    a = -0.8           # Position von Q = (a|0)\n    px, py = 0.5, 0.5  # Position von P = (px|py)\n\n    # Berechnung des Skalarprodukts\n    v0 = x\n    v1 = math.cos(v0)  # x-Koordinate von X\n    v2 = math.sin(v0)  # y-Koordinate von X\n    v3 = px - v1       # x-Komponente des Vektors XP\n    v4 = py - v2       # y-Komponente des Vektors XP\n    v5 = math.sqrt(v3**2 + v4**2)  # Länge des Vektors XP\n    v6 = v3 / v5       # x-Komponente des Einheitsvektors eP\n    v7 = v4 / v5       # y-Komponente des Einheitsvektors eP\n    \n    v8 = a - v1        # x-Komponente des Vektors XQ\n    v9 = -v2           # y-Komponente des Vektors XQ\n    v10 = math.sqrt(v8**2 + v9**2)  # Länge des Vektors XQ\n    v11 = v8 / v10     # x-Komponente des Vektors eQ    \n    v12 = v9 / v10     # y-Komponente des Vektors eQ   \n    y = (v6 + v11) * v2 - (v7 + v12) * v1  # Skalarprodukt\n    return y   \n\n# Graph der Funktion f(x) plotten\nfig = plt.figure()\nax = plt.gca()\nax.set_xlim((0,2*math.pi))\nax.set_ylim((-1.5,1.5))\nX = [2*math.pi * k / 1000 for k in range(1001)]\nY = [f(x) for x in X]\nplt.plot([0, 2*math.pi], [0, 0], 'k--') # x-Achse\nplt.plot(X,Y)\nplt.xticks([0, math.pi/2, math.pi, 3*math.pi/2, 2*math.pi],\n           ['0', 'π/2', 'π', '3π/2', '2π'])\nplt.show()  \n\n\n\n\n\nAbbildung 1.3: Graph des Skalarprodukts als Funktion des Polarwinkels \\(x\\) des Punktes \\(X = (cos(x) | sin(x))\\). Die Nullstellen entsprechen den Winkeln, bei denen die weisse Kugel die blaue Kugel trifft, nachdem sie genau einmal an die Bande gespielt wurde.\n\n\n\n\nWir möchten die Nullstellen der Funktion f(x) mit unserer Funtion newton bestimmmen. Dazu müssen wir jedoch die Ableitung von f berechnen.\n\n\n\n\n1.3.2 Gradient Descent zum Auffinden lokaler Minima\nEine weitere wichtige Aufgabe besteht darin, ein Minimum einer Funktion zu finden. Auch hier wollen wir mit Hilfe der Ableitung eine Folge von Näherungswerten \\(x_0, x_1, x_2, \\ldots\\) finden, deren Grenzwert die \\(x\\)-Koordinate eines (lokalen) Minimums von \\(f\\) ist.\nWenn \\(f'(x_n)>0\\) ist, dann wissen wir, dass die Funktion \\(f\\) an der Stelle \\(x_0\\) streng monoton wachsend ist. D.h., dass die Funktionswerte links von \\(x_n\\) kleiner sind, als an der Stelle \\(x_n\\). Analog gilt, dass wenn \\(f'(x_n)<0\\) ist, die Funktion monoton fallend ist und wir uns nach rechts bewegen sollten, um ein Minimum zu finden. In der Nähe eines Minimums ist ausserdem \\(|f'(x)|\\) sehr klein und wir können entsprechend kleinere Schritte machen, um uns diesem anzunähern. Um also von \\(x_n\\) zu \\(x_{n+1}\\) zu kommen, machen wir einen Schritt, der proportional zu \\(-f'(x_n)\\) ist. Mit dem Proporionalitätsfaktor \\(\\lambda\\in\\mathbb{R}\\) und einem geeignet gewählten Startwert \\(x_0\\) erhalten wir die Iterationsvorschrift \\[\nx_{n+1} = x_n - \\lambda\\cdot f'(x_n)\n\\tag{1.2}\\]\n\n\n\n\n\n\n\nÜbungsaufgabe 1.5 (Eigenschaften der Gradient Descent Methode)  Experimentiere mit verschiedenen Funktionen und verschiedenen Schrittweiten \\(\\lambda\\). Was passiert, wenn die Schrittweite zu klein bzw. zu gross gewählt wird? Was passiert, wenn \\(f\\) an der Stelle \\(x_0\\) ein lokales Maximum aufweist? Was passiert in der Nähe eines Sattelpunktes?\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\nIst \\(\\lambda\\) zu klein, dann konvergiert das Verfahren nur sehr langsam. Ist \\(\\lambda\\) dagegen zu gross, dann kann es passieren, dass die Iteration zwischen zwei oder mehr Werten hin- und herspringt oder sogar nach \\(\\pm\\infty\\) divergiert.\nFalls \\(x_0\\) gerade mit der Stelle eines lokalen Maximums oder eines Sattelpunktes zusammenfällt, gilt auch \\(f'(x_0)=0\\) und damit auch \\(x_n = x_0\\) für alle \\(n\\in\\mathbb{N}\\). Maxima sind aber labile Gleichgewichtspunkte in dem Sinn, dass sich \\(x_n\\) von ihnen wegbewegt, wenn \\(x_0\\) auch nur ein bisschen links oder rechts davon liegt. Ähnlich verhält es sich bei Sattelpunkten. Die Folge konvergiert gegen die Stelle des Sattelpunktes, wenn \\(f(x_0)\\) grösser als der \\(y\\)-Wert des Sattelpunktes ist und \\(\\lambda\\) nicht zu gross ist.\n\n\n\n\nÜbungsaufgabe 1.6 (Gradient Descent programmieren) \nSchreibe ein Programm, das mit Hilfe des Gradient Descent Verfahrens (Gleichung 1.2) ein lokales Minimums der Funktion \\(f(x) = \\frac{1}{16}x^4 - \\frac{1}{3}x^3 + \\frac{1}{8}x^2 + x + 2\\) berechnet. Verwende den Startwert \\(x_0 = 1.5\\) und die Schrittweite \\(\\lambda = 0.5\\). Du kannst abbrechen, wenn die Differenz \\(|x_{n+1} - x_n|\\) kleiner als eine bestimmte Toleranz wird, z.B. kleiner als tol = 1e-6. Wie flexibel ist dein Programm einsetzbar? Überlege dir z.B., wie viele Änderungen du vornehmen müsstest, wenn du ein lokales Minimum einer anderen Funktion berechnen müsstest.\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\nWelche der folgenden Lösungsvorschläge kommt deinem Programm am nächsten?\n\nVersion 1Version 2Version 3Version 4\n\n\n\nfrom math import fabs\n\nx0 = 1.5\nlam = 0.5\ntol = 1e-6\n# Erster Schritt berechnen\nx1 = x0 - lam * (1/4 * x0**3 - x0**2 + 1/4 * x0 + 1)\nwhile fabs(x1-x0) > tol:\n    x0 = x1\n    x1 = x0 - lam * (1/4 * x0**3 - x0**2 + 1/4 * x0 + 1)\nprint(x1)\n\n3.3429230748530196\n\n\nDas Gradient Descent Verfahren wird als main-Funktion (d.h. im Hauptprogramm) ausgeführt. Um das Minimum einer anderen Funktion zu bestimmen, muss ein neues Programm geschrieben werden. Die Ableitung wurde von Hand berechnet\n\n\n\nfrom math import fabs\n\ndef fdot(x):\n    ydot = 1/4 * x**3 - x**2 + 1/4 * x + 1\n    return ydot\n\nx0 = 1.5\nlam = 0.5\ntol = 1e-6\n# Erster Schritt berechnen\nx1 = x0 - lam * fdot(x0)\nwhile fabs(x1-x0) > tol:\n    x0 = x1\n    x1 = x0 - lam * fdot(x0)\nprint(x1)\n\n3.3429230748530196\n\n\nDas Gradient Descent Verfahren wird als main-Funktion (d.h. im Hauptprogramm) ausgeführt, aber die Berechnung von \\(f'\\) wurde in die Funktion fdot(x) ausgelagert. Das macht das Programm etwas flexibler. Die Ableitung wurde wieder von Hand berechnet.\n\n\n\nfrom math import fabs\n\ndef gradient_descent(fdot, x0, lam):\n    tol = 1e-6\n    # Erster Schritt berechnen\n    x1 = x0 - lam * fdot(x0)\n    while fabs(x1-x0) > tol:\n        x0 = x1\n        x1 = x0 - lam * fdot(x0)\n    return x1\n\ndef fdot(x):\n    ydot = 1/4 * x**3 - x**2 + 1/4 * x + 1\n    return ydot\n\nx0 = 1.5\nlam = 0.5\nxmin = gradient_descent(fdot, x0, lam)\nprint(xmin)\n\n3.3429230748530196\n\n\nDas Gradient Descent Verfahren wird als eigene Funktion gradient_descent(fdot, x0, lam) implementiert. Dieser Funktion werden die Ableitung \\(f'\\), der Startwert \\(x_0\\), sowie die Schrittweite \\(\\lambda\\) als Argumente übergeben. Sie kann dann im Hauptprogramm aufgerufen werden. Die Ableitung wurde aber immer noch von Hand berechnet.\n\n\n\nfrom math import fabs\n\ndef gradient_descent(f, x0, lam):\n    tol = 1e-6\n    # Erster Schritt berechnen\n    # Ableitung an der Stelle x0 annähern\n    h = 1e-6\n    ydot = ( f(x0 + h) - f(x0) ) / h\n    x1 = x0 - lam * ydot\n    while fabs(x1-x0) > tol:\n        x0 = x1\n        ydot = ( f(x0 + h) - f(x0) ) / h\n        x1 = x0 - lam * ydot\n    return x1\n\ndef f(x):\n    y = 1/16 * x**4 - 1/3 * x**3 + 1/8 * x**2 + x + 2\n    return y\n\nx0 = 1.5\nlam = 0.5\nxmin = gradient_descent(fdot, x0, lam)\nprint(xmin)\n\n2.535183236464121\n\n\nDas Gradient Descent Verfahren wird als eigene Funktion gradient_descent(f, x0, lam) implementiert. Dieser Funktion werden die ursprüngliche Funktion \\(f\\), der Startwert \\(x_0\\), sowie die Schrittweite \\(\\lambda\\) als Argumente übergeben. Die Ableitung wird nicht mehr von Hand berechnet, sondern durch den Differenzenquotienten \\(f'(x_0) \\approx \\frac{f(x_0 + h) - f(x_0)}{h}\\) angenähert. Dabei wird einfach h = 1e-6 gesetzt und gehofft, dass der entstehende Rundungsfehler klein genug ist. Offensichtlich ist diese Annahme jedoch nicht gerechtfertigt.\n\n\n\n\n\n\nDie Übungsaufgabe 1.6 verdeutlicht nochmals das Problem, welches wir bereits in Übungsaufgabe 1.4 gesehen haben. Wir müssen für den Algorithmus die Ableitung \\(f'\\) an mehreren Stellen auswerten. Wir möchten aber die Ableitung einerseits nicht von Hand berechnen und andererseits können wir uns auch nicht mit einer Approximation zufrieden geben.\nWir beschliessen dieses Kapitel mit einer praktischen Anwendung der Gradient Descent Methode.\n\nBeispiel 1.3 (Minimaler Abstand) \nDie Punkte \\(P\\) und \\(Q\\) bewegen sich auf Ellipsen im Raum. Die Position des Punktes \\(P\\) zur Zeit \\(t\\) ist gegeben durch\n\\[\\begin{align*}\n    x_P(t) &= 2 \\cos(t) - 1 \\\\\n    y_P(t) &= 1.5 \\sin(t)   \\\\\n    z_P(t) &= 0             \n\\end{align*}\\]\nund die Position von \\(Q\\) zum Zeitpunkt \\(t\\) lässt sich durch\n\\[\\begin{align*}\n    x_Q(t) &= -3 \\sin(2t)     \\\\\n    y_Q(t) &= 2 \\cos(2t) + 1  \\\\\n    z_Q(t) &= 2 \\sin(2t) + 1  \n\\end{align*}\\]\nbestimmen.\n\n\n\n\n\n\nDer Abstand zwischen den beiden Punkten lässt sich zu jedem Zeitpunkt \\(t\\) berechnen durch \\(d = d(t) = |\\overrightarrow{PQ}|\\). Das folgende Programm berechnet diese Funktion und zeichnet ihren Graph.\n\n\nCode\nimport math\nimport matplotlib.pyplot as plt\n\ndef d(t):\n    v0 = t\n    v1 = 2 * math.cos(v0) - 1    # x-Koordinate von P\n    v2 = 1.5 * math.sin(v0)      # y-Koordinate von P\n    v3 = 0                       # z-Koordinate von P\n    v4 = -3 * math.sin(2*v0)     # x-Koordinate von Q\n    v5 = 2 * math.cos(2*v0) + 1  # y-Koordinate von Q\n    v6 = 2 * math.sin(2*v0) + 1  # z-Koordinate von Q\n    y = math.sqrt((v4-v1)**2 + (v5-v2)**2 + (v6-v3)**2)\n    return y\n\n# Graph der Funktion d(t) plotten\nfig = plt.figure()\nax = plt.gca()\nax.set_xlim((0,2*math.pi))\nax.set_ylim((0,6))\nT = [2*math.pi * k / 1000 for k in range(1001)]\nY = [d(t) for t in T]\nplt.plot(T,Y)\nplt.xticks([0, math.pi/2, math.pi, 3*math.pi/2, 2*math.pi],\n           ['0', 'π/2', 'π', '3π/2', '2π'])\nplt.show()  \n\n\n\n\n\nAbbildung 1.4: Graph der Abstandsfunktion \\(d(t)\\).\n\n\n\n\nWir möchten das Minimum der Funktion \\(d(t)\\) mit Hilfe der Gradient Descent Methode finden. Dazu müssen wir aber \\(d\\) ableiten können.\n\n\n\n\n\n\nArens, Tilo, Frank Hettlich, Christian Karpfinger, Ulrich Kockelkorn, Klaus Lichtenegger, und Hellmuth Stachel. 2022. Mathematik. Berlin, Heidelberg: Springer Berlin Heidelberg.\n\n\nGander, Walter. 2015. Learning MATLAB: A Problem Solving Approach. 1. Aufl. UNITEXT. Cham, Switzerland: Springer International Publishing.\n\n\nGriewank, Andreas, und Andrea Walther. 2008. Evaluating Derivatives: Principles and Techniques of Algorithmic Differentiation. 2. Aufl. Other Titles in Applied Mathematics 105. Philadelphia, PA: SIAM. http://bookstore.siam.org/ot105/.\n\n\nHromkovic, Juraj, Jarka Arnold, Cédric Donner, Urs Hauser, Matthias Hauswirth, Tobias Kohn, Dennis Komm, David Maletinsky, und Nicole Roth. 2021. INFORMATIK, Programmieren und Robotik: Grundlagen der Informatik für Schweizer Maturitätsschulen.\n\n\nSlater, Max. 2022. „Differentiable programming from scratch“. Juli 2022. https://thenumb.at/Autodiff/."
  },
  {
    "objectID": "notAD.html#sec-ADnotNumDiff",
    "href": "notAD.html#sec-ADnotNumDiff",
    "title": "2  AD ist nicht …",
    "section": "2.1 AD ist nicht numerisches Ableiten",
    "text": "2.1 AD ist nicht numerisches Ableiten\nEine Funktion \\(y = f(x)\\) ist bekanntlich differenzierbar an der Stelle \\(x_0 \\in \\mathbb{D}\\), wenn der Grenzwert \\[ \\lim_{h\\rightarrow 0} \\frac{f(x_0 + h) - f(x_0)}{h} \\] existiert. In dem Fall ist \\(f'(x_0)\\) einfach der Wert dieses Grenzwerts.\nEin erster Ansatz zur numerischen Berechnung könnte also sein, den Differenzenquotienten für kleine \\(h\\) auszuwerten1.1 Dieser Ansatz kann verbessert werden indem man z.B. \\(f'(x_0) \\approx \\frac{f(x_0 + h) - f(x_0 - h)}{2h}\\) verwendet. Die im Beispiel beschriebenen Probleme bleiben aber auch dann bestehen.\n\nBeispiel 2.1 (Numerische Ableitung) \nLeite die Funktion \\(f(x) = x^2\\) an der Stelle \\(x_0 = 0.2\\) ab.\n\n\nCode\ndef f(x):\n    y = x ** 2\n    return y\n\ndef fdot(f, x0, h):\n    df = (f(x0 + h) - f(x0)) / h\n    return df\n\nx0 = 0.2\nH = [0.1, 0.01, 0.001, 0.0001]\nfor h in H:\n    ydot = fdot(f, x0, h)\n    print(\"h = \" + str(h) + \" \\t=> f'(x0) = \" + str(ydot))\n\n\nh = 0.1     => f'(x0) = 0.5000000000000001\nh = 0.01    => f'(x0) = 0.4099999999999999\nh = 0.001   => f'(x0) = 0.4009999999999986\nh = 0.0001  => f'(x0) = 0.40009999999993107\n\n\nEs scheint zunächst, als ob die Werte für kleiner werdende \\(h\\) zum korrekten Wert \\(f'(0.2)=0.4\\) konvergieren. Wenn wir aber an sehr genauen Werten interessiert sind und entsprechend \\(h\\) sehr klein wählen, beobachten wir folgendes:\n\n\nCode\ndef f(x):\n    y = x ** 2\n    return y\n\ndef fdot(f, x0, h):\n    df = (f(x0 + h) - f(x0)) / h\n    return df\n\nx0 = 0.2\nH = [10 ** -8, 10 ** -9, 10 ** -10, 10 ** -11]\nfor h in H:\n    ydot = fdot(f, x0, h)\n    print(\"h = \" + str(h) + \"\\t=> f'(x0) = \" + str(ydot))\n\n\nh = 1e-08   => f'(x0) = 0.4000000095039091\nh = 1e-09   => f'(x0) = 0.3999999984016789\nh = 1e-10   => f'(x0) = 0.4000000330961484\nh = 1e-11   => f'(x0) = 0.3999994779846361\n\n\nMit kleiner werdendem \\(h\\) scheint sich der Näherungswert für die Ableitung zu verschlechtern. Das Phänomen wird noch deutlicher, wenn wir den Fehler \\(E(h) = \\lvert\\frac{f(x_0+h)-f(x_0)}{h} - f'(x_0)\\rvert\\) als Funktion von \\(h\\) plotten. Beachte die doppelt logarithmische Skala.\n\n\nCode\nimport matplotlib.pyplot as plt\nimport math\n\ndef f(x):\n    y = x ** 2\n    return y\n\ndef fdot(f, x0, h):\n    df = (f(x0 + h) - f(x0)) / h\n    return df\n\nx0 = 0.2\nH = [10**(k/100) for k in range(-1800, -300)]\nE = [math.fabs(fdot(f, x0, h) - 2*x0) for h in H]\n\n# Plot\nfig = plt.figure()\nax = fig.add_axes([0.1, 0.1, 0.8, 0.8])\nax.set(xlim=(10**-18, 10**-3), ylim=(10**-12, 10**0))\nax.set_xscale('log')\nax.set_xlabel('h')\nax.set_yscale('log')\nax.set_ylabel('Fehler E(h)')\nplt.plot(H,E)\nplt.show()\n\n\n\n\n\nAbbildung 2.1: Grösse des Fehlers \\(E(h)\\) als Funktion der Schrittweite \\(h\\). Ist \\(h\\) zu gross, dann ist der Näherungswert für \\(f'(x_0)\\) ungenau. Bei kleiner werdendem \\(h\\) nimmt der Fehler zunächst ab, aber ab einem gewissen Wert dominiert die Auslöschung und der Fehler nimmt wieder zu.\n\n\n\n\n\n\n\n2.1.1 Auslöschung\nIm vorherigen Beispiel haben wir das Phänomen der Auslöschung beobachtet. Zunächst ist dir sicher aufgefallen, dass der Näherungswert für \\(f'(x_0)\\) mit \\(h=0.01\\) nicht \\[ \\frac{f(x_0 + h) - f(x_0)}{h} = \\frac{0.21^2 - 0.2^2}{0.01}=0.41\\] ergab, sondern \\(f'(x_0)\\approx 0.40999...\\). Das liegt daran, dass Dezimalzahlen nicht exakt als Binärzahl dargestellt werden können. Da nun die Werte von \\(f(x_0 + h)\\) und \\(f(x_0)\\) für kleine \\(h\\) fast gleich sind, besteht ihre Differenz \\(f(x_0 + h) - f(x_0)\\) nur noch aus diesen Rundungsfehlern. Diese (sinnlose) Differenz ist zwar sehr klein, wird aber im nächsten Schritt mit der sehr grossen Zahl \\(\\frac{1}{h}\\) multipliziert, wodurch die Rundungsfehler die gleiche Grössenordnung annehmen, wie die ursprünglichen Funktionswerte. Mehr über Rundungsfehler und Auslöschung kann in Weitz (2021) ab S. 117 nachgelesen werden."
  },
  {
    "objectID": "notAD.html#sec-ADnotSymbDiff",
    "href": "notAD.html#sec-ADnotSymbDiff",
    "title": "2  AD ist nicht …",
    "section": "2.2 AD ist nicht symbolisches Ableiten",
    "text": "2.2 AD ist nicht symbolisches Ableiten\nComputer Algebra Systeme (CAS) sind Programme zur Bearbeitung algebraischer Ausdrücke. Mit solchen Programmen lassen sich auch Ableitungen symbolisch bestimmen. Wie das funktioniert, wird in Slater (2022) kurz angedeutet. Bekannte Beispiele für CAS sind etwa Wolfram Alpha, Maxima oder Sage. Letzteres kann man hier auch online ausprobieren. Gib z.B. den folgenden Code ein, welcher die Ableitung der Funktion aus Übungsaufgabe 1.3 bestimmt:\nl(x) = x^2 + 1\nf(x) = l(l(l(x)))\nfdot = diff(f,x)\nexpand(fdot)\n\n\n\n\n\n\nTipp\n\n\n\nAuf der Website kannst du rechts unter Language auch Maxima auswählen und Maxima-Code ausführen. Maxima ist in Sage integriert.\n\n\nFür Python gibt es die Bibliothek sympy, die ein CAS für Python zur Verfügung stellt. Damit können wir die Funktion aus Übungsaufgabe 1.3 direkt in Python ableiten:\n\nBeispiel 2.2 (Symbolische Ableitung)  Leite die Funktion \\(f(x) = l(l(l(x)))\\), wobei \\(l(x) = x^2 + 1\\) ist, an der Stelle \\(x_0 = 1\\) ab.\n\n\nCode\nfrom sympy import symbols, diff\n\ndef f(x):\n    v0 = x\n    v1 = v0 ** 2 + 1\n    v2 = v1 ** 2 + 1\n    v3 = v2 ** 2 + 1\n    y = v3\n    return y\n\nx = symbols('x')\nprint(\"f(x) =\", f(x))\n\ndf = diff(f(x),x)\nprint(\"f'(x) =\", df)\n\nx0 = 1\nprint(\"f'(\" + str(x0) + \") =\", df.evalf(subs={x:x0}))\n\n\nf(x) = ((x**2 + 1)**2 + 1)**2 + 1\nf'(x) = 8*x*(x**2 + 1)*((x**2 + 1)**2 + 1)\nf'(1) = 80.0000000000000\n\n\n\n\nDamit erhält man die (bis auf Maschinengenauigkeit) exakten Werte der Ableitungen. Der Grund, warum wir nicht auf symbolische Ausdrücke für Ableitungen zurückgreifen wollen, liegt darin, dass diese Methode bei komplizierten Funktionsausdrücken sehr ineffizient ist, insbesondere dann, wenn wir auch Ableitungen von Funktionen \\(f : \\mathbb{R}^n \\rightarrow \\mathbb{R}^m\\) berechnen wollen.\n\n\n\n\nSlater, Max. 2022. „Differentiable programming from scratch“. Juli 2022. https://thenumb.at/Autodiff/.\n\n\nWeitz, Edmund. 2021. Konkrete Mathematik (nicht nur) für Informatiker. 2. Aufl. Wiesbaden, Germany: Springer Spektrum."
  },
  {
    "objectID": "ADOneDimManually.html#sec-SadManualImplementation",
    "href": "ADOneDimManually.html#sec-SadManualImplementation",
    "title": "3  Standard Algorithmische Differentiation für eindimensionale Funktionen",
    "section": "3.1 Manuelle Implementation der SAD",
    "text": "3.1 Manuelle Implementation der SAD\nBeginnen wir mit einem Beispiel:\nWir möchten den Funktionswert und die Ableitung der Funktion \\(y=f(x)=\\sin(x^2)\\) an der Stelle \\(x_0=\\frac{\\pi}{2}\\) bestimmen. Das folgende Programm berechnet den Funktionswert.\n\n\nCode\nimport math\n\ndef f(x):\n    v0 = x\n    v1 = v0**2\n    v2 = math.sin(v1)\n    y = v2\n    return y\n\nx0 = math.pi / 2\nprint(f(x0))\n\n\n0.6242659526396992\n\n\n\\(f\\) ist eine zusammengesetzte Funktion, die wir mit den Funktionen\n\\[\\begin{align*}\n    v_0(x)   &= x \\\\\n    v_1(v_0) &= v_0 ^2 \\\\\n    v_2(v_1) &= \\sin(v_1)\n\\end{align*}\\]\nschreiben können als \\(y=f(x)=v_2(v_1(v_0(x)))\\). Die Ableitung berechnet sich dann mit der Kettenregel zu \\[\nf'(x) = \\frac{dv_2}{dv_1} \\cdot \\frac{dv_1}{dv_0} \\cdot \\frac{dv_0}{dx} = \\cos(v_1)\\cdot 2v_0 \\cdot 1 = \\cos(x^2) \\cdot 2x \\cdot 1\n\\] Wir können also die Ableitung von f(x) berechnen, indem wir jede Zeile des Programms gemäss den bekannten Regeln ableiten:\nv0dot = 1\nv1dot = 2 * v0 * v0dot\nv2dot = math.cos(v1) * v1dot\nMan beachte, dass durch die Konvention, dass immer v0 = x gesetzt wird, auch immer v0dot = 1 ist. Nun können wir unsere Funktion so ergänzen, dass nicht nur der Funktionswert, sondern auch die Ableitung an der Stelle \\(x_0\\) berechnet wird:\n\n\nCode\nimport math\n\ndef f(x):\n    v0dot = 1\n    v0 = x\n    v1dot = 2 * v0 * v0dot\n    v1 = v0**2\n    v2dot = math.cos(v1) * v1dot\n    v2 = math.sin(v1)\n    ydot = v2dot\n    y = v2\n    return [y, ydot]\n\nx0 = math.pi / 2\nprint(f(x0))\n\n\n[0.6242659526396992, -2.4542495411512917]\n\n\nDie Korrektheit des Programms können wir mit GeoGebra überprüfen, welches Ableitungen symbolisch berechnet.\n\n\n\n\n\n\nBeachte, dass wir konsequent die Kettenregel verwendet haben. So wird aus v1 = v0**2 etwa v1dot = 2 * v0 * v0dot oder aus v2 = sin(v1) wird v2dot = cos(v1) * v1dot.\n\nÜbungsaufgabe 3.1 (Programm ableiten) \nÄndere das vorherige Programm so ab, dass der Funktionswert und die Ableitung der Funktion \\(y = f(x) = \\ln(\\sin(x^2))\\) an der Stelle \\(x_0 = \\frac{\\pi}{2}\\) berechnet wird. Überprüfe deine Lösung mit GeoGebra.\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\nEs müssen lediglich zwei weitere Zeilen eingefügt werden und zwar für die Berechnung von v3 und v3dot. Vergiss nicht, die richtigen Werte zurückzugeben.\n\n\nCode\nimport math\n\ndef f(x):\n    v0dot = 1\n    v0 = x\n    v1dot = 2 * v0 * v0dot\n    v1 = v0**2\n    v2dot = math.cos(v1) * v1dot\n    v2 = math.sin(v1)\n    v3dot = 1 / v2 * v2dot\n    v3 = math.log(v2)\n    ydot = v3dot\n    y = v3\n    return [y, ydot]\n\nx0 = math.pi / 2\nprint(f(x0))\n\n\n[-0.4711787952593891, -3.9314166194288416]\n\n\n\n\n\n\n\n\n\n\n\nKonvention\n\n\n\nEin Programm, welches gemäss der Konvention in Kapitel 1.2 geschrieben ist, wird folgendermassen abgeleitet:\n\nFür jede Variable v wird eine neue Variable vdot für den Wert der Ableitung definiert, angefangen bei v0dot = 1.\nJede Programmzeile wird gemäss den bekannten Regeln aus Tabelle 1.1 und Tabelle 1.2 abgeleitet. Dabei wird insbesondere in jeder Zeile die Kettenregel verwendet.\nDie abgeleitete Anweisung wird jeweils vor (!) die zu ableitende Anweisung eingeschoben.\n\n\n\n\nÜbungsaufgabe 3.2 (Produktregel) \nDas folgende Programm berechnet die Funktion \\(y = f(x) = (2+x)(x-3)\\):\n\ndef f(x):\n    v0 = x\n    v1 = 2 + v0\n    v2 = v0 - 3\n    y = v1 * v2\n    return y\n\nLeite dieses Programm ab. Dein Programm soll die Gleichung der Tangente \\(t(x) = f(x_0) + f'(x_0)\\cdot (x-x_0)\\) an der Stelle \\(x_0 = 2\\) ausgeben.\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\n\nCode\ndef f(x):\n    v0dot = 1\n    v0 = x\n    v1dot = v0dot\n    v1 = 2 + v0\n    v2dot = v0dot\n    v2 = v0 - 3\n    ydot = v1dot * v2 + v1 * v2dot # Produktregel\n    y = v1 * v2\n    return [y, ydot]\n\nx0 = 2\n[y0, y0dot] = f(x0)\nprint(\"t(x) =\", y0, \"+\", y0dot, \"* ( x -\", x0, \")\")\n\n\nt(x) = -4 + 3 * ( x - 2 )\n\n\n\n\n\n\nÜbungsaufgabe 3.3 (Programm ableiten) \nLeite die Funktion aus Übungsaufgabe 1.1 ab. Gib den Funktionswert und den Wert der Ableitung an der Stelle \\(x_0=-2\\) aus.\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\n\nCode\nimport math\n\ndef f(x):\n    v0dot = 1\n    v0 = x\n    v1dot = 2 * v0 * v0dot\n    v1 = v0 ** 2\n    v2dot = v1dot\n    v2 = v1 + 2\n    v3dot = -1/2 * v1dot\n    v3 = -v1 / 2\n    v4dot = -math.sin(v2) * v2dot\n    v4 = math.cos(v2)\n    v5dot = math.exp(v3) * v3dot\n    v5 = math.exp(v3)\n    v6dot = v4dot * v5 + v4 * v5dot\n    v6 = v4 * v5\n    ydot = v6dot - 1 / v0**2 * v0dot\n    y = v6 + 1 / v0\n    return [y, ydot]\n\nx0 = -2\nprint(f(x0))\n\n\n[-0.3700550823007931, -0.14136926695938976]\n\n\n\n\n\n\nÜbungsaufgabe 3.4 (Programm ableiten) \nLeite die Funktion aus Übungsaufgabe 1.2 ab.\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\n\nCode\nimport math\n\ndef f(x):\n    v0dot = 1\n    v0 = x\n    v1dot = 2 * v0 * v0dot\n    v1 = v0 ** 2\n    v2dot = v1dot\n    v2 = v1 + 1\n    v3dot = v2dot + v0dot\n    v3 = v2 + v0\n    v4dot = 1 / v2 * v2dot\n    v4 = math.log(v2)\n    v5dot = 1 / (2 * math.sqrt(v3)) * v3dot\n    v5 = math.sqrt(v3)\n    ydot = (v4dot * v5 - v4 * v5dot) / v5**2\n    y = v4 / v5\n    return [y, ydot]\n\n\n\n\n\nBei all diesen Beispielen könnten wir auch die Reihenfolge der Anweisungen für vdot und v vertauschen, d.h. zuerst die Variable v berechnen und erst danach das zugehörige vdot. Die folgende Übung zeigt aber, warum der 3. Punkt unserer Konvention wichtig ist.\n\nÜbungsaufgabe 3.5 (Ein Programm mit einer Schleife) \nBetrachte die Funktion aus Übungsaufgabe 1.3, welche aus \\(\\ell(x) = x^2 + 1\\) die Funktion \\(y = f(x) = \\ell(\\ell(\\ell(x)))\\) berechnet. Aus Beispiel 2.2 wissen wir, dass \\(f'(1) = 80\\) ist. Vergleiche nun die beiden Varianten für die Ableitung des Programms:\n\nvdot vor vv vor vdot\n\n\n\ndef f(x):\n    v0dot = 1\n    v0 = x\n    for i in range(3):\n        v0dot = 2 * v0 * v0dot\n        v0 = v0 ** 2 + 1\n    ydot = v0dot\n    y = v0\n    return [y, ydot]\n\nprint(f(1))\n\n[26, 80]\n\n\n\n\n\ndef f(x):\n    v0 = x\n    v0dot = 1\n    for i in range(3):\n        v0 = v0 ** 2 + 1\n        v0dot = 2 * v0 * v0dot\n    y = v0\n    ydot = v0dot\n    return [y, ydot]\n\nprint(f(1))\n\n[26, 2080]\n\n\n\n\n\nWarum wird bei der 2. Variante der Wert der Ableitung falsch berechnet?\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\nDas Problem tritt in der Schleife auf. In der 2. Variante überschreiben wir den Wert von v0 bereits mit dem neuen Wert der Iteration. Bei der Berechnung von v0dot hätten wir aber noch den alten Wert gebraucht. Die Reihenfolge ist also nur in der 1. Version korrekt. Würden wir die Schleife eliminieren und dafür wie in der Lösung zu Übungsaufgabe 1.3 für jeden Schleifendurchgang fortlaufend numerierte Variablen für die v und vdot verwenden, dann wäre die Reihenfolge wieder egal.\n\n\n\nIn der nächsten Übungsaufgabe verwenden wir die Technik der AD, um das Billardproblem aus Kapitel 1.3.1 mit dem Newtonverfahren zu lösen. Da uns die Funktion f(x) nun nicht mehr nur der Funktionswert, sondern auch die Ableitung berechnet, können wir das Newtonverfahren ohne die Probleme aus Übungsaufgabe 1.4 implementieren.\n\nÜbungsaufgabe 3.6 (Das Billard-Problem) \nLeite das Programm aus Beispiel 1.2 ab. Schreibe danach eine Funktion newton(f, x0), welche ausnutzt, dass der Funktionsaufruf f(x0) auch den exakten Wert der Ableitung zurückgibt. Stelle alle gefundenen Lösungen grafisch dar.\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\n\nCode\nimport math\nimport matplotlib.pyplot as plt\n\ndef f(x):\n    # Parameter werden im global space gefunden\n    # Berechnung des Skalarprodukts und dessen Ableitung\n    v0dot = 1\n    v0 = x\n    v1dot = -math.sin(v0) * v0dot  # Ableitung von ...\n    v1 = math.cos(v0)  # x-Koordinate von X\n    v2dot = math.cos(v0) * v0dot   # Ableitung von ...\n    v2 = math.sin(v0)  # y-Koordinate von X\n    v3dot = - v1dot    # Ableitung von ...\n    v3 = px - v1       # x-Komponente des Vektors XP\n    v4dot = - v2dot    # Ableitung von ...\n    v4 = py - v2       # y-Komponente des Vektors XP\n    v5dot = 1 / (2*math.sqrt(v3**2 + v4**2)) \\\n        * (2*v3*v3dot + 2*v4*v4dot)  # Ableitung von ...\n    v5 = math.sqrt(v3**2 + v4**2)  # Länge des Vektors XP\n    v6dot = (v3dot * v5 - v3 * v5dot) / v5**2  # Ableitung von ...\n    v6 = v3 / v5       # x-Komponente des Einheitsvektors eP\n    v7dot = (v4dot * v5 - v4 * v5dot) / v5**2  # Ableitung von ...\n    v7 = v4 / v5       # y-Komponente des Einheitsvektors eP\n    v8dot = -v1dot     # Ableitung von ...\n    v8 = a - v1        # x-Komponente des Vektors XQ\n    v9dot = -v2dot     # Ableitung von ...\n    v9 = -v2           # y-Komponente des Vektors XQ\n    v10dot = 1 / (2*math.sqrt(v8**2 + v9**2)) \\\n        * (2*v8*v8dot + 2*v9*v9dot)  # Ableitung von ...\n    v10 = math.sqrt(v8**2 + v9**2)  # Länge des Vektors XQ\n    v11dot = (v8dot * v10 - v8 * v10dot) / v10**2  # Ableitung von ...\n    v11 = v8 / v10     # x-Komponente des Vektors eQ    \n    v12dot = (v9dot * v10 - v9 * v10dot) / v10**2  # Ableitung von ... \n    v12 = v9 / v10     # y-Komponente des Vektors eQ   \n    ydot = (v6dot + v11dot) * v2 + (v6 + v11) * v2dot \\\n        - ( (v7dot + v12dot) * v1 + (v7 + v12) * v1dot )  # Ableitung von ...\n    y = (v6 + v11) * v2 - (v7 + v12) * v1\n    return [y, ydot]   \n\ndef newton(f, x0):\n    tol = 1e-8\n    # Erster Schritt berechnen\n    [y0, y0dot] = f(x0)\n    x1 = x0 - y0 / y0dot\n    while math.fabs(x1 - x0) > tol:\n        x0 = x1\n        [y0, y0dot] = f(x0)\n        x1 = x0 - y0 / y0dot\n    return x1 \n\n\nif __name__ == \"__main__\":\n\n    # Parameter definieren\n    a = -0.8           # Position von Q = (a|0)\n    px, py = 0.5, 0.5  # Position von P = (px|py)\n\n    # Lösung des Billardproblems berechnen\n    sol = set({}) # leere Menge, in der die gefundenen Lösungen gespeichert werden\n    X = [2*math.pi * k / 10 for k in range(10)]  # Liste der Startwerte für Newton\n    for x0 in X:\n        x = newton(f, x0)\n        sol.add(x)\n\n    # Lösungen grafisch darstellen\n    fig = plt.figure()\n    ax = plt.gca()\n    ax.set_xlim((-1.2, 1.2))\n    ax.set_ylim((-1.2, 1.2))\n    ax.set_aspect('equal')\n    circle = plt.Circle((0,0), 1, color='b', fill=False)\n    qBall = plt.Circle((a,0), 0.02, color='k')\n    pBall = plt.Circle([px, py], 0.02, color='k')\n    ax.add_patch(circle)\n    ax.add_patch(qBall)\n    ax.add_patch(pBall)\n    for x in sol:\n        xcoords = [a, math.cos(x), px]\n        ycoords = [0, math.sin(x), py]\n        plt.plot(xcoords, ycoords, linewidth=1, linestyle='--')\n    plt.show()\n\n\n\n\n\nAbbildung 3.1: Lösung des Billardproblems.\n\n\n\n\n\n\n\n\nÜbungsaufgabe 3.7 (Minimaler Abstand) \nLeite das Programm aus Beispiel 1.3 ab. Schreibe danach eine Funktion gradient_descent(f, x0, lam), welche ausnutzt, dass der Funktionsaufruf f(x0) auch den exakten Wert der Ableitung zurückgibt. Stelle die gefundene Lösung grafisch dar.\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\n\nCode\nimport math\nimport matplotlib.pyplot as plt\n\ndef d(t):\n    v0dot = 1                    \n    v0 = t\n    v1dot = -2 * math.sin(v0) * v0dot   # Ableitung von...\n    v1 = 2 * math.cos(v0) - 1    # x-Koordinate von P\n    v2dot = 1.5 * math.cos(v0) * v0dot  # Ableitung von...\n    v2 = 1.5 * math.sin(v0)      # y-Koordinate von P\n    v3dot = 0                    # Ableitung von...\n    v3 = 0                       # z-Koordinate von P\n    v4dot = -6 * math.cos(2*v0) * v0dot # Ableitung von...\n    v4 = -3 * math.sin(2*v0)     # x-Koordinate von Q\n    v5dot = -4 * math.sin(2*v0) * v0dot # Ableitung von...\n    v5 = 2 * math.cos(2*v0) + 1  # y-Koordinate von Q\n    v6dot = 4 * math.cos(2*v0) * v0dot  # Ableitung von...\n    v6 = 2 * math.sin(2*v0) + 1  # z-Koordinate von Q\n    ydot = (2*(v4-v1)*(v4dot-v1dot) + 2*(v5-v2)*(v5dot-v2dot) + 2*(v6-v3)*(v6dot-v3dot)) \\\n         / (2 * math.sqrt((v4-v1)**2 + (v5-v2)**2 + (v6-v3)**2))\n    y = math.sqrt((v4-v1)**2 + (v5-v2)**2 + (v6-v3)**2)\n    return [y, ydot]\n\ndef gradient_descent(f, x0, lam):\n    tol = 1e-9\n    # Erster Schritt berechnen\n    [y0, y0dot] = f(x0)\n    x1 = x0 - lam * y0dot\n    while math.fabs(x1-x0) > tol:\n        x0 = x1\n        [y0, y0dot] = f(x0)\n        x1 = x0 - lam * y0dot\n    return x1\n\nif __name__ == \"__main__\":\n    t0 = 3\n    tmin = gradient_descent(d, t0, 0.01)\n    [dmin, dmindot] = d(tmin)\n    print(\"Minimum bei (\", tmin, dmin, \")\")\n\n    fig = plt.figure()\n    ax = plt.gca()\n    ax.set_xlim((0,2*math.pi))\n    ax.set_ylim((0,6))\n    T = [2*math.pi * k / 1000 for k in range(1001)]\n    Y = [d(t)[0] for t in T]  # nur Funktionswert plotten\n    plt.plot(T,Y)\n    plt.xticks([0, math.pi/2, math.pi, 3*math.pi/2, 2*math.pi],\n               ['0', 'π/2', 'π', '3π/2', '2π'])\n    plt.plot(tmin,dmin,color='r', marker='o')\n    plt.show()      \n\n\nMinimum bei ( 4.712388977478413 1.5 )\n\n\n\n\n\nAbbildung 3.2: Kürzester Abstand mit Gradient Descent.\n\n\n\n\nBeachte, dass beim Zeichnen des Funktionsgraphen neu Y = [d(t)[0] for t in T] steht. Der Grund dafür ist, dass d(t) nun eine Liste mit zwei Elementen ist (Funktionswert und Ableitung) und wir nur den Funktionswert zeichnen wollen. Schreibt man stattdessen Y = [d(t) for t in T], dann wird zusätzlich auch der Graph der Ableitung gezeichnet."
  },
  {
    "objectID": "ADOneDimManually.html#sec-SadImplementationOperatorOverloading",
    "href": "ADOneDimManually.html#sec-SadImplementationOperatorOverloading",
    "title": "3  Standard Algorithmische Differentiation für eindimensionale Funktionen",
    "section": "3.2 Implementation der SAD mit Operator Overloading",
    "text": "3.2 Implementation der SAD mit Operator Overloading\nNach dem letzten Abschnitt könnte man einwenden, dass wir die Ableitungen der Funktionen ja doch von Hand berechnet haben, denn wir haben jede Programmzeile, in der eine Variable v berechnet wird, um eine weitere Zeile ergänzt, in der wir vdot nach den bekannten Ableitungsregeln berechnet haben. Dieser Einwand ist auch berechtigt - oder wie es Henrard ausdrückt:\n\n“The bad news is that it [calculating the derivatives] has to be done; it will not appear magically. It is not only a figure of speech that ‘something has to be done’ but that to have it working everything has to be done”. (Henrard 2017, 17)\n\nDie gute Nachricht ist, dass wir diesen Prozess weiter automatisieren können. Wir kennen die Ableitungsregeln für die elementaren Operationen (+,-,*,/), sowie für die Grundfunktionen. In diesem Abschnitt werden wir eine Klasse FloatSad schreiben, deren Instanzen Funktionswerte und Werte der Ableitung speichern. Da solche Werte in der Regel vom Typ float sind und wir die Standard-AD implementieren, nennen wir die Klasse FloatSad. Die Arbeit besteht dann darin, die Ableitungsregeln richtig in den Operatoren dieser Klasse zu kodieren. Da Python Operator Overloading kennt, werden wir dann nach getaner Arbeit die Ableitungen wirklich ohne zusätzlichen Programmieraufwand erhalten.\nDer Grundstein für unsere Klasse wurde bereits im 19. Jahrhundert gelegt, wie die folgende Infobox zeigt:\n\n\n\n\n\n\nHintergrund: Duale Zahlen\n\n\n\n\n\nDuale Zahlen wurden 1873 durch William Clifford eingeführt und sind ähnlich definiert, wie komplexe Zahlen. Zur Erinnerung: Eine komplexe Zahl ist eine Zahl der Form \\(a + bi\\), wobei \\(a,b \\in \\mathbb{R}\\) sind und \\(i\\) die Eigenschaft \\(i^2 = -1\\) hat. Eine duale Zahl ist eine Zahl der Form \\(a + a'\\epsilon\\), wobei wieder \\(a,a' \\in \\mathbb{R}\\) gilt, aber \\(\\epsilon\\) die Eigenschaft \\(\\epsilon^2 = 0\\) hat. Nun kann man nach dem Permanenzprinzip die folgenden Operationen für duale Zahlen definieren:\n\\[\\begin{alignat*}{3}\n    &\\textrm{Addition:} && (a+a'\\epsilon) + (b+b'\\epsilon) &&= (a+b) + (a'+b')\\epsilon \\\\ \\\\\n    &\\textrm{Subtraktion:} && (a+a'\\epsilon) - (b+b'\\epsilon) &&= (a-b) + (a'-b')\\epsilon \\\\ \\\\\n    &\\textrm{Multiplikation:}\\quad && (a+a'\\epsilon) \\cdot (b+b'\\epsilon) &&= ab + a'b\\epsilon + ab'\\epsilon + a'b'\\epsilon^2 \\\\\n    & && &&= ab + (a'b + ab')\\epsilon \\\\ \\\\\n    &\\textrm{Division:} && (\\textrm{für }b\\ne 0) \\quad \\frac{a+a'\\epsilon}{b+b'\\epsilon} &&= \\frac{(a+a'\\epsilon)(b-b'\\epsilon)}{(b+b'\\epsilon)(b-b'\\epsilon)} \\\\\n    & && &&= \\frac{ab+a'b\\epsilon-ab'\\epsilon-a'b'\\epsilon^2}{b^2 - (b')^2\\epsilon^2} \\\\\n    & && &&= \\frac{ab + (a'b-ab')\\epsilon}{b^2} \\\\\n    & && &&= \\frac{a}{b} + \\frac{a'b - ab'}{b^2} \\epsilon\n\\end{alignat*}\\]\nWir sehen, dass der reelle Teil den Wert der Operation und der duale Teil den Wert der zugehörigen Ableitung enthält. Dies gilt auch für Potenzen, wie man unter Anwendung des binomischen Satzes sieht:\n\\[\\begin{align*}\n    (a+a'\\epsilon)^n &= \\sum_{k=0}^n \\binom n k a^{n-k} (a'\\epsilon)^k  \\\\\n    &= a^n + n \\cdot a^{n-1} \\cdot a'\\epsilon + (\\textrm{Terme mit }\\epsilon^2) \\\\\n    &= a^n + n \\cdot a^{n-1} \\cdot a' \\epsilon\n\\end{align*}\\]\nIm dualen Teil erkennen wir die Kettenregel \\((a^n)' = n\\cdot a^{n-1}\\cdot a'\\). Damit können wir duale Zahlen auch in Polynome \\(p(x) = p_0 + p_1 x + p_2 x^2 + \\ldots + p_n x^n\\) einsetzen. Wir erhalten dann\n\\[\\begin{align*}\n    p(a+a'\\epsilon) &= p_0 + p_1 (a+a'\\epsilon) + p_2 (a+a'\\epsilon)^2 + \\ldots + p_n (a+a'\\epsilon)^n \\\\\n    &= p_0 + p_1 a + p_1 a'\\epsilon + p_2 a^2 + p_2 \\cdot 2a a' \\epsilon + ... + p_n a^n + p_n \\cdot n a^{n-1} a' \\epsilon \\\\\n    &= p_0 + p_1 a + p_2 a^2 + \\ldots p_n a^n + (p_1 + p_2 \\cdot 2a + \\ldots + p_n \\cdot n a^{n-1}) \\cdot a' \\epsilon \\\\\n    &= p(a) + p'(a) \\cdot a'\\epsilon\n\\end{align*}\\]\nDieses Resultat lässt sich auf allgemeine Funktionen \\(f\\) verallgemeinern (für den Beweis entwickelt man \\(f\\) in eine Taylorreihe und macht die gleichen Überlegungen wie für ein Polynom): \\[\nf(a+a'\\epsilon) = f(a) + f'(a)\\cdot a'\\epsilon\n\\]\n(Wikipedia: Dual number und Slater (2022))\n\n\n\n\n3.2.1 Die Klasse FloatSad\nBeginnen wir nun mit der Implementation unserer Klasse FloatSad. Analog zu den dualen Zahlen enthält jedes FloatSad-Objekt zwei Attribute. Das Attribut value speichert den Funktionswert und das Attribut derivative speichert den Wert der Ableitung. Im Konstruktor der Klasse setzen wir für derivative den Standardwert 1. Damit können wir eine gewöhnliche Float-Zahl korrekt in ein FloatSad umwandeln. Dies wird im main Programm demonstriert.\n\n\nCode\nimport math\n\nclass FloatSad:\n\n    def __init__(self, value, derivative = 1.0):\n        self.value = float(value)\n        self.derivative = derivative\n\n\nif __name__ == '__main__':\n\n    def f(x):\n        v0 = FloatSad(x)\n        y = v0\n        return y\n\n    x0 = 2\n    resultat = f(x0)\n    print(\"Funktionswert:\", resultat.value)\n    print(\"Ableitung:\", resultat.derivative)\n\n\nFunktionswert: 2.0\nAbleitung: 1.0\n\n\nIn der Funktion f haben wir nun unsere Konvention, dass v0 = x sein soll, dazu verwendet, den Zahlenwert x in ein FloatSad-Objekt umzuwandeln. Die Konvention v0dot = 1 ist im Konstruktor kodiert. Von nun an machen wir also die folgende Konvention:\n\n\n\n\n\n\nKonvention\n\n\n\nEine Funktion berechnet aus einem Argument x vom Typ float oder int einen Rückgabewert y vom Typ FloatSad über eine Reihe von Hilfsvariablen v, die alle vom Typ FloatSad sind. Insbesondere setzen wir am Anfang immer v0 = FloatSad(x).\n\n\nDas obige Programm berechnet also den Funktionswert und den Wert der Ableitung von \\(f(x) = x\\) an der Stelle \\(x_0 = 2\\).\nUm die Ausgabe etwas einfacher zu gestalten implementieren wir als nächstes die print Methode für unsere Klasse. Wir geben ein FloatSad-Objekt einfach in der Form < value ; derivative > aus.\n\ndef __repr__(self):\n        return \"< \" + str(self.value) + \" ; \" + str(self.derivative) + \" >\"\n\nDa wir nun die Funktion \\(f(x) = x\\) programmieren können, wollen wir als nächstes auch die Funktion \\(f(x) = -x\\) programmieren können. Wir müssen unsere FloatSad-Objekte also mit Vorzeichen versehen.\n\n\n3.2.2 Vorzeichen\nNatürlich wollen wir nicht nur das negative Vorzeichen, sondern auch das positive Vorzeichen implementieren, damit wir in unseren Programmen z.B. v1 = +v0 oder v2 = -v0 schreiben können. Beim positiven Vorzeichen müssen wir nichts machen, wir geben also ein FloatSad-Objekt mit den gleichen Attributen zurück. Beim negativen Vorzeichen ändern beide Attribute ihr Vorzeichen.\n\ndef __pos__(self):\n        return FloatSad(self.value, self.derivative)\n    \ndef __neg__(self):\n    newValue = -self.value\n    newDerivative = -self.derivative\n    return FloatSad(newValue, newDerivative)\n\nNun gehen wir daran, die Grundoperationen für FloatSad-Objekte zu implementieren.\n\n\n3.2.3 Die Operatoren + und -\nWir möchten in unseren Programmen Anweisungen wie v2 = v0 + v1 verwenden können. Gemäss der Summenregel können wir dazu einfach die Funktionswerte und auch die Werte der Ableitungen addieren.\n\ndef __add__(self, other):\n        newValue = self.value + other.value\n        newDerivative = self.derivative + other.derivative\n        return FloatSad(newValue, newDerivative)\n\nNun können wir zwei FloatSad-Objekte miteinander addieren. Manchmal möchten wir aber auch ein float- oder int-Wert zu einem FloatSad-Objekt addieren, z.B. v1 = v0 + 2. Dazu machen wir eine Typabfrage und passen den Wert der Ableitung entsprechend der Konstantenregel an:\n\ndef __add__(self, other):\n    if type(other) in (float, int):\n        newValue = self.value + other\n        newDerivative = self.derivative + 0.0\n    else:\n        newValue = self.value + other.value\n        newDerivative = self.derivative + other.derivative\n    return FloatSad(newValue, newDerivative)\n\nJetzt funktioniert zwar die Anweisung v1 = v0 + 2, aber die Anweisung v1 = 2 + v0 erzeugt immer noch eine Fehlermeldung. Um dieses Problem zu beheben, müssen wir als nächstes den reverse-add-Operator implementieren.\n\ndef __radd__(self, other):\n    if type(other) in (float, int):\n        newValue = other + self.value\n        newDerivative = 0.0 + self.derivative\n    else:\n        newValue = other.value + self.value\n        newDerivative = other.derivative + self.derivative\n    return FloatSad(newValue, newDerivative)\n\nHier ist die bisher implementierte Klasse zusammen mit einem kleinen Testprogramm.\n\n\nCode\nimport math\n\nclass FloatSad:\n\n    def __init__(self, value, derivative = 1.0):\n        self.value = float(value)\n        self.derivative = derivative\n\n    def __repr__(self):\n        return \"< \" + str(self.value) + \" ; \" + str(self.derivative) + \" >\"\n\n\n    # unäre Operatoren\n\n    def __pos__(self):\n        return FloatSad(self.value, self.derivative)\n    \n    def __neg__(self):\n        newValue = -self.value\n        newDerivative = -self.derivative\n        return FloatSad(newValue, newDerivative)\n    \n\n    # binäre Operatoren\n\n    def __add__(self, other):\n        if type(other) in (float, int):\n            newValue = self.value + other\n            newDerivative = self.derivative + 0.0\n        else:\n            newValue = self.value + other.value\n            newDerivative = self.derivative + other.derivative\n        return FloatSad(newValue, newDerivative)\n\n    def __radd__(self, other):\n        if type(other) in (float, int):\n            newValue = other + self.value\n            newDerivative = 0.0 + self.derivative\n        else:\n            newValue = other.value + self.value\n            newDerivative = other.derivative + self.derivative\n        return FloatSad(newValue, newDerivative)\n    \n\n\nif __name__ == '__main__':\n\n    def f(x):\n        v0 = FloatSad(x)\n        v1 = -v0 \n        v2 = 3 + v1\n        v3 = v2 + v1\n        y  = +v3\n        return y\n\n    resultat = f(2)\n    print(resultat)\n\n\n< -1.0 ; -2.0 >\n\n\n\nÜbungsaufgabe 3.8 (Korrektheit überprüfen) \nWelche Funktion berechnet f im main Programm? Stimmt die Ausgabe?\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\nEs handelt sich um die Funktion \\(f(x) = 3 - 2x\\). Die Ausgabe \\(f(2) = -1, f'(2) = -2\\) ist also korrekt.\n\n\n\nFür die nächste Übung musst du das obige Programm kopieren und in einer Datei mit dem Namen floatsad.py abspeichern. Speichere die Datei im gleichen Ordner wie die anderen Dateien.\n\nÜbungsaufgabe 3.9 (Den Operator - implementieren) \nImplementiere auf die gleiche Weise den --Operator. Die Methoden lauten __sub__(self, other) bzw. __rsub__(self, other). Schreibe auch eine Testfunktion f, welche die neuen Operatoren verwendet.\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\n\nCode\ndef __sub__(self, other):\n    if type(other) in (float, int):\n        newValue = self.value - other\n        newDerivative = self.derivative - 0.0\n    else:\n        newValue = self.value - other.value\n        newDerivative = self.derivative - other.derivative\n    return FloatSad(newValue, newDerivative)\n\ndef __rsub__(self, other):\n    if type(other) in (float, int):\n        newValue = other - self.value\n        newDerivative = 0.0 - self.derivative\n    else:\n        newValue = other.value - self.value\n        newDerivative = other.derivative - self.derivative\n    return FloatSad(newValue, newDerivative)\n\n\n\n\n\n\n\n3.2.4 Die Operatoren * und /\nAls nächstes wollen wir die Multiplikation implementieren, um Anweisungen der Form v2 = v0 * v1 ausführen zu können. Dazu müssen wir die Produktregel verwenden. Wie bei der Addition und der Subtraktion soll unser *-Operator aber auch Anweisungen der Form v1 = v0 * 2 oder v1 = -3 * v0 richtig auswerten, bei denen die Faktorregel angewendet wird. Dazu ist wieder eine Typabfrage nötig.\n\nÜbungsaufgabe 3.10 (Den Operator * implementieren) \nErgänze die Datei floatsad.py mit den Methoden __mul__(self, other) und __rmul__(self, other). Überlege dir verschiedene Testfälle und überzeuge dich von der Korrektheit deines Programms.\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\n\nCode\ndef __mul__(self, other):\n    if type(other) in (float, int):\n        newValue = self.value * other\n        newDerivative = self.derivative * other\n    else:\n        newValue = self.value * other.value\n        newDerivative = self.derivative * other.value + self.value * other.derivative\n    return FloatSad(newValue, newDerivative)\n\ndef __rmul__(self, other):\n    if type(other) in (float, int):\n        newValue = other * self.value\n        newDerivative = other * self.derivative\n    else:\n        newValue = other.value * self.value\n        newDerivative =  other.derivative * self.value + other.value * self.derivative\n    return FloatSad(newValue, newDerivative)\n\n\n\n\n\nEs fehlt noch der Divisionsoperator, damit wir Anweisungen wie v2 = v1 / v0 verwenden können. Da wir es bei differenzierbaren Funktionen immer mit float- bzw. FloatSad-Objekten zu tun haben, implementieren wir nur den /-Operator, also die Funktion __truediv__(self, other) und nicht den //-Operator. Wir wollen aber wieder die Fallunterscheidung nach den Typen machen, so dass auch Anweisungen wie v1 = v0 / 4 verwendet werden können. Dabei benötigen wir nur die Faktorregel und nicht die Quotientenregel. Um schliesslich auch noch v1 = -4 / v0 zu ermöglichen, muss noch __rtruediv__(self, other) implementiert werden. Bei letzterem darf nicht vergessen werden, dass auch die Kettenregel benutzt werden muss, denn \\(\\frac{dv_1}{dx} = \\frac{dv_1}{dv_0}\\cdot \\frac{dv_0}{dx} = \\frac{4}{v_0^2}\\cdot v_0'\\). Quadrate kann man mit math.pow(value, 2) berechnen. Bei der Implementierung müssen wir uns übrigens nicht um Fehlerbehandlungen, wie das Abfangen einer Division durch Null, kümmern, weil diese bereits im /-Operator, den wir verwenden, implementiert sind.\n\nÜbungsaufgabe 3.11 (Den Operator / implementieren) \nErgänze die Datei floatsad.py mit den Methoden __truediv__(self, other) und __rtruediv__(self, other). Überlege dir auch wieder verschiedene Testfälle und überzeuge dich von der Korrektheit deines Programms.\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\n\nCode\ndef __truediv__(self, other):\n    if type(other) in (float, int):\n        newValue = self.value / other\n        newDerivative = self.derivative / other\n    else:\n        newValue = self.value / other.value\n        newDerivative = (self.derivative * other.value - self.value * other.derivative) / math.pow(other.value, 2)\n    return FloatSad(newValue, newDerivative)\n\ndef __rtruediv__(self, other):\n    if type(other) in (float, int):\n        newValue = other / self.value\n        newDerivative = - other / math.pow(self.value, 2) * self.derivative\n    else:\n        newValue = other.value / self.value\n        newDerivative = (other.derivative * self.value - other.value * self.derivative) / math.pow(self.value, 2) * self.derivative\n    return FloatSad(newValue, newDerivative)\n\n\n\n\n\n\n\n3.2.5 Der Operator **\nInteressant ist nun die Implementation des Potenzoperators. Hier sind mehrere Fallunterscheidungen nötig.\nBetrachten wir zuerst den Fall, type(other) in (float, int), d.h. wir haben einen Ausdruck der Form v1 = v0 ** 3. In diesem Fall wenden wir die Potenzregel zusammen mit der Kettenregel an.\nIm zweiten Fall haben wir einen Ausdruck wie v3 = v1 ** v2. Wir müssen uns also zuerst überlegen, wie wir einen Ausdruck der Form \\(v_3 (x) = v_1(x) ^{v_2 (x)}\\) überhaupt ableiten. Offenbar muss dazu \\(v_1(x) > 0\\) gelten. Um die Ableitung zu finden wenden wir den Trick an, dass wir die Funktion zuerst logarithmieren, \\[\n\\ln(v_3(x)) = \\ln(v_1(x) ^{v_2 (x)}) = v_2(x) \\cdot \\ln(v_1(x))\n\\] und danach beide Seiten ableiten, wobei wir auf der rechten Seite die Produktregel anwenden: \\[\n\\frac{d}{dx}(\\ln(v_3(x))) = v_2'(x) \\cdot \\ln(v_1(x)) + v_2(x) \\cdot \\frac{1}{v_1(x)} \\cdot v_1'(x)\n\\] Die linke Seite ergibt andererseits \\(\\frac{d}{dx}(\\ln(v_3(x))) = \\frac{1}{v_3(x)}\\cdot v_3'(x)\\), so dass wir nun nach \\(v_3'(x)\\) auflösen können:\n\\[\\begin{align*}\n    v_3'(x) &= v_3(x) \\cdot \\left( v_2'(x) \\cdot \\ln(v_1(x)) + \\frac{v_2(x)}{v_1(x)} \\cdot v_1'(x) \\right) \\\\\n    &= v_1(x) ^{v_2 (x)} \\cdot \\left( \\ln(v_1(x)) \\cdot v_2'(x) + \\frac{v_2(x)}{v_1(x)} \\cdot v_1'(x) \\right)\n\\end{align*}\\]\nAuch hier sind alle nötigen Fehlerbehandlungen bereits in math.pow implementiert.\n\nÜbungsaufgabe 3.12 (Den Operator ** implementieren - Teil 1) \nErgänze die Datei floatsad.py mit der Methode __pow__(self, other). Dabei übernimmt self die Rolle von \\(v_1\\) in der obigen Herleitung und other entspricht \\(v_2\\). Die Funktion \\(\\ln(\\ldots)\\) heisst in Python math.log(). Teste dein Programm an verschiedenen Funktionen.\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\n\nCode\ndef __pow__(self, other):\n    if type(other) in (float, int):\n        newValue = math.pow(self.value, other)\n        newDerivative = other * math.pow(self.value, other - 1) * self.derivative\n    else:\n        newValue = math.pow(self.value, other.value)\n        newDerivative = math.pow(self.value, other.value) * \\\n            (other.derivative * math.log(self.value) + other.value * self.derivative / self.value)\n    return FloatSad(newValue, newDerivative)\n\n\n\n\n\nNun implementieren wir auch noch die Methode __rpow__(self, other). Im Fall, dass type(other) in (float, int) ist, handelt es sich hierbei um eine Exponentialfunktion. math.pow stellt dann sicher, dass die Basis, also other, eine positive Zahl ist. Falls other ebenfalls ein FloatSad ist, dann kann die Ableitung gleich wie oben berechnet werden, ausser, dass jetzt self und other ihre Rollen tauschen.\n\nÜbungsaufgabe 3.13 (Den Operator ** implementieren - Teil 2) \nErgänze die Datei floatsad.py mit der Methode __rpow__(self, other). Teste dein Programm an verschiedenen Funktionen.\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\n\nCode\ndef __rpow__(self, other):\n    if type(other) in (float, int):\n        newValue = math.pow(other, self.value)\n        newDerivative = math.pow(other, self.value) * math.log(other) * self.derivative\n    else:\n        newValue = math.pow(other.value, self.value)\n        newDerivative = math.pow(other.value, self.value) * \\\n            (self.derivative * math.log(other.value) + self.value * other.derivative / other.value)\n    return FloatSad(newValue, newDerivative)\n\n\n\n\n\n\n\n3.2.6 Vergleichsoperatoren\nEs könnte sein, dass wir FloatSad-Objekte auch miteinander vergleichen wollen, also eine der Abfragen aus Tabelle 3.1 machen wollen.\n\n\nTabelle 3.1: Vergleichsoperatoren\n\n\nOperator\nMethode\n\n\n\n\n<\n__lt__(self, other)\n\n\n<=\n__le__(self, other)\n\n\n==\n__eq__(self, other)\n\n\n!=\n__ne__(self, other)\n\n\n>\n__gt__(self, other)\n\n\n>=\n__ge__(self, other)\n\n\n\n\nDazu vergleichen wir jeweils nur die Funktionswerte. Die Implementation sieht dann folgendermassen aus:\n\n\nCode\n# Vergleichsoperatoren \n\ndef __lt__(self, other):\n    if type(other) in (float, int):\n        return self.value < other\n    else:\n        return self.value < other.value\n\ndef __le__(self, other):\n    if type(other) in (float, int):\n        return self.value <= other\n    else:\n        return self.value <= other.value\n\ndef __eq__(self, other):\n    if type(other) in (float, int):\n        return self.value == other\n    else:\n        return self.value == other.value\n\ndef __ne__(self, other):\n    if type(other) in (float, int):\n        return self.value != other\n    else:\n        return self.value != other.value\n\ndef __gt__(self, other):\n    if type(other) in (float, int):\n        return self.value > other\n    else:\n        return self.value > other.value\n\ndef __ge__(self, other):\n    if type(other) in (float, int):\n        return self.value >= other\n    else:\n        return self.value >= other.value"
  },
  {
    "objectID": "ADOneDimManually.html#die-klasse-floatsad-im-einsatz",
    "href": "ADOneDimManually.html#die-klasse-floatsad-im-einsatz",
    "title": "3  Standard Algorithmische Differentiation für eindimensionale Funktionen",
    "section": "3.3 Die Klasse FloatSad im Einsatz",
    "text": "3.3 Die Klasse FloatSad im Einsatz\nFalls im letzten Abschnitt etwas nicht geklappt haben sollte, kann die fertige Klasse FloatSad von hier kopiert werden.\nUm unsere Klasse zu verwenden müssen wir sie jeweils am Anfang mit\n\nfrom floatsad import FloatSad\n\neinbinden.\n\nBeispiel 3.1 (Ein Programm mit FloatSad) \nBetrachte die Funktion aus Beispiel 1.1. Wir übernehmen das Programm und passen lediglich die erste Zeile der Funktion gemäss der Konvention aus Kapitel 3.2.1 an.\n\n\nCode\nfrom floatsad import FloatSad\n\ndef f(x):\n    v0 = FloatSad(x)\n    v1 = 2 + v0\n    v2 = v0 - 3\n    y = v1 * v2\n    return y\n\nx0 = 2\nprint(f(x0))\n\n\n< -4.0 ; 3.0 >\n\n\nDa nun alle Ableitungsregeln in den verwendeten Operatoren integriert sind, können wir sogar auf die Zwischenschritte mit den v verzichten:\n\n\nCode\nfrom floatsad import FloatSad\n\ndef f(x):\n    x = FloatSad(x)\n    y = (2+x) * (x-3)\n    return y\n\nx0 = 2\nprint(f(x0))\n\n\n< -4.0 ; 3.0 >\n\n\n\n\nWir sehen, dass wir also alle unsere Konventionen, die dazu dienten, komplizierte Funktionsausdrücke in ihre Bestandteile zu zerlegen und diese mit den elementaren Ableitungsregeln zu differenzieren, wieder aufgeben können! Der einzige Zusatzaufwand, den wir bei der Programmierung haben, ist das Umwandeln des Arguments x in ein FloatSad-Objekt.\n\nÜbungsaufgabe 3.14 (FloatSad anwenden) \nVereinfache die Lösung von Übungsaufgabe 3.5 mit Hilfe der Klasse FloatSad. Überzeuge dich davon, dass die Ableitungen auch für Programme mit Schleifen korrekt berechnet werden.\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\n\nCode\nfrom floatsad import FloatSad\n\ndef l(x):\n    y = x**2 + 1\n    return y\n\ndef f(x):\n    x = FloatSad(x)\n    for i in range(3):\n        x = l(x)\n    return x\n\nprint(f(1))\n\n\n< 26.0 ; 80.0 >"
  },
  {
    "objectID": "ADOneDimManually.html#das-modul-mathsad",
    "href": "ADOneDimManually.html#das-modul-mathsad",
    "title": "3  Standard Algorithmische Differentiation für eindimensionale Funktionen",
    "section": "3.4 Das Modul mathsad",
    "text": "3.4 Das Modul mathsad\nMit der Klasse FloatSad können wir Funktionswerte und Ableitungen von algebraischen Funktionen bilden. Wir können aber unsere FloatSad-Objekte noch nicht mit den Funktionen aus dem Python-Modul math verwenden, z.B. mit exp oder sin. In diesem Abschnitt wollen wir ein eigenes Modul mathsad schreiben, in dem wir die Funktionen aus Tabelle 3.2 so implementieren, dass wir sie auf FloatSad-Objekte anwenden können.\n\n\nTabelle 3.2: Funktionen des Moduls math (Auswahl)\n\n\nsqrt\nexp\nlog\n\n\nsin\ncos\ntan\n\n\nasin\nacos\natan\n\n\nsinh\ncosh\ntanh\n\n\nasinh\nacosh\natanh\n\n\nfabs\n\n\n\n\n\n\nGemäss der Python-Dokumentation liefert die Funktion math.exp(x) präzisere Werte als math.e ** x oder math.pow(math.e, x). Die Funktion math.log(x) berechnet den Logarithmus zur Basis \\(e\\), man kann ihr aber als zweites Argument auch eine andere Basis übergeben, z.B. math.log(x,b), was dann mit math.log(x)/math.log(b) berechnet wird. Die Funktion math.fabs(x) schliesslich berechnet den Absolutbetrag \\(|x|\\). Ihre Ableitung ist\n\n(math.fabs(v)).derivative = v.derivative if v>=0 else -v.derivative\n\nDie Funktion \\(y=|x|\\) ist an der Stelle \\(x=0\\) eigentlich nicht differenzierbar. Da wir aber nicht Ableitungsfunktionen, sondern nur Werte von Ableitungen an einer bestimmten Stelle berechnen, reicht es, den rechts- oder linksseitigen Grenzwert zurückzugeben, siehe Gander (1992). Wir müssen es dem Benutzer überlassen, das Ergebnis im jeweiligen Kontext korrekt zu interpretieren.\n\n3.4.1 Die Funktion sqrt\nBeginnen wir mit der Implementierung der Wurzelfunktion.\n\n\nCode\nimport math\nfrom floatsad import FloatSad\n\ndef sqrt(x):\n    newValue = math.sqrt(x.value)\n    newDerivative = 1/(2*math.sqrt(x.value)) * x.derivative\n    return FloatSad(newValue, newDerivative)\n\nif __name__ == '__main__':\n\n    def f(x):\n        x = FloatSad(x)\n        y = 1 / sqrt(x**2 + 1)\n        return y\n\n    x0 = -1\n    print(f(x0))\n\n\n< 0.7071067811865475 ; 0.3535533905932737 >\n\n\nWir gehen davon aus, dass x ein FloatSad-Objekt ist. Für den Wert von sqrt(x) verwenden wir einfach die Funktion math.sqrt. Diese enthält auch die nötige Fehlerbehandlung. Zusätzlich berechnen wir aber noch den Wert der Ableitung mit Hilfe der bekannten Ableitungsregel und wie zuvor wenden wir immer die Kettenregel an. Das Programm enthält auch ein Testprogramm, welches die Ableitung der Funktion \\(f(x) = \\frac{1}{\\sqrt{x^2+1}}\\) an der Stelle \\(x_0 = -1\\) berechnet. Zur Kontrolle kann die GeoGebra-Vorlage zu Beginn von Kapitel 3.1 verwendet werden.\n\n\n3.4.2 Die Funktionen exp und log\n\nÜbungsaufgabe 3.15 (Exponentialfunktion) \nKopiere den obigen Code und speichere ihn in einer Datei mit dem Namen mathsad.py. Speichere die Datei im gleichen Ordner wie die anderen Dateien. Ergänze die Datei danach mit der Funktion exp. Wähle eine neue Testfunktion im main, um dich von der Richtigkeit deiner Lösung zu überzeugen.\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\n\nCode\ndef exp(x):\n    newValue = math.exp(x.value)\n    newDerivative = math.exp(x.value) * x.derivative\n    return FloatSad(newValue, newDerivative)\n\n\n\n\n\nFür die Logarithmusfunktion müssen wir uns wieder etwas mehr Gedanken machen. Mit def log(x, b = math.e) kann man der Basis \\(b\\) wie oben beschrieben den Standardwert \\(b=e\\) geben. Solange b vom Typ int oder float ist, kann man einfach die bekannte Ableitungsregel anwenden. Wenn aber b ein FloatSad-Objekt ist, wie z.B. in v3 = math.log(v1, v2), dann müssen wir den Basiswechselsatz \\[\nv_3(x) = \\log_{v_2(x)}(v_1(x)) = \\frac{\\ln(v_1(x))}{\\ln(v_2(x))}\n\\] verwenden und mit der Quotientenregel ableiten.\n\nÜbungsaufgabe 3.16 (Logarithmusfunktion) \nÜberlege dir, wie die Ableitung von \\(v_3(x)\\) aussieht. Ergänze danach die Datei mathsad.py mit der Implementation der Logarithmusfunktion. Überzeuge dich mit einer Testfunktion von der Richtigkeit deines Programms.\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\nDie Ableitung lautet \\[\n\\frac{d}{dx}v_3(x) = \\frac{\\frac{v_1'(x)}{v_1(x)}\\cdot \\ln(v_2(x))-\\ln(v_1(x))\\cdot\\frac{v_2'(x)}{v_2(x)}}{\\ln^2(v_2(x))}\n\\]\n\n\nCode\ndef log(x, b = math.e):\n    if type(b) in (float, int):\n        newValue = math.log(x.value, b)\n        newDerivative = 1 / (x.value * math.log(b)) * x.derivative\n    else:\n        newValue = math.log(x.value, b.value)\n        newDerivative = (x.derivative/x.value * math.log(b.value) - math.log(x.value) * b.derivative / b.value) \\\n            / math.pow(math.log(b.value), 2)\n    return FloatSad(newValue, newDerivative)\n\n\n\n\n\n\n\n3.4.3 Die trigonometrischen Funktionen und ihre Umkehrfunktionen\nBei den trigonometrischen Funktionen und den Arcus Funktionen können wir einfach die bekannten Ableitungsregeln verwenden.\n\nÜbungsaufgabe 3.17 (Trigonometrische Funktionen) \nErgänze die Datei mathsad.py mit den Funktionen sin, cos und tan, sowie den Funktionen asin, acos und atan.\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\nBeachte, dass man für tan einfach \\(\\tan(x)=\\frac{\\sin(x)}{\\cos(x)}\\) verwenden kann, wenn sin und cos bereits implementiert sind.\n\n\nCode\ndef sin(x):\n    newValue = math.sin(x.value)\n    newDerivative = math.cos(x.value) * x.derivative\n    return FloatSad(newValue, newDerivative)\n\ndef cos(x):\n    newValue = math.cos(x.value)\n    newDerivative = -math.sin(x.value) * x.derivative\n    return FloatSad(newValue, newDerivative)\n\ndef tan(x):\n    return sin(x) / cos(x)\n\ndef asin(x):\n    newValue = math.asin(x.value)\n    newDerivative = 1/math.sqrt( 1 - math.pow(x.value, 2)) * x.derivative\n    return FloatSad(newValue, newDerivative)\n\ndef acos(x):\n    newValue = math.acos(x.value)\n    newDerivative = -1/math.sqrt( 1 - math.pow(x.value, 2)) * x.derivative\n    return FloatSad(newValue, newDerivative)\n\ndef atan(x):\n    newValue = math.atan(x.value)\n    newDerivative = 1/(math.pow(x.value, 2) + 1) * x.derivative\n    return FloatSad(newValue, newDerivative) \n\n\n\n\n\n\n\n3.4.4 Die hyperbolischen Funktionen und ihre Umkehrfunktionen\nAuch bei den hyperbolischen Funktionen und den Area Funktionen verwenden wir die bekannten Ableitungsregeln.\n\nÜbungsaufgabe 3.18 (Hyperbolische Funktionen) \nErgänze die Datei mathsad.py mit den Funktionen sinh, cosh und tanh, sowie den Funktionen asinh, acosh und atanh.\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\nWie bei den trigonometrischen Funktionen gilt auch hier \\(\\tanh(x)=\\frac{\\sinh(x)}{\\cosh(x)}\\).\n\n\nCode\ndef sinh(x):\n    newValue = math.sinh(x.value)\n    newDerivative = math.cosh(x.value) * x.derivative\n    return FloatSad(newValue, newDerivative)\n\ndef cosh(x):\n    newValue = math.cosh(x.value)\n    newDerivative = math.sinh(x.value) * x.derivative\n    return FloatSad(newValue, newDerivative)\n\ndef tanh(x):\n    return sinh(x) / cosh(x)\n\ndef asinh(x):\n    newValue = math.asinh(x.value)\n    newDerivative = 1/math.sqrt(math.pow(x.value, 2) + 1) * x.derivative\n    return FloatSad(newValue, newDerivative)\n\ndef acosh(x):\n    newValue = math.acosh(x.value)\n    newDerivative = 1/math.sqrt(math.pow(x.value, 2) - 1) * x.derivative\n    return FloatSad(newValue, newDerivative)\n\ndef atanh(x):\n    newValue = math.atanh(x.value)\n    newDerivative = -1/(math.pow(x.value, 2) - 1) * x.derivative\n    return FloatSad(newValue, newDerivative)\n\n\n\n\n\n\n\n3.4.5 Die Betragsfunktion\nSchliesslich ergänzen wir die Datei mathsad.py noch mit der Funktion fabs wie oben beschrieben:\n\n\nCode\ndef fabs(x):\n    newValue = math.fabs(x.value)\n    newDerivative = x.derivative if x>=0 else -x.derivative\n    return FloatSad(newValue, newDerivative)\n\n\n\nBeispiel 3.2 (Motivation für die Funktion fabs) Dieses Beispiel stammt aus Griewank und Walther (2008), S. 24. Die Funktion \\(f(x) = \\sqrt{x^6} = |x|^3\\) ist auch an der Stelle \\(x_0=0\\) differenzierbar, aber die Wurzelfunktion wie auch die Betragsfunktion sind es nicht. Die folgenden Programme scheitern an dieser Schwierigkeit.\n\n\nCode\nfrom floatsad import FloatSad\n\ndef f(x):\n    x = FloatSad(x)\n    v = x**6\n    y = v**0.5\n    return y\n\nx0 = 0\nprint(f(x0)) # math domain error\n\n\nDer rationale Exponent (Wurzel) führt zu einem Fehler.\n\n\nCode\nfrom floatsad import FloatSad\nimport mathsad\n\ndef g(x):\n    x = FloatSad(x)\n    v = x**6\n    y = mathsad.sqrt(v)\n    return Y\n\nx0 = 0\nprint(g(x0)) # float division by zero\n\n\nDie Auswertung der Ableitung der Wurzelfunktion an der Stelle 0 erzeugt einen Fehler. Mit unserer Funktion fabs erhalten wir jedoch den korrekten Wert:\n\n\nCode\nfrom floatsad import FloatSad\nimport mathsad\n\ndef h(x):\n    x = FloatSad(x)\n    v = mathsad.fabs(x)\n    y = v**3\n    return y\n\nx0 = 0\nprint(h(x0)) # funktioniert\n\n\n< 0.0 ; 0.0 >\n\n\n\n\nDas fertige Modul kann auch von hier kopiert werden."
  },
  {
    "objectID": "ADOneDimManually.html#das-modul-mathsad-im-einsatz",
    "href": "ADOneDimManually.html#das-modul-mathsad-im-einsatz",
    "title": "3  Standard Algorithmische Differentiation für eindimensionale Funktionen",
    "section": "3.5 Das Modul mathsad im Einsatz",
    "text": "3.5 Das Modul mathsad im Einsatz\nNun können wir unser Modul mit\n\nimport mathsad\n\neinbinden und verwenden. Die Funktion aus Übungsaufgabe 3.3 beispielsweise können wir nun direkt hinschreiben:\n\n\nCode\nfrom floatsad import FloatSad\nimport mathsad\n\ndef f(x):\n    x = FloatSad(x)\n    y = mathsad.cos(x**2 + 2) * mathsad.exp(-1/2 * x**2) + 1/x\n    return y\n\nx0 = -2\nprint(f(x0))\n\n\n< -0.3700550823007931 ; -0.14136926695938976 >\n\n\n\nÜbungsaufgabe 3.19 (Verwendung von mathsad) \nVerwende das Modul mathsad, um die Lösung von Übungsaufgabe 3.4 zu vereinfachen. Bestimme die Ableitung von \\(f\\) an der Stelle \\(x_0=\\sqrt{2}\\).\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\n\nCode\nfrom floatsad import FloatSad\nimport math\nimport mathsad\n\ndef f(x):\n    x = FloatSad(x)\n    u = x**2 + 1\n    y = mathsad.log(u) / mathsad.sqrt(u + x)\n    return y\n\nx0 = math.sqrt(2)\nf0 = f(x0)\nprint(f0.derivative)\n\n\n0.22198842685304976\n\n\n\n\n\n\nÜbungsaufgabe 3.20 (Billard-Problem mit mathsad) \nVerwende das Modul mathsad, um die Lösung des Billard-Problems aus Übungsaufgabe 3.6 zu vereinfachen. Programmiere dazu nochmals die Funktion f(x), aber verwende aussagekräfigere Variablen. Weil f nun FloatSad-Objekte zurückgibt, muss auch die Funktion newton(f, x0) angepasst werden. Die Funktion main kann aus der obigen Lösung kopiert werden.\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\nIn der Funktion newton(f, x0) muss lediglich die Berechnung des neuen Näherungswertes angepasst werden durch x1 = x0 - y0.value / y0.derivative.\n\n\nCode\nfrom floatsad import FloatSad\nimport math\nimport mathsad\nimport matplotlib.pyplot as plt\n\ndef f(x):\n    # Parameter a, px, py werden im global space gefunden\n    x = FloatSad(x)\n    Xx, Xy = mathsad.cos(x), mathsad.sin(x) # Koordinaten von X\n    tx, ty = -Xy, Xx                        # Komponenten des Tangentialvektors\n    XPx, XPy = px - Xx, py - Xy             # Komponenten des Vektors XP\n    lXP = mathsad.sqrt(XPx**2 + XPy**2)     # Länge des Vektors XP\n    ePx, ePy = XPx / lXP, XPy / lXP         # Komponenten des Einheitsvektors in Richtung XP\n    XQx, XQy = a - Xx, -Xy                  # Komponenten des Vektors XQ\n    lXQ = mathsad.sqrt(XQx**2 + XQy**2)     # Länge des Vektors XQ\n    eQx, eQy = XQx / lXQ, XQy / lXQ         # Komponenten des Einheitsvektors in Richtung XQ\n    y = (ePx + eQx) * tx + (ePy + eQy) * ty # Skalarprodukt\n    return y\n\ndef newton(f, x0):\n    tol = 1e-8\n    y0 = f(x0)\n    x1 = x0 - y0.value / y0.derivative\n    while math.fabs(x1 - x0) > tol:\n        x0 = x1\n        y0 = f(x0)\n        x1 = x0 - y0.value / y0.derivative\n    return x1\n\nif __name__ == \"__main__\":\n\n    # Parameter definieren\n    a = -0.5          # Position von Q = (a|0)\n    px, py = 0.2, 0.6 # Position von P = (px|py)\n\n    # Lösung des Billardproblems berechnen\n    sol = set({}) # leere Menge, in der die gefundenen Lösungen gespeichert werden\n    X = [2*math.pi * k / 10 for k in range(10)]  # Liste der Startwerte für Newton\n    for x0 in X:\n        x = newton(f, x0)\n        sol.add(x)\n\n    # Lösungen grafisch darstellen\n    fig = plt.figure()\n    ax = plt.gca()\n    ax.set_xlim((-1.2, 1.2))\n    ax.set_ylim((-1.2, 1.2))\n    ax.set_aspect('equal')\n    circle = plt.Circle((0,0), 1, color='b', fill=False)\n    qBall = plt.Circle((a,0), 0.02, color='k')\n    pBall = plt.Circle([px, py], 0.02, color='k')\n    ax.add_patch(circle)\n    ax.add_patch(qBall)\n    ax.add_patch(pBall)\n    for x in sol:\n        xcoords = [a, math.cos(x), px]\n        ycoords = [0, math.sin(x), py]\n        plt.plot(xcoords, ycoords, linewidth=1, linestyle='--')\n    plt.show()\n\n\n\n\n\nAbbildung 3.3: Lösung des Billardproblems mit anderen Startwerten.\n\n\n\n\n\n\n\n\nÜbungsaufgabe 3.21 (Kürzeste Distanz mit mathsad) \nVerwende das Modul mathsad, um die Lösung von Übungsaufgabe 3.7 zu vereinfachen. Weil d nun FloatSad-Objekte zurückgibt, muss auch die Funktion gradient_descent(f, x0, lam) angepasst werden.\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\nIn der Funktion gradient_descent(f, x0, lam) muss lediglich die Berechnung des neuen Näherungswertes angepasst werden. Statt des Graphen wird hier nur das globale Minimum als Punkt ausgegeben.\n\n\nCode\nfrom floatsad import FloatSad\nimport math\nimport mathsad\n\ndef d(t):\n    t = FloatSad(t)\n    Px = 2 * mathsad.cos(t) - 1    # x-Koordinate von P\n    Py = 1.5 * mathsad.sin(t)      # y-Koordinate von P\n    Pz = 0                         # z-Koordinate von P\n    Qx = -3 * mathsad.sin(2*t)     # x-Koordinate von Q\n    Qy = 2 * mathsad.cos(2*t) + 1  # y-Koordinate von Q\n    Qz = 2 * mathsad.sin(2*t) + 1  # z-Koordinate von Q\n    y = mathsad.sqrt((Px-Qx)**2 + (Py-Qy)**2 + (Pz-Qz)**2)\n    return y\n\ndef gradient_descent(f, x0, lam):\n    tol = 1e-9\n    # Erster Schritt berechnen\n    y0 = f(x0)\n    x1 = x0 - lam * y0.derivative\n    while math.fabs(x1-x0) > tol:\n        x0 = x1\n        y0 = f(x0)\n        x1 = x0 - lam * y0.derivative\n    return x1\n\nif __name__ == \"__main__\":\n    t0 = 3\n    tmin = gradient_descent(d, t0, 0.01)\n    dmin = d(tmin)\n    print(\"Minimum bei (\", tmin, dmin.value, \")\")\n\n\nMinimum bei ( 4.712388977478413 1.5 )\n\n\n\n\n\n\n\n\n\nBaydin, Atilim Gunes, Barak A. Pearlmutter, Alexey Andreyevich Radul, und Jeffrey Mark Siskind. 2018. „Automatic Differentiation in Machine Learning: a Survey“. Journal of Machine Learning Research 18 (153): 1–43. http://jmlr.org/papers/v18/17-468.html.\n\n\nGander, Walter. 1992. Computermathematik. Birkhäuser.\n\n\nGriewank, Andreas, und Andrea Walther. 2008. Evaluating Derivatives: Principles and Techniques of Algorithmic Differentiation. 2. Aufl. Other Titles in Applied Mathematics 105. Philadelphia, PA: SIAM. http://bookstore.siam.org/ot105/.\n\n\nHenrard, Marc. 2017. Algorithmic Differentiation in Finance Explained. Financial Engineering Explained. Cham: Palgrave Macmillan. https://doi.org/10.1007/978-3-319-53979-9.\n\n\nSlater, Max. 2022. „Differentiable programming from scratch“. Juli 2022. https://thenumb.at/Autodiff/."
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Arens, Tilo, Frank Hettlich, Christian Karpfinger, Ulrich Kockelkorn,\nKlaus Lichtenegger, and Hellmuth Stachel. 2022. Mathematik.\nBerlin, Heidelberg: Springer Berlin Heidelberg.\n\n\nBaydin, Atilim Gunes, Barak A. Pearlmutter, Alexey Andreyevich Radul,\nand Jeffrey Mark Siskind. 2018. “Automatic Differentiation in\nMachine Learning: A Survey.” Journal of Machine Learning\nResearch 18 (153): 1–43. http://jmlr.org/papers/v18/17-468.html.\n\n\nGander, Walter. 1992. Computermathematik. Birkhäuser.\n\n\n———. 2015. Learning MATLAB: A Problem Solving\nApproach. 1st ed. UNITEXT. Cham, Switzerland: Springer\nInternational Publishing.\n\n\nGriewank, Andreas, and Andrea Walther. 2008. Evaluating Derivatives:\nPrinciples and Techniques of Algorithmic\nDifferentiation. 2nd ed. Other Titles in Applied Mathematics 105.\nPhiladelphia, PA: SIAM. http://bookstore.siam.org/ot105/.\n\n\nHenrard, Marc. 2017. Algorithmic Differentiation in Finance\nExplained. Financial Engineering Explained. Cham: Palgrave\nMacmillan. https://doi.org/10.1007/978-3-319-53979-9.\n\n\nHromkovic, Juraj, Jarka Arnold, Cédric Donner, Urs Hauser, Matthias\nHauswirth, Tobias Kohn, Dennis Komm, David Maletinsky, and Nicole Roth.\n2021. INFORMATIK, Programmieren Und Robotik: Grundlagen\nDer Informatik für Schweizer\nMaturitätsschulen.\n\n\nSlater, Max. 2022. “Differentiable Programming from\nScratch.” July 2022. https://thenumb.at/Autodiff/.\n\n\nWeitz, Edmund. 2021. Konkrete Mathematik (Nicht Nur)\nfür Informatiker. 2nd ed. Wiesbaden, Germany: Springer\nSpektrum."
  },
  {
    "objectID": "HigherDimFunctions.html#funktionen-mathbbrrightarrowmathbbrm",
    "href": "HigherDimFunctions.html#funktionen-mathbbrrightarrowmathbbrm",
    "title": "4  Funktionen mit mehreren In- und Outputs",
    "section": "4.1 Funktionen \\(\\mathbb{R}\\rightarrow\\mathbb{R}^m\\)",
    "text": "4.1 Funktionen \\(\\mathbb{R}\\rightarrow\\mathbb{R}^m\\)\nEine vektorwertige Funktion \\(f : \\mathbb{R}\\rightarrow\\mathbb{R}^m\\) mit\n\\[\nf(t) = \\left( \\begin{align*} y_1 &(t) \\\\ &\\vdots \\\\ y_m &(t) \\end{align*}  \\right)\n\\]\nkann man sich als eine Kurve in einem \\(m\\)-dimensionalen Raum vorstellen. Im Beispiel Beispiel 1.3 wird beispielsweise die Bahn des Punktes \\(Q\\) durch die Funktion\n\\[\nf(t) = \\left( \\begin{align*} -3 &\\sin(2t) \\\\ 2 &\\cos(2t) + 1 \\\\ 2 &\\sin(2t) + 1 \\end{align*}  \\right)\n\\]\nbeschrieben. Die Ableitung einer solchen Funktion wird komponentenweise berechnet und gibt zu einem bestimmten Zeitpunkt \\(t_0\\) den Tangentialvektor im Kurvenpunkt \\(f(t_0)\\) an:\n\\[\ndf(t) = \\left( \\begin{align*} \\dot y_1 &(t) \\\\ &\\vdots \\\\ \\dot y_m &(t) \\end{align*}  \\right)\n\\]\nPhysikalisch entspricht dies dem Geschwindigkeitsvektor zum Zeitpunkt \\(t_0\\).\nAls Programm können wir die obige Kurve so darstellen\n\n\nCode\nimport math\n\ndef f(t):\n    y1 = -3*math.sin(2*t)\n    y2 = 2*math.cos(2*t) + 1\n    y3 = 2*math.sin(2*t) + 1\n    y = [y1, y2, y3]\n    return y\n\nt0 = 2\ny0 = f(t0)\nprint(y0)\n\n\n[2.2704074859237844, -0.3072872417272239, -0.5136049906158564]\n\n\nFür die Ableitung können wir unser Modul FloatSad benutzen. Der Rückgabewert der Funktion ist dann ein Array mit drei FloatSad-Objekten.\n\n\nCode\nfrom floatsad import FloatSad \nimport mathsad\n\ndef f(t):\n    t = FloatSad(t)\n    y1 = -3*mathsad.sin(2*t)\n    y2 = 2*mathsad.cos(2*t) + 1\n    y3 = 2*mathsad.sin(2*t) + 1\n    y = [y1, y2, y3]\n    return y\n\nt0 = 2\ny0 = f(t0)\nprint(\"y1(\" + str(t0) + \") = \" + str(y0[0].value))\nprint(\"y1'(\" + str(t0) + \") = \" + str(y0[0].derivative))\n\n\ny1(2) = 2.2704074859237844\ny1'(2) = 3.921861725181672\n\n\nDiese Implementation hat den Nachteil, dass die Handhabung etwas kompliziert wird. Insbesondere kann man nicht einfach y0.value schreiben, um eine Liste der Funktionswerte zu erhalten. Abhilfe schafft dabei das Modul numpy und die Vektorisierung der Funktion:\n\n\nCode\nfrom floatsad import FloatSad\nimport mathsad\nimport numpy as np\n\n@np.vectorize\ndef f(t):\n    t = FloatSad(t)\n    y1 = -3*mathsad.sin(2*t)\n    y2 = 2*mathsad.cos(2*t) + 1\n    y3 = 2*mathsad.sin(2*t) + 1\n    y = [y1, y2, y3]\n    return y\n\ngetValues = np.vectorize(lambda y : y.value)\ngetDerivatives = np.vectorize(lambda y : y.derivative)\n\nt0 = 2\ny0 = f(t0)\nprint(getValues(y0))\nprint(getDerivatives(y0))\n\n\n[ 2.27040749 -0.30728724 -0.51360499]\n[ 3.92186173  3.02720998 -2.61457448]"
  },
  {
    "objectID": "HigherDimFunctions.html#funktionen-f-mathbbrn-rightarrowmathbbrm",
    "href": "HigherDimFunctions.html#funktionen-f-mathbbrn-rightarrowmathbbrm",
    "title": "4  Funktionen mit mehreren In- und Outputs",
    "section": "4.2 Funktionen \\(f : \\mathbb{R}^n \\rightarrow\\mathbb{R}^m\\)",
    "text": "4.2 Funktionen \\(f : \\mathbb{R}^n \\rightarrow\\mathbb{R}^m\\)"
  },
  {
    "objectID": "HigherDimFunctions.html#funktionen-mit-mehreren-ausgabewerten",
    "href": "HigherDimFunctions.html#funktionen-mit-mehreren-ausgabewerten",
    "title": "4  Funktionen mit mehreren In- und Outputs",
    "section": "4.1 Funktionen mit mehreren Ausgabewerten",
    "text": "4.1 Funktionen mit mehreren Ausgabewerten\nEine vektorwertige Funktion \\(f : \\mathbb{R}\\rightarrow\\mathbb{R}^m\\) mit\n\\[\nf(t) = \\begin{pmatrix} y_1(t) \\\\ \\vdots \\\\ y_m(t) \\end{pmatrix}\n\\]\nkann man sich als eine Kurve in einem \\(m\\)-dimensionalen Raum vorstellen. Im Beispiel Beispiel 1.3 wird beispielsweise die Bahn des Punktes \\(Q\\) durch die Funktion\n\\[\nf(t) = \\left( \\begin{align*} -3 &\\sin(2t) \\\\ 2 &\\cos(2t) + 1 \\\\ 2 &\\sin(2t) + 1 \\end{align*}  \\right)\n\\]\nbeschrieben. Die Ableitung einer solchen Funktion wird komponentenweise berechnet und gibt zu einem bestimmten Zeitpunkt \\(t_0\\) den Tangentialvektor im Kurvenpunkt \\(f(t_0)\\) an:\n\\[\n\\dot{f}(t) = \\begin{pmatrix} \\dot y_1(t) \\\\ \\vdots \\\\ \\dot y_m(t) \\end{pmatrix}\n\\]\nPhysikalisch entspricht dies dem Geschwindigkeitsvektor zum Zeitpunkt \\(t_0\\). Mehr über die Ableitung von Parameterkurven findet man z.B. in Arens u. a. (2022), S. 947.\nAls Programm können wir die obige Kurve so darstellen\n\n\nCode\nimport math\n\ndef f(t):\n    y1 = -3*math.sin(2*t)\n    y2 =  2*math.cos(2*t) + 1\n    y3 =  2*math.sin(2*t) + 1\n    y = [y1, y2, y3]\n    return y\n\nt0 = 2\ny0 = f(t0)\nprint(y0)\n\n\n[2.2704074859237844, -0.3072872417272239, -0.5136049906158564]\n\n\nFür die Ableitung können wir unser Modul FloatSad benutzen. Der Rückgabewert der Funktion ist dann ein Array mit drei FloatSad-Objekten.\n\n\nCode\nfrom floatsad import FloatSad \nimport mathsad\n\ndef f(t):\n    t = FloatSad(t)\n    y1 = -3*mathsad.sin(2*t)\n    y2 =  2*mathsad.cos(2*t) + 1\n    y3 =  2*mathsad.sin(2*t) + 1\n    y = [y1, y2, y3]\n    return y\n\nt0 = 2\ny0 = f(t0)\nprint(\"y1(\" + str(t0) + \") = \" + str(y0[0].value))\nprint(\"y1'(\" + str(t0) + \") = \" + str(y0[0].derivative))\n\n\ny1(2) = 2.2704074859237844\ny1'(2) = 3.921861725181672\n\n\nDiese Implementation hat den Nachteil, dass die Handhabung etwas kompliziert wird. Insbesondere kann man nicht einfach y0.value schreiben, um eine Liste der Funktionswerte zu erhalten. Abhilfe schafft dabei das Modul numpy und die Vektorisierung der Funktion. Wir definieren dann noch zwei Funktionen getValues(y) und getDerivatives(y), welche aus der Liste y von FloatSad-Objekten jeweils die Funktionswerte, respektive die Werte der Ableitungen extrahiert.\n\n\nCode\nfrom floatsad import FloatSad\nimport mathsad\nimport numpy as np\n\ndef f(t):\n    t = FloatSad(t)\n    y1 = -3*mathsad.sin(2*t)\n    y2 =  2*mathsad.cos(2*t) + 1\n    y3 =  2*mathsad.sin(2*t) + 1\n    y = [y1, y2, y3]\n    return y\n\ngetValues = np.vectorize(lambda y : y.value)\ngetDerivatives = np.vectorize(lambda y : y.derivative)\n\nt0 = 2\ny0 = f(t0)\nprint(getValues(y0))\nprint(getDerivatives(y0))\n\n\n[ 2.27040749 -0.30728724 -0.51360499]\n[ 3.92186173  3.02720998 -2.61457448]"
  },
  {
    "objectID": "HigherDimFunctions.html#funktionen-mit-mehreren-eingabewerten",
    "href": "HigherDimFunctions.html#funktionen-mit-mehreren-eingabewerten",
    "title": "4  Funktionen mit mehreren In- und Outputs",
    "section": "4.2 Funktionen mit mehreren Eingabewerten",
    "text": "4.2 Funktionen mit mehreren Eingabewerten\nDie Ableitung einer Funktion \\(f : \\mathbb{R}^n \\rightarrow \\mathbb{R}\\) ist der Gradient\n\\[\n\\nabla f = \\left( \\frac{\\partial f}{\\partial x_1}, \\ldots, \\frac{\\partial f}{\\partial x_n} \\right)\n\\]\nFür weitere Details zum Gradienten sei auf Arens u. a. (2022), S. 870 verwiesen.\n\nBeispiel 4.1 (Eine Funktion mit drei Eingabwerten) \nBetrachte z.B. die Funktion \\(f : \\mathbb{R}^3 \\rightarrow \\mathbb{R}\\)\n\\[\nf(x_0, x_1, x_2) = x_0^2 + 2\\cdot x_0 \\cdot x_1 - \\frac{x_1}{x_2 ^3}\n\\]\nDas folgende Programm berechnet den Funktionswert \\(f(1, 2, 3)=\\frac{133}{27}\\approx 4.9259...\\)\n\n\nCode\ndef f(x):\n    y = x[0]**2 + 2*x[0]*x[1] - x[1]/x[2]**3\n    return y\n\nx0 = [1, 2, 3]\ny0 = f(x0)\nprint(y0)\n\n\n4.925925925925926\n\n\nDer Gradient dieser Funktion ist \\[\n\\nabla f = \\left( 2x_0+2x_1, 2x_0 - \\frac{1}{x_2^3}, 3\\frac{x_1}{x_2^4} \\right)\n\\]\nbzw. ausgewertet an der Stelle \\((x_0, x_1, x_2) = (1, 2, 3)\\) \\[\n\\begin{align*}\n\\nabla f \\vert _{(1, 2, 3)} &= \\left( 6, \\frac{53}{27}, \\frac2{27} \\right) \\\\\n&\\approx \\left( 6, 1.9629..., 0.0740... \\right)\n\\end{align*}\n\\]\n\n\nMit der Standard Algorithmischen Differentiation kann der Gradient nicht in einem Durchgang berechnet werden. Bei der Umwandlung der Anfangswerte in FloatSad-Objekte müssen wir für allen Variablen in \\(x = (x_1, \\ldots, x_n)\\) einen Anfangswert \\(\\dot{x} = (\\dot{x_1}, \\ldots, \\dot{x_n})\\) geben. Wenn wir für die Initialisierung \\(\\dot{x} = e_i = (0, \\ldots, 1, \\ldots, 0)\\) verwenden (mit \\(1\\) an der \\(i\\)-ten Stelle und sonst lauter \\(0\\)), dann bekommen wir den Wert von \\(\\frac{\\partial f}{\\partial x_i}\\).\nUm die Funktion im obigen Beispiel mit unserer Klasse FloatSad abzuleiten, verwenden wir wieder numpy und die Vektorisierungsfunktionen. Als erstes definieren wir eine Funktion float2FloatSad, mit der wir aus der Liste x eine Liste von FloatSad-Objekten erzeugen. Die Werte der Ableitungen werden zu Beginn explizit in der Variablen xdot initialisiert.\n\nAbleitung nach x0Ableitung nach x1Ableitung nach x2\n\n\n\n\nCode\nfrom floatsad import FloatSad\nimport numpy as np\n\ndef f(x):\n    xdot = [1, 0, 0]\n    x = float2FloatSad(x, xdot)\n    y = x[0]**2 + 2*x[0]*x[1] - x[1]/x[2]**3\n    return y\n\nfloat2FloatSad = np.vectorize(lambda x, v : FloatSad(x,v))\n\nx0 = [1, 2, 3]\ny0 = f(x0)\nprint(y0)\n\n\n< 4.925925925925926 ; 6.0 >\n\n\n\n\n\n\nCode\nfrom floatsad import FloatSad\nimport numpy as np\n\ndef f(x):\n    xdot = [0, 1, 0]\n    x = float2FloatSad(x, xdot)\n    y = x[0]**2 + 2*x[0]*x[1] - x[1]/x[2]**3\n    return y\n\nfloat2FloatSad = np.vectorize(lambda x, v : FloatSad(x,v))\n\nx0 = [1, 2, 3]\ny0 = f(x0)\nprint(y0)\n\n\n< 4.925925925925926 ; 1.962962962962963 >\n\n\n\n\n\n\nCode\nfrom floatsad import FloatSad\nimport numpy as np\n\ndef f(x):\n    xdot = [0, 0, 1]\n    x = float2FloatSad(x, xdot)\n    y = x[0]**2 + 2*x[0]*x[1] - x[1]/x[2]**3\n    return y\n\nfloat2FloatSad = np.vectorize(lambda x, v : FloatSad(x,v))\n\nx0 = [1, 2, 3]\ny0 = f(x0)\nprint(y0)\n\n\n< 4.925925925925926 ; 0.07407407407407407 >\n\n\n\n\n\nInitialisiert man die Ableitungen beispielsweise mit xdot = [1, 1, 1], dann erhält man die Summe der drei Richtungsableitungen:\n\n\n< 4.925925925925926 ; 8.037037037037036 >\n\n\nAllgemein gilt: Initialisiert man xdot mit dem Vektor \\(r = (r_1, \\ldots, r_n)^\\intercal\\), dann erhält man das Skalarprodukt \\[\n\\nabla f \\cdot r =\n\\left ( \\left .\\frac{\\partial f}{\\partial x_1} \\right \\vert_{(x_1, \\ldots, x_n)}, \\ldots, \\left .\\frac{\\partial f}{\\partial x_n} \\right \\vert_{(x_1, \\ldots, x_n)}  \\right ) \\cdot \\begin{pmatrix} r_1 \\\\ \\vdots \\\\ r_n \\end{pmatrix}\n\\]"
  },
  {
    "objectID": "HigherDimFunctions.html",
    "href": "HigherDimFunctions.html",
    "title": "4  Funktionen mit mehreren In- und Outputs",
    "section": "",
    "text": "5 Funktionen mit mehreren Ein- und Ausgabewerten\nEine Funktion \\(f : \\mathbb{R}^n \\rightarrow \\mathbb{R}^m\\) hat die Form \\[\nf(x_1, \\ldots, x_n) = \\left( \\begin{align*} y_1(x_1, &\\ldots, x_n) \\\\ &\\vdots \\\\ y_m(x_1, &\\ldots, x_n) \\end{align*} \\right)\n\\] Die Ableitung einer solchen Funktion wird durch die Jakobi Matrix \\[\nJf = \\begin{pmatrix}\n\\frac{\\partial y_1}{\\partial x_1} & \\ldots & \\frac{\\partial y_1}{\\partial x_n} \\\\\n\\vdots & & \\vdots \\\\\n\\frac{\\partial y_m}{\\partial x_1} & \\ldots & \\frac{\\partial y_m}{\\partial x_n}\n\\end{pmatrix}\n\\]"
  },
  {
    "objectID": "HigherDimFunctions.html#funktionen-mit-mehreren-ein--und-ausgabewerten",
    "href": "HigherDimFunctions.html#funktionen-mit-mehreren-ein--und-ausgabewerten",
    "title": "4  Funktionen mit mehreren In- und Outputs",
    "section": "4.3 Funktionen mit mehreren Ein- und Ausgabewerten",
    "text": "4.3 Funktionen mit mehreren Ein- und Ausgabewerten\nEine Funktion \\(f : \\mathbb{R}^n \\rightarrow \\mathbb{R}^m\\) hat die Form \\[\nf(x_1, \\ldots, x_n) = \\left( \\begin{align*} y_1(x_1, &\\ldots, x_n) \\\\ &\\vdots \\\\ y_m(x_1, &\\ldots, x_n) \\end{align*} \\right)\n\\] Die Ableitung einer solchen Funktion wird durch die Jacobi Matrix \\[\nJf = \\begin{pmatrix}\n    \\frac{\\partial y_1}{\\partial x_1} & \\ldots & \\frac{\\partial y_1}{\\partial x_n} \\\\\n    \\vdots & & \\vdots \\\\\n    \\frac{\\partial y_m}{\\partial x_1} & \\ldots & \\frac{\\partial y_m}{\\partial x_n}\n\\end{pmatrix}\n\\in\\mathbb{R}^{m\\times n}\n\\] gegeben. Auch hierzu findet der Leser mehr Informationen in Arens u. a. (2022), S. 878.\n\nBeispiel 4.2 (Eine Funktion mit zwei Ein- und 3 Ausgabwerten) \nBetrachte die Funktion \\(f : \\mathbb{R}^2 \\rightarrow \\mathbb{R}^3\\) \\[\nf(x_0, x_1) =\n    \\begin{pmatrix}\n        x_0\\cdot \\sqrt{x_1} + 3x_1 \\\\\n        \\cos(x_0) / x_1 \\\\\n        e^{x_0 ^2\\cdot x_1}\n    \\end{pmatrix}\n\\]\nDie Jacobi Matrix lautet in diesem Fall \\[\nJf =\n\\begin{pmatrix}\n    \\sqrt{x_1} & \\frac{x_0}{2\\sqrt{x_1}} + 3 \\\\\n    -\\frac{\\sin(x_0)}{x_1} & -\\frac{\\cos(x_0)}{x_1^2} \\\\\n    e^{x_0^2\\cdot x_1}\\cdot 2 x_0 x_1 & e^{x_0^2\\cdot x_1}\\cdot x_0^2\n\\end{pmatrix}\n\\]\nAusgewertet an der Stelle \\((x_0, x_1) = (2, 1)\\) ergibt dies \\[\nf(2,1) \\approx \\begin{pmatrix} 5 \\\\ -0.4161... \\\\ 54.5981... \\end{pmatrix}, \\qquad\nJF \\vert _{(2,1)} \\approx\n    \\begin{pmatrix}  \n        1 & 4 \\\\\n        -0.9092... & 0.4161... \\\\\n        218.3926... & 218.3926...\n    \\end{pmatrix}\n\\]\n\n\nUm die Funktion aus dem Beispiel mit SAD abzuleiten kombinieren wir die Techniken aus den beiden vorherigen Abschnitten. Je nach Initialisierung von xdot erhalten wir die erste oder die zweite Spalte von \\(JF\\).\n\n1. Spalte2. Spalte\n\n\n\n\nCode\nfrom floatsad import FloatSad\nimport mathsad\nimport numpy as np\n\ndef f(x):\n    xdot = [1, 0]\n    x = float2FloatSad(x, xdot)\n    y1 = x[0]*mathsad.sqrt(x[1]) + 3*x[1]\n    y2 = mathsad.cos(x[0]) / x[1]\n    y3 = mathsad.exp(x[0]**2 * x[1])\n    return [y1, y2, y3]    \n\n\nfloat2FloatSad = np.vectorize(lambda x, v : FloatSad(x,v))\ngetValues = np.vectorize(lambda y : y.value)\ngetDerivatives = np.vectorize(lambda y : y.derivative)\n\n\nx0 = (2, 1)\ny0 = f(x0)\nprint(\"Funktionswerte:\")\nprint(getValues(y0))\nprint(\"1. Spalte von Jf:\")\nprint(getDerivatives(y0))\n\n\nFunktionswerte:\n[ 5.         -0.41614684 54.59815003]\n1. Spalte von Jf:\n[  1.          -0.90929743 218.39260013]\n\n\n\n\n\n\nCode\nfrom floatsad import FloatSad\nimport mathsad\nimport numpy as np\n\ndef f(x):\n    xdot = [0, 1]\n    x = float2FloatSad(x, xdot)\n    y1 = x[0]*mathsad.sqrt(x[1]) + 3*x[1]\n    y2 = mathsad.cos(x[0]) / x[1]\n    y3 = mathsad.exp(x[0]**2 * x[1])\n    return [y1, y2, y3]    \n\n\nfloat2FloatSad = np.vectorize(lambda x, v : FloatSad(x,v))\ngetValues = np.vectorize(lambda y : y.value)\ngetDerivatives = np.vectorize(lambda y : y.derivative)\n\n\nx0 = (2, 1)\ny0 = f(x0)\nprint(\"Funktionswerte:\")\nprint(getValues(y0))\nprint(\"2. Spalte von Jf:\")\nprint(getDerivatives(y0))\n\n\nFunktionswerte:\n[ 5.         -0.41614684 54.59815003]\n2. Spalte von Jf:\n[  4.           0.41614684 218.39260013]\n\n\n\n\n\nInitialisiert man allgemein xdot mit dem Vektor \\(r = (r_1, \\ldots, r_n)^\\intercal\\), dann erhält man als Resultat das Produkt \\[\nJf \\cdot r =\n\\begin{pmatrix}\n    \\frac{\\partial y_1}{\\partial x_1} & \\ldots & \\frac{\\partial y_1}{\\partial x_n} \\\\\n    \\vdots & & \\vdots \\\\\n    \\frac{\\partial y_m}{\\partial x_1} & \\ldots & \\frac{\\partial y_m}{\\partial x_n}\n\\end{pmatrix}\n\\cdot \\begin{pmatrix} r_1 \\\\ \\vdots \\\\ r_n \\end{pmatrix}\n\\]\nBraucht man die gesammte Jacobi Matrix, dann muss man also die Funktion so oft aufrufen, wie die Matrix Spalten hat, d.h. len(x) Mal. Die SAD Methode ist also effizient, wenn eine Funktion mehr Aus- als Eingabewerte hat. Der ineffizienteste Fall tritt auf, wenn die Funktion aus vielen Eingabewerte nur einen Ausgabewert berechnet. Mit anderen Worten: Das Bestimmen des Gradienten einer Funktion \\(f: \\mathbb{R}^n \\rightarrow \\mathbb{R}\\) benötigt den grössten Aufwand gemessen an der Anzahl zu berechnender Werte. Abhilfe schafft in so einem Fall die Adjungierte Automatische Differentiation (AAD).\n\n\n\n\nArens, Tilo, Frank Hettlich, Christian Karpfinger, Ulrich Kockelkorn, Klaus Lichtenegger, und Hellmuth Stachel. 2022. Mathematik. Berlin, Heidelberg: Springer Berlin Heidelberg."
  }
]
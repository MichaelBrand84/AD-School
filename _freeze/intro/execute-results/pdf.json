{
  "hash": "26c453dc09e16bfbfdd75b16ba19456a",
  "result": {
    "markdown": "---\ntbl-cap-location: bottom\n---\n\n# Ableitungen und ihre Anwendungen\n\n## Ableitungen von Funktionen\n\nWir kennen Ableitungen von Funktionen $f: \\mathbb{R}\\rightarrow\\mathbb{R}$ aus dem Mathematikunterricht. Sie geben uns darüber Auskunft, wie gross die Steigung der Tangente in einem bestimmten Punkt des Funktionsgraphen ist. Die Tangente stellt dabei die beste lineare Annäherung an den Funktionsgraph dar. Ableitungen beschreiben auch die lokale Änderungsrate der Funktion. Ableitungen erlauben es uns ausserdem, die Extrema und Wendepunkte einer Funktion zu bestimmen. \n\nDie folgende Tabelle fasst die bekannten Ableitungen der Grundfunktionen zusammen.\n\n| $f(x)$                    | $f'(x)$                                 |     | $f(x)$                 | $f'(x)$                                       |\n|---------------------------|-----------------------------------------|-----|------------------------|-----------------------------------------------|\n| $x^n$                     | $n \\cdot x^n \\quad (n\\in\\mathbb{R})$    |     | $\\sqrt{x}$             | $\\frac{1}{2\\cdot\\sqrt{x}}$                    |\n| $e^x$                     | $e^x$                                   |     | $a^x$                  | $a^x \\cdot \\ln(a) \\quad (a>0, a\\ne 1)$        |\n| $\\ln(x)$                  | $\\frac{1}{x}$                           |     | $\\log_a(x)$            | $\\frac{1}{x\\cdot\\ln(a)} \\quad (a>0, a\\ne 1)$  |\n| $\\sin(x)$                 | $\\cos(x)$                               |     | $\\arcsin(x)$           | $\\frac{1}{\\sqrt{1-x^2}}$                      |\n| $\\cos(x)$                 | $-\\sin(x)$                              |     | $\\arccos(x)$           | $-\\frac{1}{\\sqrt{1-x^2}}$                     |\n| $\\tan(x)$                 | $\\frac{1}{\\cos^2(x)} = 1 + \\tan^2(x)$   |     | $\\arctan(x)$           | $\\frac{1}{x^2+1}$                             |\n| $\\sinh(x)$                | $\\cosh(x)$                              |     | $\\textrm{arsinh}(x)$   | $\\frac{1}{\\sqrt{x^2+1}}$                      |\n| $\\cosh(x)$                | $\\sinh(x)$                              |     | $\\textrm{arcosh(x)}$   | $\\frac{1}{\\sqrt{x^2-1}}$                      |\n| $\\tanh(x)$                | $\\frac{1}{\\cosh^2(x)} = 1 - \\tanh^2(x)$ |     | $\\textrm{artanh(x)}$   | $-\\frac{1}{x^2-1}$                            |\n\n: Ableitungen der Grundfunktionen {#tbl-DiffGrundfunktionen}\n\nNeue Funktionen erhält man, indem man die Grundfunktionen aus @tbl-DiffGrundfunktionen addiert, subtrahiert, multipliziert, dividiert und komponiert, d.h. Verkettungen der Form $(f\\circ g)(x) = f(g(x))$ bildet. Um solche Funktionen abzuleiten, brauchen wir die Regeln aus @tbl-DiffRegeln. Mit diesen Regeln sind wir dann schon in der Lage, alle differenzierbaren Funktionen abzuleiten.\n\n|     |     |\n| --- | --- |\n| Summenregel     | $\\frac{d}{dx}(f(x)\\pm g(x)) = f'(x) \\pm g'(x)$ |\n| Produktregel <br> *Spezialfall: Faktorregel*    | $\\frac{d}{dx}(f(x)\\cdot g(x)) = f'(x)\\cdot g(x) + f(x) \\cdot g'(x)$ <br> $\\frac{d}{dx}(a\\cdot f(x)) = a\\cdot f'(x)$ |\n| Quotientenregel | $\\frac{d}{dx}\\frac{f(x)}{g(x)} = \\frac{f'(x)\\cdot g(x) - f(x) \\cdot g'(x)}{g(x)^2}$  |\n| Kettenregel     | $\\frac{d}{dx} f(g(x)) = f'(g(x))\\cdot g'(x)$  |\n\n: Ableitungsregeln {#tbl-DiffRegeln}\n\nAn dieser Stelle sei noch angemerkt, dass sich der Begriff der Ableitung sinngemäss auf Funktionen $f: \\mathbb{R}^n \\rightarrow\\mathbb{R}^m$ verallgemeinern lässt. Eine kurze Beschreibung der Grundidee findet sich in @Slater2022. Weitergehende Informationen findet man z.B. in @Arens2022 oder in jedem Lehrbuch zur Analysis 2.\n\n\n## Programme als Funktionen {#sec-ProgFunc}\n\nProgramme, die numerische Werte einlesen und numerische Werte ausgeben, können als mathematische Funktionen betrachtet werden. Wir beschränken uns zunächst auf Programme, die nur ein Argument erhalten und nur einen Rückgabewert liefern.\n\n:::{#exm-FirstFunctionAsProgram}\n\n## Eine Funktion als Programm\n<br>\n\n::: {.cell execution_count=1}\n``` {.python .cell-code code-fold=\"false\"}\ndef f(x):\n    y = (2 + x) * (x - 3)\n    return y\n\nx0 = 2\nprint( f(x0) )\n```\n:::\n\n\nDiese Python-Funktion entspricht der Funktion $f:\\mathbb{R}\\rightarrow\\mathbb{R} , x \\mapsto y=(2+x)(x-3)$ im Sinne der Mathematik. Natürlich kann der Funktionskörper viel komplizierter aufgebaut sein und z.B. Schleifen und Bedingungen enthalten. \n\nUm zu verstehen, wie der Computer einen Ausdruck wie `y = (2 + x) * (x - 3)` auswertet, ist es hilfreich, ihn als Baum (im Sinne der Graphentheorie) darzustellen. Ausdrucksbäume sind ein Spezialfall von so genannten *computational graphs* und werden z.B. in @Hromkovic2021 erklärt.\n\n\n```{dot}\n//| label: fig-compTreeSimple\n//| fig-cap: Ausdrucksbaum zum Ausdruck `y = (2 + x) * (x - 3)`.\ndigraph \"\" {\n    rankdir=BT\n    fontname=\"Consolas\"\n    node [fontname=\"Consolas\", fontsize=8, width=\".2\", height=\".2\", margin=.02]\n    edge [fontname=\"Consolas\", fontsize=8, arrowsize=0.5, len=minlen]\n    graph[fontsize=8];\n\n\n    nx [label = \"x\", shape = none];\n    n2 [label = \"2\", shape = none];\n    n3 [label = \"3\", shape = none];\n    nPlus [label = \"+\", shape = circle];\n    nMinus [label = \"-\", shape = circle];\n    nMult [label = \"*\", shape = circle];\n    ny [label = \"y\", shape = none];\n\n    n2 -> nPlus;\n    nx -> nPlus;\n    nx -> nMinus;\n    n3 -> nMinus;\n    nPlus -> nMult;\n    nMinus -> nMult;\n    nMult -> ny;\n\n}\n```\n\n\nWir wollen nun unsere Python-Funktion so umschreiben, dass diese Struktur auch im Funktionskörper sichtbar wird. Dazu führen wir drei Hilfsvariablen `v0, v1, v2` ein.\n\n::: {.cell execution_count=2}\n``` {.python .cell-code code-fold=\"false\"}\ndef f(x):\n    v0 = x\n    v1 = 2 + v0\n    v2 = v0 - 3\n    y = v1 * v2\n    return y\n```\n:::\n\n\n:::\n\n---\n\n:::{.callout-important}\n\n## Konvention\n\nEine Funktion berechnet aus einem Argument `x` einen Rückgabewert `y` über eine Reihe von Hilfsvariablen `v`, die mit aufsteigenden Indizes versehen sind. Dabei setzen wir am Anfang immer `v0 = x`.\n\n:::\n\n:::{#exr-ProgToFun}\n\n## Programm in Funktion übersetzen\n<br>\n\nSchreibe die mathematische Funktion auf, die durch das folgende Programm berechnet wird.\n\n::: {.cell execution_count=3}\n``` {.python .cell-code code-fold=\"false\"}\nimport math\n\ndef f(x):\n    v0 = x\n    v1 = v0 ** 2\n    v2 = v1 + 2\n    v3 = -v1 / 2\n    v4 = math.cos(v2)\n    v5 = math.exp(v3)\n    v6 = v4 * v5\n    y = v6 + 1 / v0\n    return y \n```\n:::\n\n\n:::\n\n:::{.callout-tip collapse=\"true\"}\n\n## Lösung\n\n\\begin{align}\nv_1 & = x^2 \\\\\nv_2 & = x^2 + 2 \\\\\nv_3 & = - \\frac{x^2}{2} \\\\\nv_4 & = \\cos(x^2 + 2) \\\\\nv_5 & = e^{- \\frac{x^2}{2}} \\\\\nv_6 & = \\cos(x^2 + 2) \\cdot e^{- \\frac{x^2}{2}} \\\\\ny & = f(x) = \\cos(x^2 + 2) \\cdot e^{- \\frac{x^2}{2}} + \\frac{1}{x}\n\\end{align}\n\n:::\n\n:::{#exr-FunToGraphProg}\n\n## Funktion in Graph und Programm übersetzen\n<br>\n\nSchreibe zur mathematischen Funktion $y = f(x) = \\frac{\\ln(x^2 + 1)}{\\sqrt{x^2 + 1 + x}}$ den Ausdrucksbaum auf.\nÜbersetze den Ausdruck anschliessend in eine Python-Funktion gemäss der Konvention.\n\n:::\n\n:::{.callout-tip collapse=\"true\"}\n\n## Lösung\n\n```{dot}\n//| label: fig-compTreeSimple\n//| fig-cap: Computational Graph zum Ausdruck `y = ln(x^2 + 1) / sqrt(x^2 + 1 + x)`.\ndigraph \"\" {\n    rankdir=LR\n    fontname=\"Consolas\"\n    node [fontname=\"Consolas\", fontsize=8, width=\".2\", height=\".2\", margin=.02]\n    edge [fontname=\"Consolas\", fontsize=8, arrowsize=0.5, len=minlen]\n    graph[fontsize=8];\n\n\n    nx [label = \"x\", shape = none];\n    n2 [label = \"2\", shape = none];\n    n1 [label = \"1\", shape = none];\n    nPlus1 [label = \"+\", shape = circle];\n    nPlus2 [label = \"+\", shape = circle];\n    nPow [label = \"^\", shape = circle];\n    nFrac [label = \"/\", shape = circle];\n    nLog [label = \"ln( )\", shape = circle];\n    nSqrt [label = \"sqrt( )\", shape = circle];\n    ny [label = \"y\", shape = none];\n\n    nx -> nPow;\n    n2 -> nPow;\n    nPow -> nPlus1;\n    n1 -> nPlus1;\n    nx -> nPlus2;\n    nPlus1 -> nPlus2;\n    nPlus1 -> nLog;\n    nPlus2 -> nSqrt;\n    nLog -> nFrac;\n    nSqrt -> nFrac;\n    nFrac -> ny;\n}\n```\n\n::: {.cell execution_count=4}\n``` {.python .cell-code}\nimport math\n\ndef f(x):\n    v0 = x\n    v1 = v0 ** 2\n    v2 = v1 + 1\n    v3 = v2 + v0\n    v4 = math.log(v2)\n    v5 = math.sqrt(v3)\n    y = v4 / v5\n    return y\n```\n:::\n\n\nNatürlich hätte man z.B. `v3` und `v4` auch vertauschen können. \n\n:::\n\n:::{#exr-LoopProgToFun}\n\n## Ein Programm mit einer Schleife\n<br>\n\nBetrachte das folgende Programm:\n\n::: {.cell execution_count=5}\n``` {.python .cell-code code-fold=\"false\"}\ndef f(x):\n    v0 = x\n    for i in range(2):\n        v0 = v0 ** 2 + 1\n    y = v0\n    return y\n```\n:::\n\n\nErsetze im Funktionskörper die Schleife durch mehrere Befehle, so dass immer noch der gleiche mathematische Ausdruck berechnet wird und unsere Konvention eingehalten wird. Welche mathematische Funktion wird durch die Python-Funktion berechnet?\nWas ändert sich, wenn stattdessen `for i in range(3)` oder `for i in range(4)` stehen würde? \n\n:::\n\n:::{.callout-tip collapse=\"true\"}\n\n## Lösung\n\nFür jeden Schleifendurchgang benötigen wir eine neue Hilfsvariable. Die Funktion, die dabei entsteht, kann geschrieben werden als $f(x) = (\\ell \\circ \\ell \\circ \\ldots \\circ \\ell)(x)$, wobei $\\ell(x) = x^2 + 1$ ist.\n\n::::{.panel-tabset}\n\n## `range(2)`\n\n::: {.cell execution_count=6}\n``` {.python .cell-code code-fold=\"false\"}\ndef f(x):\n    v0 = x\n    v1 = v0 ** 2 + 1\n    v2 = v1 ** 2 + 1\n    y = v2\n    return y\n```\n:::\n\n\n\\begin{align}\n    f(x) &= \\ell(\\ell(x)) \\\\ \n         &= (x^2 + 1)^2 + 1 = x^4 + 2x^2 + 2\n\\end{align}\n\n## `range(3)`\n\n::: {.cell execution_count=7}\n``` {.python .cell-code code-fold=\"false\"}\ndef f(x):\n    v0 = x\n    v1 = v0 ** 2 + 1\n    v2 = v1 ** 2 + 1\n    v3 = v2 ** 2 + 1\n    y = v3\n    return y\n```\n:::\n\n\n\\begin{align}\n    f(x) &= \\ell(\\ell(\\ell(x))) \\\\\n         &= ((x^2 + 1)^2 + 1)^2 + 1 = x^8 + 4x^6 + 8x^4 + 8x^2 + 5\n\\end{align}\n\n## `range(4)`\n\n::: {.cell execution_count=8}\n``` {.python .cell-code code-fold=\"false\"}\ndef f(x):\n    v0 = x\n    v1 = v0 ** 2 + 1\n    v2 = v1 ** 2 + 1\n    v3 = v2 ** 2 + 1\n    v4 = v3 ** 2 + 1\n    y = v4\n    return y\n```\n:::\n\n\n\\begin{align}\n    f(x) &= \\ell(\\ell(\\ell(\\ell(x)))) \\\\\n         &= (((x^2 + 1)^2 + 1)^2 + 1)^2 + 1 \\\\\n         &= x^{16} + 8x^{14} + 32x^{12} + 80x^{10} + 138x^8 + 168x^6 + 144x^4 + 80x^2 + 26\n\\end{align}\n\n::::\n\n:::\n\n\n\n## Unser Ziel: Programme ableiten\n\nWie eingangs erwähnt wurde, haben Ableitungen viele nützliche Anwendungen. \n\nWir möchten nun Ableitungen von Funktionen berechnen, die durch Programme beschrieben werden, die wie oben einen numerischen Parameter `x` als Input erhalten und einen numerischen Wert `y` zurückliefern. Unser Ziel wird es sein, die Programme so zu modifizieren, dass der Funktionsaufruf `f(x0)` nicht nur den Funktionswert $f(x_0)$ zurückgibt, sondern auch den Wert der Ableitung $f'(x_0)$. Wir sind dabei nicht an einer symbolischen Ableitung interessiert, wie das z.B. GeoGebra oder Mathematica machen (s. @sec-ADnotSymbDiff), sondern nur an einer punktweisen Auswertung. Natürlich wollen wir die Ableitungsfunktion auch nicht von Hand bestimmen. Wir wollen uns aber auch nicht bloss mit einer Annhäerung des Wertes der Ableitung zufrieden geben (s. @sec-ADnotNumDiff), sondern den Wert von $f'(x_0)$ bis auf Maschinengenauigkeit exakt berechnen. In @sec-SADforOneDimFunctions werden wir eine Methode kennen lernen, die all dies leistet und dabei die Laufzeit eines Programms nicht wesentlich erhöht. Der Name dieser Methode: Algorithmische Differentiation (AD), obwohl die Namensgebung hier nicht eindeutig ist:\n\n> One of the obstacles in this area [of computing derivatives], which involves \"symbolic\" and \"numerical\" methods, has been a confusion in terminology [...]. There is not even general agreement on the best name for the field, which is frequently referred to as *automatic* or *computational differentiation* in the literature. For this book the adjective *algorithmic* seemed preferable, because much of the material emphasizes algorithmic structure, sometimes glossing over the details and pitfalls of actual implementations. (Aus dem Vorwort zu @Griewank2008EDP)\n\nBevor wir uns aber der Methode der algorithmischen Differentiation zuwenden, wollen wir sie durch einige Beispiele motivieren, bei denen die Berechnung von Ableitung von Funktionen und Programmen eine zentrale Rolle spielt: Das Newtonverfahren und das Gradient Descent Verfahren. \n\n### Das Newtonverfahren zur Berechnung von Nullstellen  {#sec-Newtonverfahren1D}\n\nIn vielen Anwendungen steht man vor der Aufgabe, die Gleichung $f(x) = 0$ nach $x$ aufzulösen, d.h. eine Nullstelle $\\bar{x}$ der Funktion zu finden. Oft ist es aber nicht möglich, die Lösung einer solchen Gleichung in geschlossener Form darzustellen. Um dennoch eine Lösung zumindest näherungsweise berechnen zu können, kann man folgendermassen vorgehen:\n\n1. Wähle einen Startwert $x_0$, der in der Nähe einer Nullstelle $\\bar{x}$ von $f$ liegt.\n2. Im Kurvenpunkt $(x_0 | y_0)$ wird die Tangente an die Kurve $f$ gelegt. Deren Schnittpunkt $x_1$ mit der $x$-Achse liegt in der Regel näher bei $\\bar{x}$ als $x_0$.\n3. Nun wiederholt man das Verfahren, indem man bei $x_1$ die Tangente an die Kurve legt, usw. Auf diese Weise erhält man eine Folge von Näherungen $x_0, x_1, x_2, \\ldots$, deren Grenzwert die Nullstelle $\\bar{x}$ ist.\n\nDieser Algorithmus ist als Newtonverfahren bekannt.\n\n:::{.content-visible unless-format=\"pdf\"}\n\n::::{.fig-NewtonGeoGebra}\n\n<iframe scrolling=\"no\" title=\"Newtonverfahren\" src=\"https://www.geogebra.org/material/iframe/id/baja85gv/width/700/height/500/border/888888/sfsb/true/smb/false/stb/false/stbh/false/ai/false/asb/false/sri/true/rc/false/ld/false/sdz/true/ctl/false\" width=\"700px\" height=\"500px\" style=\"border:0px;\"> </iframe>\n\n::::\n\n:::\n\nDie Gleichung der Tangente im Punkt $(x_n | y_n) = (x_n | f(x_n))$ ist bekanntlich $t(x) = f(x_n) + f'(x_n) \\cdot (x - x_n)$. Die Nullstelle der Tangente ist der Näherungswert $x_{n+1}$. Aus $t(x_{n+1}) = 0$ ergibt sich nun die Iterationsvorschrift des Newtonverfahrens:\n$$\nx_{n+1} = x_n - \\frac{f(x_n)}{f'(x_n)}\n$$ {#eq-newton}\n\n:::{#exr-NewtonFirstTry}\n\n## Das Newtonverfahren programmieren\n<br>\n\nSchreibe ein Programm, das mit Hilfe des Newtonverfahrens (@eq-newton) eine Nullstelle der Funktion $f(x) = \\frac{1}{31} x^3 -\\frac{1}{20} x^2 -x + 1$ berechnet. Verwende den Startwert $x_0 = -2$. Du kannst abbrechen, wenn die Differenz $|x_{n+1} - x_n|$ kleiner als eine bestimmte Toleranz wird, z.B. kleiner als `tol = 1e-6`.\nWie flexibel ist dein Programm einsetzbar? Überlege dir z.B., wie viele Änderungen du vornehmen müsstest, wenn du die Nullstelle einer anderen Funktion berechnen müsstest. \n\n:::\n\n:::{.callout-tip collapse=\"true\"}\n\n## Lösung\n\nWelche der folgenden Lösungsvorschläge kommt deinem Programm am nächsten?\n\n::::{.panel-tabset}\n\n## Version 1\n\n::: {.cell execution_count=9}\n``` {.python .cell-code code-fold=\"false\"}\nfrom math import fabs\n\nx0 = -2\ntol = 1e-6\n# Erster Schritt berechnen\nx1 = x0 - (1/31 * x0**3 - 1/20 * x0**2 - x0 + 1) / (3/31 * x0**2 - 1/10 * x0 - 1)\nwhile fabs(x1 - x0) > tol:\n    x0 = x1\n    x1 = x0 - (1/31 * x0**3 - 1/20 * x0**2 - x0 + 1) / (3/31 * x0**2 - 1/10 * x0 - 1)\nprint(x1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n5.908619865450271\n```\n:::\n:::\n\n\nDas Newtonverfahren wird als main-Funktion (d.h. im Hauptprogramm) ausgeführt. Braucht man jedoch die Nullstelle einer anderen Funktion, dann muss ein neues Programm geschrieben werden. Die Ableitung wurde von Hand berechnet.\n\n\n## Version 2\n\n::: {.cell execution_count=10}\n``` {.python .cell-code code-fold=\"false\"}\nfrom math import fabs\n\ndef f(x):\n    y = 1/31 * x**3 - 1/20 * x**2 - x + 1\n    return y\n\ndef fdot(x):\n    ydot = 3/31 * x**2 - 1/10 * x - 1\n    return ydot\n\nx0 = -2\ntol = 1e-6\n# Erster Schritt berechnen\nx1 = x0 - f(x0) / fdot(x0)\nwhile fabs(x1 - x0) > tol:\n    x0 = x1\n    x1 = x0 - f(x0) / fdot(x0)\nprint(x1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n5.908619865450271\n```\n:::\n:::\n\n\nDas Newtonverfahren wird als main-Funktion (d.h. im Hauptprogramm) ausgeführt, aber die Berechnung von $f$ und ihrer Ableitung $f'$ wurde in zwei Funktionen `f` und `fdot` ausgelagert. Das macht das Programm übersichtlicher und flexibler. Die Ableitung wurde wieder von Hand berechnet.\n\n## Version 3\n\n::: {.cell execution_count=11}\n``` {.python .cell-code code-fold=\"false\"}\nfrom math import fabs\n\ndef newton(f, fdot, x0):\n    tol = 1e-6\n    # Erster Schritt berechnen\n    x1 = x0 - f(x0) / fdot(x0)\n    while fabs(x1 - x0) > tol:\n        x0 = x1\n        x1 = x0 - f(x0) / fdot(x0)\n    return x1\n\ndef f(x):\n    y = 1/31 * x**3 - 1/20 * x**2 - x + 1\n    return y\n\ndef fdot(x):\n    ydot = 3/31 * x**2 - 1/10 * x - 1\n    return ydot\n\nx0 = -2\nxbar = newton(f, fdot, x0)\nprint(xbar)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n5.908619865450271\n```\n:::\n:::\n\n\nDas Newtonverfahren wird als eigene Funktion `newton(f, fdot, x0)` implementiert. Dieser werden die Funktion $f$ und ihre Ableitung $f'$, sowie der Startwert $x_0$ als Argumente übergeben. Sie kann dann im Hauptprogramm aufgerufen werden. Die Ableitung wurde aber immer noch von Hand berechnet.\n\n## Version 4\n\n::: {.cell execution_count=12}\n``` {.python .cell-code code-fold=\"false\"}\nfrom math import fabs\n\ndef newton(f, x0):\n    tol = 1e-6\n    # Erster Schritt berechnen\n    # Ableitung von f an der Stelle x0 annähern\n    h = 1e-6\n    ydot = ( f(x0 + h) - f(x0) ) / h\n    x1 = x0 - f(x0) / ydot\n    while fabs(x1 - x0) > tol:\n        x0 = x1\n        ydot = ( f(x0 + h) - f(x0) ) / h\n        x1 = x0 - f(x0) / ydot\n    return x1\n\ndef f(x):\n    y = 1/31 * x**3 - 1/20 * x**2 - x + 1\n    return y\n\nx0 = -2\nxbar = newton(f, x0)\nprint(xbar)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n5.90861986545027\n```\n:::\n:::\n\n\nHier wird das Newtonverfahren in einer Funktion implementiert. Die Ableitung wird nicht mehr von Hand berechnet, sondern innerhalb der Funktion mit $f'(x_0)\\approx \\frac{f(x_0 + h) - f(x_0)}{h}$ angenähert. Dabei wird einfach `h = 1e-6` gesetzt und gehofft, dass der entstehende Rundungsfehler klein genug ist. Beachte aber, dass sich der berechnete Wert von der Ausgabe in den anderen Versionen leicht unterscheidet.\n\n::::\n\n:::\n\nAuch die Version 4 der vorgestellten Lösung ist noch nicht befriedigend. Als wir die Ableitung von Hand berechnet hatten, musste nur die Funktion `fdot` and der Stelle `x0` ausgewertet werden, um den (bis auf Maschinengenauigkeit) *exakten* Wert von $f'(x_0)$ zu erhalten. Bei der letzten Methode muss man sich mit einem Näherungswert der Ableitung zufrieden geben. Auch wenn der Wert in diesem Beispiel gut genug war ^[Das Newton-Verfahren hat die angenehme Eigenschaft, dass kleine Rundungsfehler automatisch ausgeglichen werden. Auf andere numerische Verfahren, die die Ableitung verwenden, trifft dies aber nicht zu.], so haben wir doch keine Garantie, dass wir für alle Funktionen einen vernünftigen Wert erhalten. Auf die Probleme, die mit dieser Annäherung von $f'(x_0)$ auftreten, wird in @sec-ADnotNumDiff näher eingegangen.\n\n:::{#exm-Billard}\n## Billard auf einem runden Tisch\n<br>\n\nWir betrachten ein Beispiel aus @Gander2015. Platziere die weisse und die blaue Billardkugel auf dem runden Tisch. Das Ziel ist es, die weisse Kugel so anzustossen, dass sie die blaue Kugel trifft, nachdem sie vorher genau einmal an die Bande gespielt wurde.\n\n::::{.content-visible unless-format=\"pdf\"}\n\n:::::{.fig-CircularBillardBasic}\n\n<iframe scrolling=\"no\" title=\"Billard\" src=\"https://www.geogebra.org/material/iframe/id/zz2y2use/width/700/height/500/border/888888/sfsb/true/smb/false/stb/false/stbh/false/ai/false/asb/false/sri/true/rc/false/ld/false/sdz/false/ctl/false\" width=\"700px\" height=\"500px\" style=\"border:0px;\"> </iframe>\n\n:::::\n\n::::\n\nAus Symmetriegründen dürfen wir annehmen, dass der Rand des Billardtisches der Einheitskreis ist und dass die weisse Kugel auf der $x$-Achse liegt. Die blaue Kugel habe die Koordinaten $(x_P|y_P)$. Weiter sei $X$ der Punkt auf dem Einheitskreis, an dem die weisse Kugel abprallt. Wir beschreiben diesen Punkt mit seinen Polarkoordinaten $X=(\\cos(x)|\\sin(x))$. Unser Ziel ist es, $x$ so zu berechnen, dass die weisse Kugel die blaue trifft, nachdem sie bei $X$ an die Bande gestossen ist. Dabei verhält sie sich so, als ob sie an der Kreistangente in $X$ reflektiert wird. Der Tangentenvektor im Punkt $X$ lautet $\\vec{t} = \\begin{pmatrix} -\\sin(x) \\\\ \\cos(x) \\end{pmatrix}$. \n\n::::{.content-visible unless-format=\"pdf\"}\n\n:::::{.column-margin}\n\n![Billard auf einem runden Tisch](CircularBillard_sketch.png)\n\n:::::\n\n::::\n\n::::{.content-visible when-format=\"pdf\"}\n\n![Billard auf einem runden Tisch](CircularBillard_sketch.png)\n\n::::\n\nWir betrachten nun die Einheitsvektoren $\\vec{e}_Q$ in Richtung $\\overrightarrow{XQ}$ und $\\vec{e}_P$ in Richtung $\\overrightarrow{XP}$. Wenn die weisse Kugel die blaue treffen soll, dann müssen die Winkel zwischen der Tangente und diesen Vektoren gleich sein. Das ist genau dann der Fall, wenn $\\vec{t}$ senkrecht steht auf $\\vec{e}_Q + \\vec{e}_P$. Wir müssen also $x$ so bestimmen, dass $\\vec{t} \\cdot (\\vec{e}_Q + \\vec{e}_P) = 0$ ist.\n\nDas folgende Programm berechnet das Skalarprodukt der linken Seite dieser Gleichung.\n\n::: {.cell execution_count=13}\n``` {.python .cell-code code-fold=\"show\"}\nimport math\nimport matplotlib.pyplot as plt\n\ndef f(x):\n    # Parameter\n    a = -0.8           # Position von Q = (a|0)\n    px, py = 0.5, 0.5  # Position von P = (px|py)\n\n    # Berechnung des Skalarprodukts\n    v0 = x\n    v1 = math.cos(v0)  # x-Koordinate von X\n    v2 = math.sin(v0)  # y-Koordinate von X\n    v3 = px - v1       # x-Komponente des Vektors XP\n    v4 = py - v2       # y-Komponente des Vektors XP\n    v5 = math.sqrt(v3**2 + v4**2)  # Länge des Vektors XP\n    v6 = v3 / v5       # x-Komponente des Einheitsvektors eP\n    v7 = v4 / v5       # y-Komponente des Einheitsvektors eP\n    \n    v8 = a - v1        # x-Komponente des Vektors XQ\n    v9 = -v2           # y-Komponente des Vektors XQ\n    v10 = math.sqrt(v8**2 + v9**2)  # Länge des Vektors XQ\n    v11 = v8 / v10     # x-Komponente des Vektors eQ    \n    v12 = v9 / v10     # y-Komponente des Vektors eQ   \n    y = (v6 + v11) * v2 - (v7 + v12) * v1  # Skalarprodukt\n    return y   \n\n# Graph der Funktion f(x) plotten\nfig = plt.figure()\nax = plt.gca()\nax.set_xlim((0,2*math.pi))\nax.set_ylim((-1.5,1.5))\nX = [2*math.pi * k / 1000 for k in range(1001)]\nY = [f(x) for x in X]\nplt.plot([0, 2*math.pi], [0, 0], 'k--') # x-Achse\nplt.plot(X,Y)\n#plt.xticks([0, math.pi/2, math.pi, 3*math.pi/2, 2*math.pi],\n#           ['0', 'π/2', 'π', '3π/2', '2π'])\nplt.show()  \n```\n\n::: {.cell-output .cell-output-display}\n![Graph des Skalarprodukts als Funktion des Polarwinkels $x$ des Punktes $X = (cos(x) | sin(x))$. Die Nullstellen entsprechen den Winkeln, bei denen die weisse Kugel die blaue Kugel trifft, nachdem sie genau einmal an die Bande gespielt wurde.](intro_files/figure-pdf/fig-graphofbillard-output-1.pdf){#fig-graphofbillard}\n:::\n:::\n\n\nWir möchten die Nullstellen der Funktion `f(x)` mit unserer Funtion `newton` bestimmmen. Dazu müssen wir jedoch die Ableitung von `f` berechnen.\n\n:::\n---\n\n### Gradient Descent zum Auffinden lokaler Minima\n\nEine weitere wichtige Aufgabe besteht darin, ein Minimum einer Funktion zu finden. Auch hier wollen wir mit Hilfe der Ableitung eine Folge von Näherungswerten $x_0, x_1, x_2, \\ldots$ finden, deren Grenzwert die $x$-Koordinate eines (lokalen) Minimums von $f$ ist.\n\nWenn $f'(x_n)>0$ ist, dann wissen wir, dass die Funktion $f$ an der Stelle $x_0$ streng monoton wachsend ist. D.h., dass die Funktionswerte links von $x_n$ kleiner sind, als an der Stelle $x_n$. Analog gilt, dass wenn $f'(x_n)<0$ ist, die Funktion monoton fallend ist und wir uns nach rechts bewegen sollten, um ein Minimum zu finden. In der Nähe eines Minimums ist ausserdem $|f'(x)|$ sehr klein und wir können entsprechend kleinere Schritte machen, um uns diesem anzunähern. Um also von $x_n$ zu $x_{n+1}$ zu kommen, machen wir einen Schritt, der proportional zu $-f'(x_n)$ ist. Mit dem Proporionalitätsfaktor $\\lambda\\in\\mathbb{R}$ und einem geeignet gewählten Startwert $x_0$ erhalten wir die Iterationsvorschrift\n$$\nx_{n+1} = x_n - \\lambda\\cdot f'(x_n)\n$$ {#eq-gradientDescent}\n\n:::{.content-visible unless-format=\"pdf\"}\n\n::::{.fig-GradientDescentGeoGebra1D}\n\n<iframe scrolling=\"no\" title=\"Gradient Descent Verfahren\" src=\"https://www.geogebra.org/material/iframe/id/xnjdmuqr/width/700/height/500/border/888888/sfsb/true/smb/false/stb/false/stbh/false/ai/false/asb/false/sri/true/rc/false/ld/false/sdz/true/ctl/false\" width=\"700px\" height=\"500px\" style=\"border:0px;\"> </iframe>\n\n::::\n\n:::\n\n:::{#exr-GradientDescentBasicProperties}\n\n## Eigenschaften der Gradient Descent Methode\n<br>\nExperimentiere mit verschiedenen Funktionen und verschiedenen Schrittweiten $\\lambda$. Was passiert, wenn die Schrittweite zu klein bzw. zu gross gewählt wird? Was passiert, wenn $f$ an der Stelle $x_0$ ein lokales Maximum aufweist? Was passiert in der Nähe eines Sattelpunktes?\n\n:::\n\n:::{.callout-tip collapse=\"true\"}\n\n## Lösung\n\nIst $\\lambda$ zu klein, dann konvergiert das Verfahren nur sehr langsam. Ist $\\lambda$ dagegen zu gross, dann kann es passieren, dass die Iteration zwischen zwei oder mehr Werten hin- und herspringt oder sogar nach $\\pm\\infty$ divergiert. \n\nFalls $x_0$ gerade mit der Stelle eines lokalen Maximums oder eines Sattelpunktes zusammenfällt, gilt auch $f'(x_0)=0$ und damit auch $x_n = x_0$ für alle $n\\in\\mathbb{N}$. Maxima sind aber labile Gleichgewichtspunkte in dem Sinn, dass sich $x_n$ von ihnen wegbewegt, wenn $x_0$ auch nur ein bisschen links oder rechts davon liegt. Ähnlich verhält es sich bei Sattelpunkten. Die Folge konvergiert gegen die Stelle des Sattelpunktes, wenn $f(x_0)$ grösser als der $y$-Wert des Sattelpunktes ist und $\\lambda$ nicht zu gross ist.\n\n:::\n\n:::{#exr-GradientDescentFirstTry}\n\n## Gradient Descent programmieren\n<br>\n\nSchreibe ein Programm, das mit Hilfe des Gradient Descent Verfahrens (@eq-gradientDescent) ein lokales Minimums der Funktion $f(x) = \\frac{1}{16}x^4 - \\frac{1}{3}x^3 + \\frac{1}{8}x^2 + x + 2$ berechnet. Verwende den Startwert $x_0 = 1.5$ und die Schrittweite $\\lambda = 0.5$. Du kannst abbrechen, wenn die Differenz $|x_{n+1} - x_n|$ kleiner als eine bestimmte Toleranz wird, z.B. kleiner als `tol = 1e-6`. Wie flexibel ist dein Programm einsetzbar? Überlege dir z.B., wie viele Änderungen du vornehmen müsstest, wenn du ein lokales Minimum einer anderen Funktion berechnen müsstest. \n\n:::\n\n:::{.callout-tip collapse=\"true\"}\n\n## Lösung\n\nWelche der folgenden Lösungsvorschläge kommt deinem Programm am nächsten?\n\n::::{.panel-tabset}\n\n## Version 1\n\n::: {.cell execution_count=14}\n``` {.python .cell-code code-fold=\"false\"}\nfrom math import fabs\n\nx0 = 1.5\nlam = 0.5\ntol = 1e-6\n# Erster Schritt berechnen\nx1 = x0 - lam * (1/4 * x0**3 - x0**2 + 1/4 * x0 + 1)\nwhile fabs(x1-x0) > tol:\n    x0 = x1\n    x1 = x0 - lam * (1/4 * x0**3 - x0**2 + 1/4 * x0 + 1)\nprint(x1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n3.3429230748530196\n```\n:::\n:::\n\n\nDas Gradient Descent Verfahren wird als main-Funktion (d.h. im Hauptprogramm) ausgeführt. Um das Minimum einer anderen Funktion zu bestimmen, muss ein neues Programm geschrieben werden. Die Ableitung wurde von Hand berechnet\n\n## Version 2\n\n::: {.cell execution_count=15}\n``` {.python .cell-code code-fold=\"false\"}\nfrom math import fabs\n\ndef fdot(x):\n    ydot = 1/4 * x**3 - x**2 + 1/4 * x + 1\n    return ydot\n\nx0 = 1.5\nlam = 0.5\ntol = 1e-6\n# Erster Schritt berechnen\nx1 = x0 - lam * fdot(x0)\nwhile fabs(x1-x0) > tol:\n    x0 = x1\n    x1 = x0 - lam * fdot(x0)\nprint(x1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n3.3429230748530196\n```\n:::\n:::\n\n\nDas Gradient Descent Verfahren wird als main-Funktion (d.h. im Hauptprogramm) ausgeführt, aber die Berechnung von $f'$ wurde in die Funktion `fdot(x)` ausgelagert. Das macht das Programm etwas flexibler. Die Ableitung wurde wieder von Hand berechnet.\n\n## Version 3\n\n::: {.cell execution_count=16}\n``` {.python .cell-code code-fold=\"false\"}\nfrom math import fabs\n\ndef gradient_descent(fdot, x0, lam):\n    tol = 1e-6\n    # Erster Schritt berechnen\n    x1 = x0 - lam * fdot(x0)\n    while fabs(x1-x0) > tol:\n        x0 = x1\n        x1 = x0 - lam * fdot(x0)\n    return x1\n\ndef fdot(x):\n    ydot = 1/4 * x**3 - x**2 + 1/4 * x + 1\n    return ydot\n\nx0 = 1.5\nlam = 0.5\nxmin = gradient_descent(fdot, x0, lam)\nprint(xmin)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n3.3429230748530196\n```\n:::\n:::\n\n\nDas Gradient Descent Verfahren wird als eigene Funktion `gradient_descent(fdot, x0, lam)` implementiert. Dieser Funktion werden die Ableitung $f'$, der Startwert $x_0$, sowie die Schrittweite $\\lambda$ als Argumente übergeben. Sie kann dann im Hauptprogramm aufgerufen werden. Die Ableitung wurde aber immer noch von Hand berechnet.\n\n## Version 4\n\n::: {.cell execution_count=17}\n``` {.python .cell-code code-fold=\"false\"}\nfrom math import fabs\n\ndef gradient_descent(f, x0, lam):\n    tol = 1e-6\n    # Erster Schritt berechnen\n    # Ableitung an der Stelle x0 annähern\n    h = 1e-6\n    ydot = ( f(x0 + h) - f(x0) ) / h\n    x1 = x0 - lam * ydot\n    while fabs(x1-x0) > tol:\n        x0 = x1\n        ydot = ( f(x0 + h) - f(x0) ) / h\n        x1 = x0 - lam * ydot\n    return x1\n\ndef f(x):\n    y = 1/16 * x**4 - 1/3 * x**3 + 1/8 * x**2 + x + 2\n    return y\n\nx0 = 1.5\nlam = 0.5\nxmin = gradient_descent(fdot, x0, lam)\nprint(xmin)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n2.535183236464121\n```\n:::\n:::\n\n\nDas Gradient Descent Verfahren wird als eigene Funktion `gradient_descent(f, x0, lam)` implementiert. Dieser Funktion werden die ursprüngliche Funktion $f$, der Startwert $x_0$, sowie die Schrittweite $\\lambda$ als Argumente übergeben. Die Ableitung wird nicht mehr von Hand berechnet, sondern durch den Differenzenquotienten $f'(x_0) \\approx \\frac{f(x_0 + h) - f(x_0)}{h}$ angenähert. Dabei wird einfach `h = 1e-6` gesetzt und gehofft, dass der entstehende Rundungsfehler klein genug ist. Offensichtlich ist diese Annahme jedoch nicht gerechtfertigt.\n\n::::\n\n:::\n\nDie @exr-GradientDescentFirstTry verdeutlicht nochmals das Problem, welches wir bereits in @exr-NewtonFirstTry gesehen haben. Wir müssen für den Algorithmus die Ableitung $f'$ an mehreren Stellen auswerten. Wir möchten aber die Ableitung einerseits nicht von Hand berechnen und andererseits können wir uns auch nicht mit einer Approximation zufrieden geben.\n\nWir beschliessen dieses Kapitel mit einer praktischen Anwendung der Gradient Descent Methode.\n\n:::{#exm-GDApplication}\n\n## Abstand zwischen Eillipse und Gerade\n<br>\n\nDie Punkte $P$ und $Q$ bewegen sich auf Ellipsen im Raum. Die Position des Punktes $P$ zur Zeit $t$ ist gegeben durch\n\n\\begin{align}\n    x_P(t) &= 2 \\cos(t) - 1 \\\\\n    y_P(t) &= 1.5 \\sin(t)   \\\\\n    z_P(t) &= 0             \n\\end{align}\n\nund die Position von $Q$ zum Zeitpunkt $t$ lässt sich durch\n\n\\begin{align}\n    x_Q(t) &= -3 \\sin(2t)     \\\\\n    y_Q(t) &= 2 \\cos(2t) + 1  \\\\\n    z_Q(t) &= 2 \\sin(2t) + 1  \n\\end{align}\n\nbestimmen.\n\n::::{.content-visible unless-format=\"pdf\"}\n\n:::::{.fig-AbstandEllipseGerade}\n\n<iframe scrolling=\"no\" title=\"Abstandsproblem\" src=\"https://www.geogebra.org/material/iframe/id/ksauhvfy/width/700/height/500/border/888888/sfsb/true/smb/false/stb/false/stbh/false/ai/false/asb/false/sri/true/rc/false/ld/true/sdz/true/ctl/false\" width=\"700px\" height=\"500px\" style=\"border:0px;\"> </iframe>\n\n:::::\n\n::::\n\nDer Abstand zwischen den beiden Punkten lässt sich zu jedem Zeitpunkt $t$ berechnen durch $d = d(t) = |\\overrightarrow{PQ}|$. Das folgende Programm berechnet diese Funktion und zeichnet ihren Graph.\n\n::: {.cell execution_count=18}\n``` {.python .cell-code code-fold=\"show\"}\nimport math\n\ndef d(t):\n    v0 = t\n    v1 = 2 * math.cos(v0) - 1    # x-Koordinate von P\n    v2 = 1.5 * math.sin(v0)      # y-Koordinate von P\n    v3 = 0                       # z-Koordinate von P\n    v4 = -3 * math.sin(2*v0)     # x-Koordinate von Q\n    v5 = 2 * math.cos(2*v0) + 1  # y-Koordinate von Q\n    v6 = 2 * math.sin(2*v0) + 1  # z-Koordinate von Q\n    y = math.sqrt((v4-v1)**2 + (v5-v2)**2 + (v6-v3)**2)\n    return y\n\n# Graph der Funktion d(t) plotten\nfig = plt.figure()\nax = plt.gca()\nax.set_xlim((0,2*math.pi))\nax.set_ylim((0,6))\nT = [2*math.pi * k / 1000 for k in range(1001)]\nY = [d(t) for t in T]\nplt.plot(T,Y)\n#plt.xticks([0, math.pi/2, math.pi, 3*math.pi/2, 2*math.pi],\n#           ['0', 'π/2', 'π', '3π/2', '2π'])\nplt.show()  \n```\n\n::: {.cell-output .cell-output-display}\n![Graph der Abstandsfunktion $d(t)$.](intro_files/figure-pdf/fig-graphofdistanceproblem-output-1.pdf){#fig-graphofdistanceproblem}\n:::\n:::\n\n\nWir möchten das Minimum der Funktion $d(t)$ mit Hilfe der Gradient Descent Methode finden. Dazu müssen wir aber $d$ ableiten können.\n\n:::\n\n---\n\n",
    "supporting": [
      "intro_files\\figure-pdf"
    ],
    "filters": []
  }
}
{
  "hash": "4a45962fb88d1699214a1c6f249eba63",
  "result": {
    "markdown": "---\ntbl-cap-location: bottom\n---\n\n# Funktionen mit mehreren In- und Outputs\n\n\n\n\n\nWir wollen nun unsere Betrachtungen erweitern auf Funktionen, die zu einem Eingabewert mehrere Ausgabewerte produzieren, d.h. $f : \\mathbb{R}\\rightarrow\\mathbb{R}^m$ (Parameterkurven) oder aus mehreren Eingabewerten einen Ausgabewert berechnen, d.h. $f : \\mathbb{R}^n \\rightarrow\\mathbb{R}$ oder im allgemeinen Fall aus $n$ Eingabewerten $m$ Ausgabewerte berechnen, d.h. $f : \\mathbb{R}^n \\rightarrow\\mathbb{R}^m$.\n\n## Funktionen mit mehreren Ausgabewerten\n\nEine vektorwertige Funktion $f : \\mathbb{R}\\rightarrow\\mathbb{R}^m$ mit\n\n$$\nf(t) = \\begin{pmatrix} y_1(t) \\\\ \\vdots \\\\ y_m(t) \\end{pmatrix}\n$$\n\nkann man sich als eine Kurve in einem $m$-dimensionalen Raum vorstellen. Im @exm-GDApplication wird etwa die Bahn des Punktes $Q$ durch die Funktion\n\n$$\nf(t) = \\left( \\begin{align*} -3 &\\sin(2t) \\\\ 2 &\\cos(2t) + 1 \\\\ 2 &\\sin(2t) + 1 \\end{align*}  \\right)\n$$\n\nbeschrieben. Die Ableitung einer solchen Funktion wird komponentenweise berechnet und gibt zu einem bestimmten Zeitpunkt $t_0$ den Tangentialvektor im Kurvenpunkt $f(t_0)$ an:\n\n$$\n\\dot{f}(t_0) = \\begin{pmatrix} \\dot y_1(t_0) \\\\ \\vdots \\\\ \\dot y_m(t_0) \\end{pmatrix}\n$$\n\nPhysikalisch entspricht dies dem Geschwindigkeitsvektor zum Zeitpunkt $t_0$. Mehr über die Ableitung von Parameterkurven findet man z.B. in @Arens2022, S. 947.\n\nAls Programm können wir die obige Kurve so darstellen\n\n::: {.cell execution_count=3}\n``` {.python .cell-code code-fold=\"show\"}\nimport math\n\ndef f(t):\n    y1 = -3*math.sin(2*t)\n    y2 =  2*math.cos(2*t) + 1\n    y3 =  2*math.sin(2*t) + 1\n    y = [y1, y2, y3]\n    return y\n\nt0 = 2\ny0 = f(t0)\nprint(y0)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[2.2704074859237844, -0.3072872417272239, -0.5136049906158564]\n```\n:::\n:::\n\n\nFür die Ableitung können wir unser Modul `FloatSad` benutzen. Der Rückgabewert der Funktion ist dann eine Liste mit drei `FloatSad`-Objekten.\n\n::: {.cell execution_count=4}\n``` {.python .cell-code code-fold=\"show\"}\nfrom floatsad import FloatSad \nimport mathsad\n\ndef f(t):\n    t = FloatSad(t)\n    y1 = -3*mathsad.sin(2*t)\n    y2 =  2*mathsad.cos(2*t) + 1\n    y3 =  2*mathsad.sin(2*t) + 1\n    y = [y1, y2, y3]\n    return y\n\nt0 = 2\ny0 = f(t0)\nprint(\"y1(\" + str(t0) + \") = \" + str(y0[0].value))\nprint(\"y1'(\" + str(t0) + \") = \" + str(y0[0].derivative))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\ny1(2) = 2.2704074859237844\ny1'(2) = 3.921861725181672\n```\n:::\n:::\n\n\nDiese Implementation hat den Nachteil, dass die Handhabung etwas kompliziert wird. Insbesondere kann man nicht einfach `y0.value` schreiben, um eine Liste der Funktionswerte zu erhalten. Abhilfe schafft dabei das Modul `numpy`. Wir verwenden daraus die Möglichkeit, Funktionen zu vektorisieren, um zwei Funktionen `getValues(y)` und `getDerivatives(y)` zu definieren, welche aus der Liste `y` von `FloatSad`-Objekten jeweils die Funktionswerte, respektive die Werte der Ableitungen extrahieren.\n\n::: {.cell execution_count=5}\n``` {.python .cell-code code-fold=\"show\"}\nfrom floatsad import FloatSad\nimport mathsad\nimport numpy as np\n\ndef f(t):\n    t = FloatSad(t)\n    y1 = -3*mathsad.sin(2*t)\n    y2 =  2*mathsad.cos(2*t) + 1\n    y3 =  2*mathsad.sin(2*t) + 1\n    y = [y1, y2, y3]\n    return y\n\ngetValues = np.vectorize(lambda y : y.value)\ngetDerivatives = np.vectorize(lambda y : y.derivative)\n\nt0 = 2\ny0 = f(t0)\nprint(getValues(y0))\nprint(getDerivatives(y0))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[ 2.27040749 -0.30728724 -0.51360499]\n[ 3.92186173  3.02720998 -2.61457448]\n```\n:::\n:::\n\n\n## Funktionen mit mehreren Eingabewerten\n\nDie Ableitung einer Funktion $f : \\mathbb{R}^n \\rightarrow \\mathbb{R}$ ist der Gradient\n\n$$\n\\nabla f = \\left( \\frac{\\partial f}{\\partial x_1}, \\ldots, \\frac{\\partial f}{\\partial x_n} \\right)\n$$\n\nFür weitere Details zum Gradienten sei auf @Arens2022, S. 870 verwiesen.\n\n:::{#exm-ExampleFunctionRnToR}\n\n## Eine Funktion mit drei Eingabwerten\n<br>\n\nBetrachten wir als Beispiel die Funktion $f : \\mathbb{R}^3 \\rightarrow \\mathbb{R}$\n\n$$\nf(x_0, x_1, x_2) = x_0^2 + 2\\cdot x_0 \\cdot x_1 - \\frac{x_1}{x_2 ^3}\n$$\n\nDas folgende Programm berechnet den Funktionswert $f(1, 2, 3)=\\frac{133}{27}\\approx 4.9259...$\n\n::: {.cell execution_count=6}\n``` {.python .cell-code code-fold=\"show\"}\ndef f(x):\n    y = x[0]**2 + 2*x[0]*x[1] - x[1]/x[2]**3\n    return y\n\nx0 = [1, 2, 3]\ny0 = f(x0)\nprint(y0)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n4.925925925925926\n```\n:::\n:::\n\n\nDer Gradient dieser Funktion ist\n$$\n\\nabla f = \\left( 2x_0+2x_1, 2x_0 - \\frac{1}{x_2^3}, 3\\frac{x_1}{x_2^4} \\right)\n$$\n\nbzw. ausgewertet an der Stelle $(x_0, x_1, x_2) = (1, 2, 3)$\n$$\n\\begin{align*}\n\\nabla f \\vert _{(1, 2, 3)} &= \\left( 6, \\frac{53}{27}, \\frac2{27} \\right) \\\\\n&\\approx \\left( 6, 1.9629..., 0.0740... \\right)\n\\end{align*}\n$$\n:::\n\n---\n\nMit der Standard Algorithmischen Differentiation kann der Gradient nicht in einem Durchgang berechnet werden. Bei der Umwandlung der Anfangswerte in `FloatSad`-Objekte müssen wir allen Variablen in $x = (x_1, \\ldots, x_n)$ einen Anfangswert $\\dot{x} = (\\dot x_1, \\ldots, \\dot x_n)$ geben. Wenn wir für die Initialisierung $\\dot{x} = e_i = (0, \\ldots, 1, \\ldots, 0)$ verwenden (mit $1$ an der $i$-ten Stelle und sonst lauter $0$), dann bekommen wir den Wert der $i$-ten partiellen Ableitung $\\frac{\\partial f}{\\partial x_i}$.\n\nUm die Funktion im obigen Beispiel mit unserer Klasse `FloatSad` abzuleiten, verwenden wir wieder `numpy`. Als erstes definieren wir eine vektorisierte Funktion `float2FloatSad`, mit der wir aus der Liste `x` eine Liste von `FloatSad`-Objekten erzeugen. Die Werte der Ableitungen werden zu Beginn explizit in der Variablen `xdot` initialisiert. \n\n:::{.panel-tabset}\n\n## Ableitung nach `x0`\n\n::: {.cell execution_count=7}\n``` {.python .cell-code code-fold=\"show\"}\nfrom floatsad import FloatSad\nimport numpy as np\n\ndef f(x):\n    xdot = [1, 0, 0]\n    x = float2FloatSad(x, xdot)\n    y = x[0]**2 + 2*x[0]*x[1] - x[1]/x[2]**3\n    return y\n\nfloat2FloatSad = np.vectorize(lambda x, v : FloatSad(x,v))\n\nx0 = [1, 2, 3]\ny0 = f(x0)\nprint(y0)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n< 4.925925925925926 ; 6.0 >\n```\n:::\n:::\n\n\n## Ableitung nach `x1`\n\n::: {.cell execution_count=8}\n``` {.python .cell-code code-fold=\"show\"}\nfrom floatsad import FloatSad\nimport numpy as np\n\ndef f(x):\n    xdot = [0, 1, 0]\n    x = float2FloatSad(x, xdot)\n    y = x[0]**2 + 2*x[0]*x[1] - x[1]/x[2]**3\n    return y\n\nfloat2FloatSad = np.vectorize(lambda x, v : FloatSad(x,v))\n\nx0 = [1, 2, 3]\ny0 = f(x0)\nprint(y0)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n< 4.925925925925926 ; 1.962962962962963 >\n```\n:::\n:::\n\n\n## Ableitung nach `x2`\n\n::: {.cell execution_count=9}\n``` {.python .cell-code code-fold=\"show\"}\nfrom floatsad import FloatSad\nimport numpy as np\n\ndef f(x):\n    xdot = [0, 0, 1]\n    x = float2FloatSad(x, xdot)\n    y = x[0]**2 + 2*x[0]*x[1] - x[1]/x[2]**3\n    return y\n\nfloat2FloatSad = np.vectorize(lambda x, v : FloatSad(x,v))\n\nx0 = [1, 2, 3]\ny0 = f(x0)\nprint(y0)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n< 4.925925925925926 ; 0.07407407407407407 >\n```\n:::\n:::\n\n\n:::\n\nInitialisiert man die Ableitungen beispielsweise mit `xdot = [1, 1, 1]`, dann erhält man die Summe der drei Richtungsableitungen:\n\n::: {.cell execution_count=10}\n\n::: {.cell-output .cell-output-stdout}\n```\n< 4.925925925925926 ; 8.037037037037036 >\n```\n:::\n:::\n\n\nAllgemein gilt: Initialisiert man `xdot` mit dem Vektor $\\vec r = (r_1, \\ldots, r_n)^\\intercal$, dann erhält man das Skalarprodukt\n$$\n\\nabla f \\cdot \\vec r = \n\\left ( \\left .\\frac{\\partial f}{\\partial x_1} \\right \\vert_{(x_1, \\ldots, x_n)}, \\ldots, \\left .\\frac{\\partial f}{\\partial x_n} \\right \\vert_{(x_1, \\ldots, x_n)}  \\right ) \\cdot \\begin{pmatrix} r_1 \\\\ \\vdots \\\\ r_n \\end{pmatrix} \n$$\n\n\n## Funktionen mit mehreren Ein- und Ausgabewerten\n\nEine Funktion $f : \\mathbb{R}^n \\rightarrow \\mathbb{R}^m$ hat die Form\n$$\nf(x_1, \\ldots, x_n) = \\left( \\begin{align*} y_1(x_1, &\\ldots, x_n) \\\\ &\\vdots \\\\ y_m(x_1, &\\ldots, x_n) \\end{align*} \\right)\n$$\nDie Ableitung einer solchen Funktion wird durch die Jacobi Matrix\n$$\nJf = \\begin{pmatrix}\n    \\frac{\\partial y_1}{\\partial x_1} & \\ldots & \\frac{\\partial y_1}{\\partial x_n} \\\\\n    \\vdots & & \\vdots \\\\\n    \\frac{\\partial y_m}{\\partial x_1} & \\ldots & \\frac{\\partial y_m}{\\partial x_n}\n\\end{pmatrix}\n\\in\\mathbb{R}^{m\\times n}\n$$\ngegeben. Auch hierzu findet der Leser mehr Informationen in @Arens2022, S. 878.\n\n:::{#exm-ExFunctionR2ToR3}\n\n## Eine Funktion mit zwei Ein- und drei Ausgabwerten\n<br>\n\nBetrachte die Funktion $f : \\mathbb{R}^2 \\rightarrow \\mathbb{R}^3$ \n$$\nf(x_0, x_1) = \n    \\begin{pmatrix}\n        x_0\\cdot \\sqrt{x_1} + 3x_1 \\\\\n        \\cos(x_0) / x_1 \\\\\n        e^{x_0 ^2\\cdot x_1}\n    \\end{pmatrix}\n$$\n\nDie Jacobi Matrix lautet in diesem Fall\n$$\nJf = \n\\begin{pmatrix}\n    \\sqrt{x_1} & \\frac{x_0}{2\\sqrt{x_1}} + 3 \\\\\n    -\\frac{\\sin(x_0)}{x_1} & -\\frac{\\cos(x_0)}{x_1^2} \\\\\n    e^{x_0^2\\cdot x_1}\\cdot 2 x_0 x_1 & e^{x_0^2\\cdot x_1}\\cdot x_0^2\n\\end{pmatrix}\n$$\n\nAusgewertet an der Stelle $(x_0, x_1) = (2, 1)$ ergibt dies \n$$\nf(2,1) \\approx \\begin{pmatrix} 5 \\\\ -0.4161... \\\\ 54.5981... \\end{pmatrix}, \\qquad \nJF \\vert _{(2,1)} \\approx \n    \\begin{pmatrix}  \n        1 & 4 \\\\\n        -0.9092... & 0.4161... \\\\\n        218.3926... & 218.3926...\n    \\end{pmatrix}\n$$\n\n:::\n---\n\nUm die Funktion aus dem Beispiel mit SAD abzuleiten kombinieren wir die Techniken aus den beiden vorherigen Abschnitten. Je nach Initialisierung von `xdot` erhalten wir die erste oder die zweite Spalte von $JF$.\n\n:::{.panel-tabset}\n\n## 1. Spalte\n\n::: {.cell execution_count=11}\n``` {.python .cell-code code-fold=\"show\"}\nfrom floatsad import FloatSad\nimport mathsad\nimport numpy as np\n\ndef f(x):\n    xdot = [1, 0]\n    x = float2FloatSad(x, xdot)\n    y1 = x[0]*mathsad.sqrt(x[1]) + 3*x[1]\n    y2 = mathsad.cos(x[0]) / x[1]\n    y3 = mathsad.exp(x[0]**2 * x[1])\n    return [y1, y2, y3]    \n\n\nfloat2FloatSad = np.vectorize(lambda x, v : FloatSad(x,v))\ngetValues = np.vectorize(lambda y : y.value)\ngetDerivatives = np.vectorize(lambda y : y.derivative)\n\n\nx0 = (2, 1)\ny0 = f(x0)\nprint(\"Funktionswerte:\")\nprint(getValues(y0))\nprint(\"1. Spalte von Jf:\")\nprint(getDerivatives(y0))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nFunktionswerte:\n[ 5.         -0.41614684 54.59815003]\n1. Spalte von Jf:\n[  1.          -0.90929743 218.39260013]\n```\n:::\n:::\n\n\n## 2. Spalte\n\n::: {.cell execution_count=12}\n``` {.python .cell-code code-fold=\"show\"}\nfrom floatsad import FloatSad\nimport mathsad\nimport numpy as np\n\ndef f(x):\n    xdot = [0, 1]\n    x = float2FloatSad(x, xdot)\n    y1 = x[0]*mathsad.sqrt(x[1]) + 3*x[1]\n    y2 = mathsad.cos(x[0]) / x[1]\n    y3 = mathsad.exp(x[0]**2 * x[1])\n    return [y1, y2, y3]    \n\n\nfloat2FloatSad = np.vectorize(lambda x, v : FloatSad(x,v))\ngetValues = np.vectorize(lambda y : y.value)\ngetDerivatives = np.vectorize(lambda y : y.derivative)\n\n\nx0 = (2, 1)\ny0 = f(x0)\nprint(\"Funktionswerte:\")\nprint(getValues(y0))\nprint(\"2. Spalte von Jf:\")\nprint(getDerivatives(y0))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nFunktionswerte:\n[ 5.         -0.41614684 54.59815003]\n2. Spalte von Jf:\n[  4.           0.41614684 218.39260013]\n```\n:::\n:::\n\n\n:::\n\nInitialisiert man allgemein `xdot` mit dem Vektor $r = (r_1, \\ldots, r_n)^\\intercal$, dann erhält man als Resultat das Produkt\n$$\nJf \\cdot r = \n\\begin{pmatrix}\n    \\frac{\\partial y_1}{\\partial x_1} & \\ldots & \\frac{\\partial y_1}{\\partial x_n} \\\\\n    \\vdots & & \\vdots \\\\\n    \\frac{\\partial y_m}{\\partial x_1} & \\ldots & \\frac{\\partial y_m}{\\partial x_n}\n\\end{pmatrix}\n\\cdot \\begin{pmatrix} r_1 \\\\ \\vdots \\\\ r_n \\end{pmatrix} \n$$\n\nBraucht man die gesammte Jacobi Matrix, dann muss man also die Funktion so oft aufrufen, wie die Matrix Spalten hat, d.h. `len(x)` Mal. Die SAD Methode ist also effizient, wenn eine Funktion mehr Aus- als Eingabewerte hat. Der ineffizienteste Fall tritt auf, wenn die Funktion aus vielen Eingabewerte nur einen Ausgabewert berechnet. Mit anderen Worten: Das Bestimmen des Gradienten einer Funktion $f: \\mathbb{R}^n \\rightarrow \\mathbb{R}$ benötigt den grössten Aufwand gemessen an der Anzahl zu berechnender Werte. Abhilfe schafft in so einem Fall die Adjungierte Automatische Differentiation (AAD).\n\nZum Schluss sei noch angemerkt, dass die Definition der drei Funktionen `float2FloatSad`, `getValues` und `getDerivatives` in die Datei `floatsad.py` geschrieben werden könnten (beachte, dass sie *nicht* eingerückt werden wie die restlichen Befehle der Klasse). Dann vereinfacht sich das obige Programm:\n\n::: {.cell execution_count=13}\n``` {.python .cell-code code-fold=\"show\"}\nfrom floatsad import *\nimport mathsad\n\ndef f(x):\n    xdot = [1, 0]\n    x = float2FloatSad(x, xdot)\n    y1 = x[0]*mathsad.sqrt(x[1]) + 3*x[1]\n    y2 = mathsad.cos(x[0]) / x[1]\n    y3 = mathsad.exp(x[0]**2 * x[1])\n    return [y1, y2, y3]    \n\n\nx0 = (2, 1)\ny0 = f(x0)\nprint(getValues(y0))\nprint(getDerivatives(y0))\n```\n:::\n\n\n",
    "supporting": [
      "HigherDimFunctions_files"
    ],
    "filters": [],
    "includes": {}
  }
}
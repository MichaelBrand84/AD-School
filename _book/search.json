[
  {
    "objectID": "notAD.html",
    "href": "notAD.html",
    "title": "2  AD ist nicht …",
    "section": "",
    "text": "Bevor wir uns mit den konkreten Implementationen von algorithmischer Differentiation beschäftigen, wollen wir herausstellen, was AD nicht ist."
  },
  {
    "objectID": "notAD.html#sec-ADnotNumDiff",
    "href": "notAD.html#sec-ADnotNumDiff",
    "title": "2  AD ist nicht …",
    "section": "2.1 AD ist nicht numerisches Ableiten",
    "text": "2.1 AD ist nicht numerisches Ableiten\nEine Funktion \\(y = f(x)\\) ist bekanntlich differenzierbar an der Stelle \\(x_0 \\in \\mathbb{D}\\), wenn der Grenzwert \\[ \\lim_{h\\rightarrow 0} \\frac{f(x_0 + h) - f(x_0)}{h} \\] existiert. In dem Fall ist \\(f'(x_0)\\) einfach der Wert dieses Grenzwerts.\nEin erster Ansatz zur numerischen Berechnung könnte also sein, den Differenzenquotienten für kleine \\(h\\) auszuwerten1.1 Dieser Ansatz kann verbessert werden indem man z.B. \\(f'(x_0) \\approx \\frac{f(x_0 + h) - f(x_0 - h)}{2h}\\) verwendet. Die im Beispiel beschriebenen Probleme bleiben aber auch dann bestehen.\n\nBeispiel 2.1 (Numerische Ableitung) \nLeite die Funktion \\(f(x) = x^2\\) an der Stelle \\(x_0 = 2\\) ab.\n\n\nCode\ndef f(x):\n    y = x ** 2\n    return y\n\ndef fdot(f, x0, h):\n    df = (f(x0 + h) - f(x0)) / h\n    return df\n\nx0 = 0.2\nH = [0.1, 0.01, 0.001, 0.0001]\nfor h in H:\n    ydot = fdot(f, x0, h)\n    print(\"h = \" + str(h) + \" \\t=> f'(x0) = \" + str(ydot))\n\n\nh = 0.1     => f'(x0) = 0.5000000000000001\nh = 0.01    => f'(x0) = 0.4099999999999999\nh = 0.001   => f'(x0) = 0.4009999999999986\nh = 0.0001  => f'(x0) = 0.40009999999993107\n\n\nEs scheint zunächst, als ob die Werte für kleiner werdende \\(h\\) zum korrekten Wert \\(f'(0.2)=0.4\\) konvergieren. Wenn wir aber an sehr genauen Werten interessiert sind und entsprechend \\(h\\) sehr klein wählen, beobachten wir folgendes:\n\n\nCode\ndef f(x):\n    y = x ** 2\n    return y\n\ndef fdot(f, x0, h):\n    df = (f(x0 + h) - f(x0)) / h\n    return df\n\nx0 = 0.2\nH = [10 ** -8, 10 ** -9, 10 ** -10, 10 ** -11]\nfor h in H:\n    ydot = fdot(f, x0, h)\n    print(\"h = \" + str(h) + \"\\t=> f'(x0) = \" + str(ydot))\n\n\nh = 1e-08   => f'(x0) = 0.4000000095039091\nh = 1e-09   => f'(x0) = 0.3999999984016789\nh = 1e-10   => f'(x0) = 0.4000000330961484\nh = 1e-11   => f'(x0) = 0.3999994779846361\n\n\nDas Phänomen wird noch deutlicher, wenn wir den Fehler \\(E(h) = \\lvert\\frac{f(x_0+h)-f(x_0)}{h} - f'(x_0)\\rvert\\) als Funktion von \\(h\\) plotten. Beachte die doppelt logarithmische Skala.\n\n\nCode\nimport matplotlib.pyplot as plt\nimport math\n\ndef f(x):\n    y = x ** 2\n    return y\n\ndef fdot(f, x0, h):\n    df = (f(x0 + h) - f(x0)) / h\n    return df\n\nx0 = 0.2\nH = [10**(k/100) for k in range(-1800, -300)]\nE = [math.fabs(fdot(f, x0, h) - 2*x0) for h in H]\n\n# Plot\nfig = plt.figure()\nax = fig.add_axes([0.1, 0.1, 0.8, 0.8])\nax.set(xlim=(10**-18, 10**-3), ylim=(10**-12, 10**0))\nax.set_xscale('log')\nax.set_xlabel('h')\nax.set_yscale('log')\nax.set_ylabel('Fehler E(h)')\nplt.plot(H,E)\nplt.show()\n\n\n\n\n\nAbbildung 2.1: Grösse des Fehlers \\(E(h)\\) als Funktion der Schrittweite \\(h\\). Ist \\(h\\) zu gross, dann ist der Näherungswert für \\(f'(x_0)\\) ungenau. Bei kleiner werdendem \\(h\\) nimmt der Fehler zunächst ab, aber ab einem gewissen Wert dominiert die Auslöschung und der Fehler nimmt wieder zu.\n\n\n\n\n\n\n\n2.1.1 Auslöschung\nIm vorherigen Beispiel haben wir das Phänomen der Auslöschung beobachtet. Zunächst ist dir sicher aufgefallen, dass der Näherungswert für \\(f'(x_0)\\) mit \\(h=0.01\\) nicht \\[ \\frac{f(x_0 + h) - f(x_0)}{h} = \\frac{0.21^2 - 0.2^2}{0.01}=0.41\\] ergab, sondern \\(f'(x_0)\\approx 0.40999...\\). Das liegt daran, dass Dezimalzahlen nicht exakt als Binärzahl dargestellt werden können. Da nun die Werte von \\(f(x_0 + h)\\) und \\(f(x_0)\\) für kleine \\(h\\) fast gleich sind, besteht ihre Differenz \\(f(x_0 + h) - f(x_0)\\) nur noch aus diesen Rundungsfehlern. Diese (sinnlose) Differenz ist zwar sehr klein, wird aber im nächsten Schritt mit der sehr grossen Zahl \\(\\frac{1}{h}\\) multipliziert, wodurch die Rundungsfehler die gleiche Grössenordnung annehmen, wie die ursprünglichen Funktionswerte. Mehr über Rundungsfehler und Auslöschung kann in Weitz (2021) ab S. 117 nachgelesen werden."
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Arens, Tilo, Frank Hettlich, Christian Karpfinger, Ulrich Kockelkorn,\nKlaus Lichtenegger, and Hellmuth Stachel. 2022. Mathematik.\nBerlin, Heidelberg: Springer Berlin Heidelberg.\n\n\nGander, Walter. 2015. Learning MATLAB: A Problem\nSolving Approach. 1st ed. UNITEXT. Cham, Switzerland: Springer\nInternational Publishing.\n\n\nHromkovic, Juraj, Jarka Arnold, Cédric Donner, Urs Hauser, Matthias\nHauswirth, Tobias Kohn, Dennis Komm, David Maletinsky, and Nicole Roth.\n2021. INFORMATIK, Programmieren Und Robotik: Grundlagen\nDer Informatik für Schweizer\nMaturitätsschulen.\n\n\nSlater, Max. 2022. “Differentiable Programming from\nScratch.” July 2022. https://thenumb.at/Autodiff/."
  },
  {
    "objectID": "notAD.html#ad-ist-nicht-symbolisches-ableiten",
    "href": "notAD.html#ad-ist-nicht-symbolisches-ableiten",
    "title": "2  AD ist nicht …",
    "section": "2.2 AD ist nicht symbolisches Ableiten",
    "text": "2.2 AD ist nicht symbolisches Ableiten\nComputer Algebra Systeme (CAS) sind Programme zur Bearbeitung algebraischer Ausdrücke. Mit solchen Programmen lassen sich auch Ableitungen symbolisch bestimmen. Wie das funktioniert, wird in Slater (2022) kurz angedeutet. Bekannte Beispiele für CAS sind etwa Wolfram Alpha, Maxima oder Sage. Letzteres kann man hier auch online ausprobieren. Gib z.B. den folgenden Code ein, welcher die Ableitung der Funktion aus Übungsaufgabe 1.3 ableitet:\nl(x) = x^2 + 1\nf(x) = l(l(l(x)))\nfdot = diff(f,x)\nexpand(fdot)\n\n\n\n\n\n\nTipp\n\n\n\nAuf der Website kannst du rechts unter Language auch Maxima auswählen und Maxima-Code ausführen. Maxima ist in Sage integriert.\n\n\nFür Python gibt es die Bibliothek sympy, die ein CAS für Python zur Verfügung stellt. Damit können wir die Funktion aus Übungsaufgabe 1.3 direkt in Python ableiten:\n\nBeispiel 2.2 (Symbolische Ableitung)  Leite die Funktion \\(f(x) = l(l(l(x)))\\), wobei \\(l(x) = x^2 + 1\\) ist, an der Stelle \\(x_0 = 2\\) ab.\n\n\nCode\nfrom sympy  import symbols, diff\n\ndef f(x):\n    v0 = x\n    v1 = v0 ** 2 + 1\n    v2 = v1 ** 2 + 1\n    v3 = v2 ** 2 + 1\n    y = v3\n    return y\n\nx = symbols('x')\nprint(\"f(x) =\", f(x))\n\ndf = diff(f(x),x)\nprint(\"f'(x) =\", df)\n\nx0 = 2\nprint(\"f'(\" + str(x0) + \") =\", df.evalf(subs={x:2}))\n\n\nf(x) = ((x**2 + 1)**2 + 1)**2 + 1\nf'(x) = 8*x*(x**2 + 1)*((x**2 + 1)**2 + 1)\nf'(2) = 2080.00000000000\n\n\n\nDamit erhält man die (bis auf Maschinengenauigkeit) exakten Werte der Ableitungen. Der Grund, warum wir nicht auf symbolische Ausdrücke für Ableitungen zurückgreifen wollen, liegt darin, dass diese Methode bei komplizierten Funktionsausdrücken sehr ineffizient ist, insbesondere dann, wenn wir auch Ableitungen von Funktionen \\(f : \\mathbb{R}^n \\rightarrow \\mathbb{R}^m\\) berechnen wollen.\n\n\n\n\nSlater, Max. 2022. „Differentiable programming from scratch“. Juli 2022. https://thenumb.at/Autodiff/.\n\n\nWeitz, Edmund. 2021. Konkrete Mathematik (nicht nur) für Informatiker. 2. Aufl. Wiesbaden, Germany: Springer Spektrum."
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "1  Ableitungen und ihre Anwendungen",
    "section": "",
    "text": "Wir kennen Ableitungen von Funktionen \\(f: \\mathbb{R}\\rightarrow\\mathbb{R}\\) aus dem Mathematikunterricht. Sie geben uns darüber Auskunft, wie gross die Steigung der Tangente in einem bestimmten Punkt des Funktionsgraphen ist. Die Tangente stellt dabei die beste lineare Annäherung an den Funktionsgraph dar. Ableitungen beschreiben auch die lokale Änderungsrate der Funktion. Ableitungen erlauben es uns ausserdem, die Extrema und Wendepunkte einer Funktion zu bestimmen.\nDie folgende Tabelle fasst die bekannten Ableitungen der Grundfunktionen zusammen.\n\n\nTabelle 1.1: Ableitungen der Grundfunktionen\n\n\n\n\n\n\n\n\n\n\\(f(x)\\)\n\\(f'(x)\\)\n\n\\(f(x)\\)\n\\(f'(x)\\)\n\n\n\n\n\\(x^n\\)\n\\(n \\cdot x^n \\quad (n\\in\\mathbb{R})\\)\n\n\\(\\sqrt{x}\\)\n\\(\\frac{1}{2\\cdot\\sqrt{x}}\\)\n\n\n\\(e^x\\)\n\\(e^x\\)\n\n\\(a^x\\)\n\\(a^x \\cdot \\ln(a) \\quad (a>0, a\\ne 1)\\)\n\n\n\\(\\ln(x)\\)\n\\(\\frac{1}{x}\\)\n\n\\(\\log_a(x)\\)\n\\(\\frac{1}{x\\cdot\\ln(a)} \\quad (a>0, a\\ne 1)\\)\n\n\n\\(\\sin(x)\\)\n\\(\\cos(x)\\)\n\n\\(\\arcsin(x)\\)\n\\(\\frac{1}{\\sqrt{1-x^2}}\\)\n\n\n\\(\\cos(x)\\)\n\\(-\\sin(x)\\)\n\n\\(\\arccos(x)\\)\n\\(-\\frac{1}{\\sqrt{1-x^2}}\\)\n\n\n\\(\\tan(x)\\)\n\\(\\frac{1}{\\cos^2(x)} = 1 + \\tan^2(x)\\)\n\n\\(\\arctan(x)\\)\n\\(\\frac{1}{x^2+1}\\)\n\n\n\\(\\sinh(x)\\)\n\\(\\cosh(x)\\)\n\n\\(\\textrm{arsinh}(x)\\)\n\\(\\frac{1}{\\sqrt{x^2+1}}\\)\n\n\n\\(\\cosh(x)\\)\n\\(\\sinh(x)\\)\n\n\\(\\textrm{arcosh(x)}\\)\n\\(\\frac{1}{\\sqrt{x^2-1}}\\)\n\n\n\\(\\tanh(x)\\)\n\\(\\frac{1}{\\cosh^2(x)} = 1 - \\tanh^2(x)\\)\n\n\\(\\textrm{artanh(x)}\\)\n\\(-\\frac{1}{x^2-1}\\)\n\n\n\n\nNeue Funktionen erhält man, indem man die Grundfunktionen aus Tabelle 1.1 addiert, subtrahiert, multipliziert, dividiert und komponiert, d.h. Verkettungen der Form \\((f\\circ g)(x) = f(g(x))\\) bildet. Um solche Funktionen abzuleiten, brauchen wir die Regeln aus Tabelle 1.2. Mit diesen Regeln sind wir dann schon in der Lage, alle differenzierbaren Funktionen abzuleiten.\n\n\nTabelle 1.2: Ableitungsregeln\n\n\n\n\n\n\nSummenregel\n\\(\\frac{d}{dx}(f(x)\\pm g(x)) = f'(x) \\pm g'(x)\\)\n\n\nProduktregel  Spezialfall: Faktorregel\n\\(\\frac{d}{dx}(f(x)\\cdot g(x)) = f'(x)\\cdot g(x) + f(x) \\cdot g'(x)\\)  \\(\\frac{d}{dx}(a\\cdot f(x)) = a\\cdot f'(x)\\)\n\n\nQuotientenregel\n\\(\\frac{d}{dx}\\frac{f(x)}{g(x)} = \\frac{f'(x)\\cdot g(x) - f(x) \\cdot g'(x)}{g(x)^2}\\)\n\n\nKettenregel\n\\(\\frac{d}{dx} f(g(x)) = f'(g(x))\\cdot g'(x)\\)\n\n\n\n\nAn dieser Stelle sei noch angemerkt, dass sich der Begriff der Ableitung sinngemäss auf Funktionen \\(f: \\mathbb{R}^n \\rightarrow\\mathbb{R}^m\\) verallgemeinern lässt. Eine kurze Beschreibung der Grundidee findet sich in Slater (2022). Weitergehende Informationen findet man z.B. in Arens u. a. (2022) oder in jedem Lehrbuch zur Analysis 2."
  },
  {
    "objectID": "intro.html#programme-als-funktionen",
    "href": "intro.html#programme-als-funktionen",
    "title": "1  Ableitungen und ihre Anwendungen",
    "section": "1.2 Programme als Funktionen",
    "text": "1.2 Programme als Funktionen\nProgramme, die numerische Werte einlesen und numerische Werte ausgeben, können als mathematische Funktionen betrachtet werden. Wir beschränken uns zunächst auf Programme, die nur ein Argument erhalten und nur einen Rückgabewert liefern, z.B.\n\ndef f(x):\n    y = (2 + x) * (x - 3)\n    return y\n\nx0 = 2\nprint( f(x0) )\n\nDiese Python-Funktion entspricht der Funktion \\(f:\\mathbb{R}\\rightarrow\\mathbb{R} , x \\mapsto y=(2+x)(x-3)\\) im Sinne der Mathematik. Natürlich kann der Funktionskörper viel komplizierter aufgebaut sein und z.B. Schleifen und Bedingungen enthalten.\nUm zu verstehen, wie der Computer einen Ausdruck wie y = (2 + x) * (x - 3) auswertet, ist es hilfreich, ihn als Baum (im Sinne der Graphentheorie) darzustellen. Ausdrucksbäume sind ein Spezialfall von so genannten computational graphs und werden z.B. in Hromkovic u. a. (2021) erklärt.\n\n\n\n\n\n\n   \n\nnx\n\nx   \n\nnPlus\n\n +   \n\nnx->nPlus\n\n    \n\nnMinus\n\n -   \n\nnx->nMinus\n\n    \n\nn2\n\n2   \n\nn2->nPlus\n\n    \n\nn3\n\n3   \n\nn3->nMinus\n\n    \n\nnMult\n\n *   \n\nnPlus->nMult\n\n    \n\nnMinus->nMult\n\n    \n\nny\n\ny   \n\nnMult->ny\n\n   \n\n\nAbbildung 1.1: Ausdrucksbaum zum Ausdruck y = (2 + x) * (x - 3).\n\n\n\n\nWir wollen nun unsere Python-Funktion so umschreiben, dass diese Struktur auch im Funktionskörper sichtbar wird. Dazu führen wir drei Hilfsvariablen v0, v1, v2 ein.\n\ndef f(x):\n    v0 = x\n    v1 = 2 + v0\n    v2 = v0 - 3\n    y = v1 * v2\n    return y\n\n\n\n\n\n\n\nKonvention\n\n\n\nEine Funktion berechnet aus einem Argument x einen Rückgabewert y über eine Reihe von Hilfsvariablen v, die mit verschiedenen Indizes versehen sind. Dabei setzen wir am Anfang immer v0 = x.\n\n\n\nÜbungsaufgabe 1.1 (Programm in Funktion übersetzen) \nSchreibe die mathematische Funktion auf, die durch das folgende Programm berechnet wird.\n\nimport math\n\ndef f(x):\n    v0 = x\n    v1 = v0 ** 2\n    v2 = v1 + 2\n    v3 = -v1 / 2\n    v4 = math.cos(v2)\n    v5 = math.exp(v3)\n    v6 = v4 * v5\n    y = v6 + 1 / v0\n    return y \n\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\\[\n\\begin{flalign}\nv_1 & = x^2 \\\\\nv_2 & = x^2 + 2 \\\\\nv_3 & = - \\frac{x^2}{2} \\\\\nv_4 & = \\cos(x^2 + 2) \\\\\nv_5 & = e^{- \\frac{x^2}{2}} \\\\\nv_6 & = \\cos(x^2 + 2) \\cdot e^{- \\frac{x^2}{2}} \\\\\ny & = f(x) = \\cos(x^2 + 2) \\cdot e^{- \\frac{x^2}{2}} + \\frac{1}{x} \\\\\n\\end{flalign}\n\\]\n\n\n\n\nÜbungsaufgabe 1.2 (Funktion in Graph und Programm übersetzen) \nSchreibe zur mathematischen Funktion \\(y = f(x) = \\frac{\\ln(x^2 + 1)}{\\sqrt{x^2 + 1 + x}}\\) den Ausdrucksbaum auf. Übersetze den Ausdruck anschliessend in eine Python-Funktion gemäss der Konvention.\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\n\n\n\n\n\n   \n\nnx\n\nx   \n\nnPlus2\n\n +   \n\nnx->nPlus2\n\n    \n\nnPow\n\n ^   \n\nnx->nPow\n\n    \n\nn2\n\n2   \n\nn2->nPow\n\n    \n\nn1\n\n1   \n\nnPlus1\n\n +   \n\nn1->nPlus1\n\n    \n\nnPlus1->nPlus2\n\n    \n\nnLog\n\n ln( )   \n\nnPlus1->nLog\n\n    \n\nnSqrt\n\n sqrt( )   \n\nnPlus2->nSqrt\n\n    \n\nnPow->nPlus1\n\n    \n\nnFrac\n\n /   \n\nny\n\ny   \n\nnFrac->ny\n\n    \n\nnLog->nFrac\n\n    \n\nnSqrt->nFrac\n\n   \n\n\nAbbildung 1.2: Computational Graph zum Ausdruck y = ln(x^2 + 1) / sqrt(x^2 + 1 + x).\n\n\n\n\n\n\nCode\nimport math\n\ndef f(x):\n    v0 = x\n    v1 = v0 ** 2\n    v2 = v1 + 1\n    v3 = v2 + v0\n    v4 = math.log(v2)\n    v5 = math.sqrt(v3)\n    y = v4 / v5\n    return y\n\n\nNatürlich hätte man z.B. v3 und v4 auch vertauschen können.\n\n\n\n\nÜbungsaufgabe 1.3 (Ein Programm mit einer Schleife) \nErsetze im Funktionskörper die Schleife durch mehrere Befehle, so dass immer noch der gleiche mathematische Ausdruck berechnet wird und unsere Konvention eingehalten wird. Welche mathematische Funktion wird durch die Python-Funktion berechnet? Was ändert sich, wenn stattdessen for i in range(3) oder for i in range(4) stehen würde?\n\ndef f(x):\n    v0 = x\n    for i in range(2):\n        v0 = v0 ** 2 + 1\n    y = v0\n    return y\n\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\nFür jeden Schleifendurchgang benötigen wir eine neue Hilfsvariable. Die Funktion, die dabei entsteht, kann geschrieben werden als \\(f(x) = (\\ell \\circ \\ell \\circ \\ldots \\circ \\ell)(x)\\), wobei \\(\\ell(x) = x^2 + 1\\) ist.\n\nrange(2)range(3)range(4)\n\n\n\ndef f(x):\n    v0 = x\n    v1 = v0 ** 2 + 1\n    v2 = v1 ** 2 + 1\n    y = v2\n    return y\n\n\\[\n\\begin{flalign}\n    f(x) &= \\ell(\\ell(x)) \\\\\n         &= (x^2 + 1)^2 + 1 = x^4 + 2x^2 + 2\n\\end{flalign}\n\\]\n\n\n\ndef f(x):\n    v0 = x\n    v1 = v0 ** 2 + 1\n    v2 = v1 ** 2 + 1\n    v3 = v2 ** 2 + 1\n    y = v3\n    return y\n\n\\[\n\\begin{flalign}\n    f(x) &= \\ell(\\ell(\\ell(x))) \\\\\n         &= ((x^2 + 1)^2 + 1)^2 + 1 = x^8 + 4x^6 + 8x^4 + 8x^2 + 5\n\\end{flalign}\n\\]\n\n\n\ndef f(x):\n    v0 = x\n    v1 = v0 ** 2 + 1\n    v2 = v1 ** 2 + 1\n    v3 = v2 ** 2 + 1\n    v4 = v3 ** 2 + 1\n    y = v4\n    return y\n\n\\[\n\\begin{flalign}\n    f(x) &= \\ell(\\ell(\\ell(\\ell(x)))) \\\\\n         &= (((x^2 + 1)^2 + 1)^2 + 1)^2 + 1 \\\\\n         &= x^{16} + 8x^{14} + 32x^{12} + 80x^{10} + 138x^8 + 168x^6 + 144x^4 + 80x^2 + 26\n\\end{flalign}\n\\]"
  },
  {
    "objectID": "intro.html#unser-ziel-programme-ableiten",
    "href": "intro.html#unser-ziel-programme-ableiten",
    "title": "1  Ableitungen und ihre Anwendungen",
    "section": "1.3 Unser Ziel: Programme ableiten",
    "text": "1.3 Unser Ziel: Programme ableiten\nWie eingangs erwähnt wurde, haben Ableitungen viele nützliche Anwendungen.\nCOMING SOON: Idee Programm als Funktion ableiten, Namensgebung AD, möglichst exakte Werte gesucht, nicht von Hand ableiten weil letztes Bsp zeigt, dass Funktionsausdrücke schnell sehr gross werden können.\n\n1.3.1 Das Newtonverfahren zur Berechnung von Nullstellen\nIn vielen Anwendungen steht man vor der Aufgabe, die Gleichung \\(f(x) = 0\\) nach \\(x\\) aufzulösen, d.h. eine Nullstelle \\(\\bar{x}\\) der Funktion zu finden. Oft ist es aber nicht möglich, die Lösung einer solchen Gleichung in geschlossener Form darzustellen. Um dennoch eine Lösung zumindest näherungsweise berechnen zu können, kann man folgendermassen vorgehen:\n\nWähle einen Startwert \\(x_0\\), der in der Nähe einer Nullstelle \\(\\bar{x}\\) von \\(f\\) liegt.\nIm Kurvenpunkt \\((x_0 | y_0)\\) wird die Tangente an die Kurve \\(f\\) gelegt. Deren Schnittpunkt \\(x_1\\) mit der \\(x\\)-Achse liegt in der Regel näher bei \\(\\bar{x}\\) als \\(x_0\\).\nNun wiederholt man das Verfahren, indem man bei \\(x_1\\) die Tangente an die Kurve legt, usw. Auf diese Weise erhält man eine Folge von Näherungen \\(x_0, x_1, x_2, \\ldots\\), deren Grenzwert die Nullstelle \\(\\bar{x}\\) ist.\n\nDieser Algorithmus ist als Newtonverfahren bekannt.\n\n\n\n\nDie Gleichung der Tangente im Punkt \\((x_n | y_n) = (x_n | f(x_n))\\) ist bekanntlich \\(t(x) = f(x_n) + f'(x_n) \\cdot (x - x_n)\\). Die Nullstelle der Tangente ist der Näherungswert \\(x_{n+1}\\). Aus \\(t(x_{n+1}) = 0\\) ergibt sich nun die Iterationsvorschrift des Newtonverfahrens: \\[\nx_{n+1} = x_n - \\frac{f(x_n)}{f'(x_n)}\n\\tag{1.1}\\]\n\nÜbungsaufgabe 1.4 (Das Newtonverfahren programmieren) \nSchreibe ein Programm, das mit Hilfe des Newtonverfahrens (Gleichung 1.1) eine Nullstelle der Funktion \\(f(x) = \\frac{1}{31} x^3 -\\frac{1}{20} x^2 -x + 1\\) berechnet. Verwende den Startwert \\(x_0 = -2\\). Du kannst abbrechen, wenn die Differenz \\(|x_{n+1} - x_n|\\) kleiner als eine bestimmte Toleranz wird, z.B. kleiner als tol = 1e-6. Wie flexibel ist dein Programm einsetzbar? Überlege dir z.B., wie viele Änderungen du vornehmen müsstest, wenn du die Nullstelle einer anderen Funktion berechnen müsstest.\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\nWelche der folgenden Lösungsvorschläge kommt deinem Programm am nächsten?\n\nVersion 1Version 2Version 3Version 4\n\n\n\nfrom math import fabs\n\nx0 = -2\ntol = 1e-6\n# Erster Schritt berechnen\nx1 = x0 - (1/31 * x0**3 - 1/20 * x0**2 - x0 + 1) / (3/31 * x0**2 - 1/10 * x0 - 1)\nwhile fabs(x1 - x0) > tol:\n    x0 = x1\n    x1 = x0 - (1/31 * x0**3 - 1/20 * x0**2 - x0 + 1) / (3/31 * x0**2 - 1/10 * x0 - 1)\nprint(x1)\n\n5.908619865450271\n\n\nDas Newtonverfahren wird als main-Funktion (d.h. im Hauptprogramm) ausgeführt. Braucht man jedoch die Nullstelle einer anderen Funktion, dann muss ein neues Programm geschrieben werden. Die Ableitung wurde von Hand berechnet.\n\n\n\nfrom math import fabs\n\ndef f(x):\n    y = 1/31 * x**3 - 1/20 * x**2 - x + 1\n    return y\n\ndef fdot(x):\n    ydot = 3/31 * x**2 - 1/10 * x - 1\n    return ydot\n\nx0 = -2\ntol = 1e-6\n# Erster Schritt berechnen\nx1 = x0 - f(x0) / fdot(x0)\nwhile fabs(x1 - x0) > tol:\n    x0 = x1\n    x1 = x0 - f(x0) / fdot(x0)\nprint(x1)\n\n5.908619865450271\n\n\nDas Newtonverfahren wird als main-Funktion (d.h. im Hauptprogramm) ausgeführt, aber die Berechnung von \\(f\\) und ihrer Ableitung \\(f'\\) wurde in zwei Funktionen f und fdot ausgelagert. Das macht das Programm übersichtlicher und flexibler. Die Ableitung wurde wieder von Hand berechnet.\n\n\n\nfrom math import fabs\n\ndef newton(f, fdot, x0):\n    tol = 1e-6\n    # Erster Schritt berechnen\n    x1 = x0 - f(x0) / fdot(x0)\n    while fabs(x1 - x0) > tol:\n        x0 = x1\n        x1 = x0 - f(x0) / fdot(x0)\n    return(x1)\n\ndef f(x):\n    y = 1/31 * x**3 - 1/20 * x**2 - x + 1\n    return y\n\ndef fdot(x):\n    ydot = 3/31 * x**2 - 1/10 * x - 1\n    return ydot\n\nx0 = -2\nxbar = newton(f, fdot, x0)\nprint(xbar)\n\n5.908619865450271\n\n\nDas Newtonverfahren wird als eigene Funktion newton(f, fdot, x0) implementiert. Dieser werden die Funktion \\(f\\) und ihre Ableitung \\(f'\\), sowie der Startwert \\(x_0\\) als Argumente übergeben. Sie kann dann im Hauptprogramm aufgerufen werden. Die Ableitung wurde aber immer noch von Hand berechnet.\n\n\n\nfrom math import fabs\n\ndef newton(f, x0):\n    tol = 1e-6\n    # Erster Schritt berechnen\n    # Ableitung von f an der Stelle x0 annähern\n    h = 1e-6\n    ydot = ( f(x0 + h) - f(x0) ) / h\n    x1 = x0 - f(x0) / ydot\n    while fabs(x1 - x0) > tol:\n        x0 = x1\n        ydot = ( f(x0 + h) - f(x0) ) / h\n        x1 = x0 - f(x0) / ydot\n    return(x1)\n\ndef f(x):\n    y = 1/31 * x**3 - 1/20 * x**2 - x + 1\n    return y\n\nx0 = -2\nxbar = newton(f, x0)\nprint(xbar)\n\n5.90861986545027\n\n\nHier wird das Newtonverfahren in einer Funktion implementiert. Die Ableitung wird nicht mehr von Hand berechnet, sondern innerhalb der Funktion mit \\(f'(x_0)\\approx \\frac{f(x_0 + h) - f(x_0)}{h}\\) angenähert. Dabei wird einfach h = 1e-6 gesetzt und gehofft, dass der entstehende Rundungsfehler klein genug ist. Beachte aber, dass sich der berechnete Wert von der Ausgabe in den anderen Versionen leicht unterscheidet.\n\n\n\n\n\n\nAuch die Version 4 der vorgestellten Lösung ist noch nicht befriedigend. Als wir die Ableitung von Hand berechnet hatten, musste nur die Funktion fdot and der Stelle x0 ausgewertet werden, um den (bis auf Maschinengenauigkeit) exakten Wert von \\(f'(x_0)\\) zu erhalten. Bei der letzten Methode muss man sich mit einem Näherungswert der Ableitung zufrieden geben. Auch wenn der Wert in diesem Beispiel gut genug war1, so haben wir doch keine Garantie, dass wir für alle Funktionen einen vernünftigen Wert erhalten. Auf die Probleme, die mit dieser Annäherung von \\(f'(x_0)\\) auftreten, wird in Kapitel 2.1 näher eingegangen.1 Das Newton-Verfahren hat die angenehme Eigenschaft, dass kleine Rundungsfehler automatisch ausgeglichen werden. Auf andere numerische Verfahren, die die Ableitung verwenden, trifft dies aber nicht zu.\n\nBeispiel 1.1 (Billard auf einem runden Tisch) \nWir betrachten ein Beispiel aus Gander (2015). Platziere die weisse und die blaue Billardkugel auf dem runden Tisch. Das Ziel ist es, die weisse Kugel so anzustossen, dass sie die blaue Kugel trifft, nachdem sie vorher genau einmal an die Bande gespielt wurde.\n\n\n\n\nAus Symmetriegründen dürfen wir annehmen, dass der Rand des Billardtisches der Einheitskreis ist und dass die weisse Kugel auf der \\(x\\)-Achse liegt. Die blaue Kugel habe die Koordinaten \\((x_P|y_P)\\). Weiter sei \\(X\\) der auf dem Einheitskreis, an dem die weisse Kugel abprallt. Wir beschreiben diesen Punkt mit seinen Polarkoordinaten \\(X=(\\cos(x)|\\sin(x))\\). Unser Ziel ist es, \\(x\\) so zu berechnen, dass die weisse Kugel die blaue trifft, nachdem sie bei \\(X\\) an die Bande gestossen ist. Dabei verhält sie sich so, als ob sie an der Kreistangente in \\(X\\) reflektiert wird. Der Tangentenvektor im Punkt \\(X\\) lautet \\(\\vec{r} = \\begin{pmatrix} -\\sin(x) \\\\ \\cos(x) \\end{pmatrix}\\).\n\n\n\n\n\nBillard auf einem runden Tisch\n\n\nWir betrachten nun die Einheitsvektoren \\(\\vec{e}_Q\\) in Richtung \\(\\overrightarrow{XQ}\\) und \\(\\vec{e}_P\\) in Richtung \\(\\overrightarrow{XP}\\). Wenn die weisse Kugel die blaue treffen soll, dann müssen die Winkel zwischen der Tangente und diesen Vektoren gleich sein. Das ist genau dann der Fall, wenn \\(\\vec{r}\\) senkrecht steht auf \\(\\vec{e}_Q + \\vec{e}_P\\). Wir müssen also \\(x\\) so bestimmen, dass \\(\\vec{r} \\cdot (\\vec{e}_Q + \\vec{e}_P) = 0\\) ist.\nDas folgende Programm berechnet das Skalarprodukt der linken Seite dieser Gleichung.\n\n\nCode\nimport math\nimport matplotlib.pyplot as plt\n\ndef f(x):\n    # Parameter\n    a = -0.8           # Position von Q = (a|0)\n    px, py = 0.5, 0.5  # Position von P = (px|py)\n\n    # Berechnung des Skalarprodukts\n    v0 = x\n    v1 = math.cos(v0)  # x-Koordinate von X\n    v2 = math.sin(v0)  # y-Koordinate von X\n    v3 = px - v1       # x-Komponente des Vektors XP\n    v4 = py - v2       # y-Komponente des Vektors XP\n    v5 = math.sqrt(v3**2 + v4**2)  # Länge des Vektors XP\n    v6 = v3 / v5       # x-Komponente des Einheitsvektors eP\n    v7 = v4 / v5       # y-Komponente des Einheitsvektors eP\n    \n    v8 = a - v1        # x-Komponente des Vektors XQ\n    v9 = -v2           # y-Komponente des Vektors XQ\n    v10 = math.sqrt(v8**2 + v9**2)  # Länge des Vektors XQ\n    v11 = v8 / v10     # x-Komponente des Vektors eQ    \n    v12 = v9 / v10     # y-Komponente des Vektors eQ   \n    y = (v6 + v11) * v2 - (v7 + v12) * v1\n    return y   \n\n# Graph der Funktion f(x) plotten\nfig = plt.figure()\nax = plt.gca()\nax.set_xlim((0,2*math.pi))\nax.set_ylim((-1.5,1.5))\nX = [2*math.pi * k / 1000 for k in range(1001)]\nY = [f(x) for x in X]\nplt.plot([0, 2*math.pi], [0, 0], 'k--') # x-Achse\nplt.plot(X,Y)\nplt.xticks([0, math.pi/2, math.pi, 3*math.pi/2, 2*math.pi],\n           ['0', 'π/2', 'π', '3π/2', '2π'])\nplt.show()  \n\n\n\n\n\nAbbildung 1.3: Graph des Skalarprodukts als Funktion des Polarwinkels \\(x\\) des Punktes \\(X = (cos(x) | sin(x))\\). Die Nullstellen entsprechen den Winkeln, bei denen die weisse Kugel die blaue Kugel trifft, nachdem sie genau einmal an die Bande gespielt wurde.\n\n\n\n\nWir möchten die Nullstellen der Funktion f(x) mit unserer Funtion newton bestimmmen. Dazu müssen wir jedoch die Ableitung von f berechnen.\n\n\n\n\n1.3.2 Gradient Descent zum Auffinden lokaler Minima\nEine weitere wichtige Aufgabe besteht darin, ein Minimum einer Funktion zu finden. Auch hier wollen wir mit Hilfe der Ableitung eine Folge von Näherungswerten \\(x_0, x_1, x_2, \\ldots\\) finden, deren Grenzwert die \\(x\\)-Koordinate eines (lokalen) Minimums von \\(f\\) ist.\nWenn \\(f'(x_n)>0\\) ist, dann wissen wir, dass die Funktion \\(f\\) an der Stelle \\(x_0\\) streng monoton wachsend ist. D.h., dass die Funktionswerte links von \\(x_n\\) kleiner sind, als an der Stelle \\(x_n\\). Analog gilt, dass wenn \\(f'(x_n)<0\\) ist, die Funktion monoton fallend ist und wir uns nach rechts bewegen sollten, um ein Minimum zu finden. In der Nähe eines Minimums ist ausserdem \\(|f'(x)|\\) sehr klein und wir können entsprechend kleinere Schritte machen, um uns diesem anzunähern. Um also von \\(x_n\\) zu \\(x_{n+1}\\) zu kommen, machen wir einen Schritt, der proportional zu \\(-f'(x_n)\\) ist. Mit dem Proporionalitätsfaktor \\(\\lambda\\in\\mathbb{R}\\) und einem geeignet gewählten Startwert \\(x_0\\) erhalten wir die Iterationsvorschrift \\[\nx_{n+1} = x_n - \\lambda\\cdot f'(x_n)\n\\tag{1.2}\\]\n\n\n\n\n\nÜbungsaufgabe 1.5 (Eigenschaften der Gradient Descent Methode)  Experimentiere mit verschiedenen Funktionen und verschiedenen Schrittweiten \\(\\lambda\\). Was passiert, wenn die Schrittweite zu klein bzw. zu gross gewählt wird? Was passiert, wenn \\(f\\) an der Stelle \\(x_0\\) ein lokales Maximum aufweist? Was passiert in der Nähe eines Sattelpunktes?\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\nIst \\(\\lambda\\) zu klein, dann konvergiert das Verfahren nur sehr langsam. Ist \\(\\lambda\\) dagegen zu gross, dann kann es passieren, dass die Iteration zwischen zwei oder mehr Werten hin- und herspringt oder sogar nach \\(\\pm\\infty\\) divergiert.\nFalls \\(x_0\\) gerade mit der Stelle eines lokalen Maximums oder eines Sattelpunktes zusammenfällt, gilt auch \\(f'(x_0)=0\\) und damit auch \\(x_n = x_0\\) für alle \\(n\\in\\mathbb{N}\\). Maxima sind aber labile Gleichgewichtspunkte in dem Sinn, dass sich \\(x_n\\) von ihnen wegbewegt, wenn \\(x_0\\) auch nur ein bisschen links oder rechts davon liegt. Ähnlich verhält es sich bei Sattelpunkten. Die Folge konvergiert gegen die Stelle des Sattelpunktes, wenn \\(f(x_0)\\) grösser als der \\(y\\)-Wert des Sattelpunktes ist und \\(\\lambda\\) nicht zu gross ist.\n\n\n\n\nÜbungsaufgabe 1.6 (Gradient Descent programmieren) \nSchreibe ein Programm, das mit Hilfe des Gradient Descent Verfahrens (Gleichung 1.2) ein lokales Minimums der Funktion \\(f(x) = \\frac{1}{16}x^4 - \\frac{1}{3}x^3 + \\frac{1}{8}x^2 + x + 2\\) berechnet. Verwende den Startwert \\(x_0 = 1.5\\) und die Schrittweite \\(\\lambda = 0.5\\). Du kannst abbrechen, wenn die Differenz \\(|x_{n+1} - x_n|\\) kleiner als eine bestimmte Toleranz wird, z.B. kleiner als tol = 1e-6. Wie flexibel ist dein Programm einsetzbar? Überlege dir z.B., wie viele Änderungen du vornehmen müsstest, wenn du ein lokales Minimum einer anderen Funktion berechnen müsstest.\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\nWelche der folgenden Lösungsvorschläge kommt deinem Programm am nächsten?\n\nVersion 1Version 2Version 3Version 4\n\n\n\nfrom math import fabs\n\nx0 = 1.5\nlam = 0.5\ntol = 1e-6\n# Erster Schritt berechnen\nx1 = x0 - lam * (1/4 * x0**3 - x0**2 + 1/4 * x0 + 1)\nwhile fabs(x1-x0) > tol:\n    x0 = x1\n    x1 = x0 - lam * (1/4 * x0**3 - x0**2 + 1/4 * x0 + 1)\nprint(x1)\n\n3.3429230748530196\n\n\nDas Gradient Descent Verfahren wird als main-Funktion (d.h. im Hauptprogramm) ausgeführt. Um das Minimum einer anderen Funktion zu bestimmen, muss ein neues Programm geschrieben werden. Die Ableitung wurde von Hand berechnet\n\n\n\nfrom math import fabs\n\ndef fdot(x):\n    ydot = 1/4 * x**3 - x**2 + 1/4 * x + 1\n    return ydot\n\nx0 = 1.5\nlam = 0.5\ntol = 1e-6\n# Erster Schritt berechnen\nx1 = x0 - lam * fdot(x0)\nwhile fabs(x1-x0) > tol:\n    x0 = x1\n    x1 = x0 - lam * fdot(x0)\nprint(x1)\n\n3.3429230748530196\n\n\nDas Gradient Descent Verfahren wird als main-Funktion (d.h. im Hauptprogramm) ausgeführt, aber die Berechnung von \\(f'\\) wurde in die Funktion fdot(x) ausgelagert. Das macht das Programm etwas flexibler. Die Ableitung wurde wieder von Hand berechnet.\n\n\n\nfrom math import fabs\n\ndef gradient_descent(fdot, x0, lam):\n    tol = 1e-6\n    # Erster Schritt berechnen\n    x1 = x0 - lam * fdot(x0)\n    while fabs(x1-x0) > tol:\n        x0 = x1\n        x1 = x0 - lam * fdot(x0)\n    return x1\n\ndef fdot(x):\n    ydot = 1/4 * x**3 - x**2 + 1/4 * x + 1\n    return ydot\n\nx0 = 1.5\nlam = 0.5\nxmin = gradient_descent(fdot, x0, lam)\nprint(xmin)\n\n3.3429230748530196\n\n\nDas Gradient Descent Verfahren wird als eigene Funktion gradient_descent(fdot, x0, lam) implementiert. Dieser Funktion werden die Ableitung \\(f'\\), der Startwert \\(x_0\\), sowie die Schrittweite \\(\\lambda\\) als Argumente übergeben. Sie kann dann im Hauptprogramm aufgerufen werden. Die Ableitung wurde aber immer noch von Hand berechnet.\n\n\n\nfrom math import fabs\n\ndef gradient_descent(f, x0, lam):\n    tol = 1e-6\n    # Erster Schritt berechnen\n    # Ableitung an der Stelle x0 annähern\n    h = 1e-6\n    ydot = ( f(x0 + h) - f(x0) ) / h\n    x1 = x0 - lam * ydot\n    while fabs(x1-x0) > tol:\n        x0 = x1\n        ydot = ( f(x0 + h) - f(x0) ) / h\n        x1 = x0 - lam * ydot\n    return x1\n\ndef f(x):\n    y = 1/16 * x**4 - 1/3 * x**3 + 1/8 * x**2 + x + 2\n    return y\n\nx0 = 1.5\nlam = 0.5\nxmin = gradient_descent(fdot, x0, lam)\nprint(xmin)\n\n2.535183236464121\n\n\nDas Gradient Descent Verfahren wird als eigene Funktion gradient_descent(f, x0, lam) implementiert. Dieser Funktion werden die ursprüngliche Funktion \\(f\\), der Startwert \\(x_0\\), sowie die Schrittweite \\(\\lambda\\) als Argumente übergeben. Die Ableitung wird nicht mehr von Hand berechnet, sondern durch den Differenzenquotienten \\(f'(x_0) \\approx \\frac{f(x_0 + h) - f(x_0)}{h}\\) angenähert. Dabei wird einfach h = 1e-6 gesetzt und gehofft, dass der entstehende Rundungsfehler klein genug ist. Offensichtlich ist diese Annahme jedoch nicht gerechtfertigt.\n\n\n\n\n\n\nDie Übungsaufgabe 1.6 verdeutlicht nochmals das Problem, welches wir bereits in Übungsaufgabe 1.4 gesehen haben. Wir müssen für den Algorithmus die Ableitung \\(f'\\) an mehreren Stellen auswerten. Wir möchten aber die Ableitung einerseits nicht von Hand berechnen und andererseits können wir uns auch nicht mit einer Approximation zufrieden geben.\nWir beschliessen dieses Kapitel mit einer praktischen Anwendung der Gradient Descent Methode.\n\nBeispiel 1.2 (Titel) \nCOMING SOON: Anwendungsbeispiel für Gradient Descent\n\n\n\n\n\n\nArens, Tilo, Frank Hettlich, Christian Karpfinger, Ulrich Kockelkorn, Klaus Lichtenegger, und Hellmuth Stachel. 2022. Mathematik. Berlin, Heidelberg: Springer Berlin Heidelberg.\n\n\nGander, Walter. 2015. Learning MATLAB: A Problem Solving Approach. 1. Aufl. UNITEXT. Cham, Switzerland: Springer International Publishing.\n\n\nHromkovic, Juraj, Jarka Arnold, Cédric Donner, Urs Hauser, Matthias Hauswirth, Tobias Kohn, Dennis Komm, David Maletinsky, und Nicole Roth. 2021. INFORMATIK, Programmieren und Robotik: Grundlagen der Informatik für Schweizer Maturitätsschulen.\n\n\nSlater, Max. 2022. „Differentiable programming from scratch“. Juli 2022. https://thenumb.at/Autodiff/."
  },
  {
    "objectID": "index.html#danksagung",
    "href": "index.html#danksagung",
    "title": "AutoDiff",
    "section": "Danksagung",
    "text": "Danksagung"
  }
]